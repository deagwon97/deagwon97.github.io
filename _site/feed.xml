<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-12-29T01:32:18+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">bdg-blog</title><subtitle></subtitle><entry><title type="html">[sqlalchemy]트랜젝션 격리 수준</title><link href="http://localhost:4000/%EB%B0%B1%EC%95%A4%EB%93%9C/2024/07/20/sqlalchemy-%ED%8A%B8%EB%9E%9C%EC%A0%9D%EC%85%98-%EA%B2%A9%EB%A6%AC-%EC%88%98%EC%A4%80.html" rel="alternate" type="text/html" title="[sqlalchemy]트랜젝션 격리 수준" /><published>2024-07-20T00:00:00+09:00</published><updated>2024-07-20T00:00:00+09:00</updated><id>http://localhost:4000/%EB%B0%B1%EC%95%A4%EB%93%9C/2024/07/20/sqlalchemy-%ED%8A%B8%EB%9E%9C%EC%A0%9D%EC%85%98-%EA%B2%A9%EB%A6%AC-%EC%88%98%EC%A4%80</id><content type="html" xml:base="http://localhost:4000/%EB%B0%B1%EC%95%A4%EB%93%9C/2024/07/20/sqlalchemy-%ED%8A%B8%EB%9E%9C%EC%A0%9D%EC%85%98-%EA%B2%A9%EB%A6%AC-%EC%88%98%EC%A4%80.html"><![CDATA[<h1 id="트랜잭션-격리-수준과-데이터베이스-조회-문제-해결">트랜잭션 격리 수준과 데이터베이스 조회 문제 해결</h1>

<p>sqlalchemy를 활용하여 개발하던 중 <b>트랜잭션 격리 수준</b>으로 인해 예상치 못한 문제를 겪었습니다. 이 글에서는 트랜잭션 격리 수준이 무엇인지, 왜 중요한지, 그리고 이를 어떻게 설정하고 관리할 수 있는지에 대해 설명하겠습니다.</p>

<h2 id="1-서론">1. 서론</h2>
<h3 id="11-문제-상황">1.1. 문제 상황</h3>
<p>데이터베이스의 데이터를 생성한 후, 다른 sqlalchemy 세션에서 동일한 데이터를 조회할 때, 생성된 데이터를 조회할 수 없는 상황이 발생했습니다.</p>

<h3 id="12-문제의-원인-추측">1.2. 문제의 원인 추측</h3>
<p>sqlalchemy의 세션을 종료하고 새롭게 세션을 만들면, 정상적으로 조회가 된다는 사실을 통해서 트랜젝션 격리 수준으로 인한 문제라고 생각했습니다.</p>

<h2 id="2-트랜잭션-격리-수준의-이해">2. 트랜잭션 격리 수준의 이해</h2>
<h3 id="21-트랜잭션과-격리-수준이란">2.1. 트랜잭션과 격리 수준이란?</h3>
<p>트랜잭션은 데이터베이스의 논리적 작업 단위이며, 격리 수준은 트랜잭션이 다른 트랜잭션의 영향을 받지 않도록 하는 정도를 정의합니다. 격리 수준은 데이터의 무결성과 일관성을 유지하기 위해 중요합니다.</p>

<p>read, write, commit, flush, close</p>

<h3 id="22-주요-트랜잭션-격리-수준">2.2. 주요 트랜잭션 격리 수준</h3>

<h4 id="a-read-uncommitted">a) <code class="highlighter-rouge">READ UNCOMMITTED</code></h4>
<p>가장 낮은 격리 수준으로, 한 트랜잭션이 다른 트랜잭션의 미완료 데이터를 읽을 수 있습니다.</p>

<h4 id="a-read-committed">a) <code class="highlighter-rouge">READ COMMITTED</code></h4>
<p>다른 트랜잭션의 완료된 데이터만 읽을 수 있습니다.</p>
<h4 id="a-repeatable-read-같은-데이터를-여러-번-읽을-때-항상-같은-값을-읽도록-보장합니다">a) <code class="highlighter-rouge">REPEATABLE READ</code>: 같은 데이터를 여러 번 읽을 때 항상 같은 값을 읽도록 보장합니다.</h4>
<h4 id="a-serializable-가장-높은-격리-수준으로-트랜잭션이-직렬화된-것처럼-실행됩니다">a) <code class="highlighter-rouge">SERIALIZABLE</code>: 가장 높은 격리 수준으로, 트랜잭션이 직렬화된 것처럼 실행됩니다.</h4>

<h3 id="23-동시성-문제">2.3. 동시성 문제</h3>
<ul>
  <li><code class="highlighter-rouge">Dirty Read</code>: 미완료 데이터를 읽는 경우</li>
  <li><code class="highlighter-rouge">Non-repeatable Read</code>: 동일 데이터를 여러 번 읽을 때 다른 값을 얻는 경우</li>
  <li><code class="highlighter-rouge">Phantom Read</code>: 동일 쿼리를 여러 번 실행할 때 레코드 수가 달라지는 경우</li>
</ul>

<h2 id="3-문제의-원인-트랜잭션-격리-수준">3. 문제의 원인: 트랜잭션 격리 수준</h2>
<h3 id="31-문제-발생-시나리오">3.1. 문제 발생 시나리오</h3>
<p>데이터 수정 트랜잭션이 커밋된 후, 다른 세션에서 동일 데이터를 조회할 때 변경 사항이 반영되지 않는 문제를 겪었습니다.</p>

<h3 id="32-트랜잭션-격리-수준의-영향">3.2. 트랜잭션 격리 수준의 영향</h3>
<p>문제는 데이터베이스의 트랜잭션 격리 수준이 READ COMMITTED로 설정되어 있었기 때문에 발생했습니다. 이는 한 트랜잭션이 커밋한 후에 다른 트랜잭션이 데이터를 읽을 수 있음을 의미합니다.</p>

<h2 id="4-문제-해결-방법">4. 문제 해결 방법</h2>
<h3 id="41-격리-수준-조정">4.1. 격리 수준 조정</h3>
<p>트랜잭션 격리 수준을 조정하여 문제를 해결할 수 있습니다. 애플리케이션의 요구 사항에 따라 적절한 격리 수준을 선택합니다.</p>

<p>예제 코드: READ COMMITTED로 설정
python
코드 복사
from sqlalchemy.orm import sessionmaker
from sqlalchemy import create_engine</p>

<p>engine = create_engine(‘your_database_url’, isolation_level=’READ COMMITTED’)
SessionLocal = sessionmaker(bind=engine)
4.2. 세션 새로 고침
데이터 조회 시 세션을 새로 고침하여 최신 데이터를 반영하도록 합니다.</p>

<p>예제 코드: 세션 새로 고침
python
코드 복사
class MyDatabaseClass:
    def <strong>init</strong>(self):
        self.db = SessionLocal()</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def get_aimodel_by_name(self, name):
    self.db.expire_all()  # 모든 객체를 만료시켜 강제로 새로 고침
    query = self.db.query(schema.Aimodel).filter(schema.Aimodel.name == name)
    aimodel = query.first()
    return aimodel 5. 결론 트랜잭션 격리 수준은 데이터베이스의 동시성 제어와 데이터 일관성 유지에 매우 중요한 역할을 합니다. 격리 수준을 적절히 설정하고 관리하면 데이터베이스의 예상치 못한 문제를 방지할 수 있습니다. 이 글이 트랜잭션 격리 수준을 이해하고 문제를 해결하는 데 도움이 되길 바랍니다.
</code></pre></div></div>]]></content><author><name></name></author><category term="백앤드" /><summary type="html"><![CDATA[트랜잭션 격리 수준과 데이터베이스 조회 문제 해결]]></summary></entry><entry><title type="html">chatgpt의 간단한 이해</title><link href="http://localhost:4000/%EA%B8%B0%ED%83%80/2023/10/14/chatgpt%EC%9D%98-%EA%B0%84%EB%8B%A8%ED%95%9C-%EC%9D%B4%ED%95%B4.html" rel="alternate" type="text/html" title="chatgpt의 간단한 이해" /><published>2023-10-14T00:00:00+09:00</published><updated>2023-10-14T00:00:00+09:00</updated><id>http://localhost:4000/%EA%B8%B0%ED%83%80/2023/10/14/chatgpt%EC%9D%98-%EA%B0%84%EB%8B%A8%ED%95%9C-%EC%9D%B4%ED%95%B4</id><content type="html" xml:base="http://localhost:4000/%EA%B8%B0%ED%83%80/2023/10/14/chatgpt%EC%9D%98-%EA%B0%84%EB%8B%A8%ED%95%9C-%EC%9D%B4%ED%95%B4.html"><![CDATA[<h2 id="chatgpt란">chatgpt란?</h2>

<ul>
  <li>Transformer 계열의 대형 언어 모델(large language model, LLM) 챗봇이다.</li>
  <li>인간 피드백형 강화학습 (Reinforcement Learning w/ Human Feedback, RLHF)을 통해 학습한다.</li>
  <li>chatgpt는 인간의 언어, 이미지, 영상 등을 입력으로 받는다. LLM을 통해서 이러한 정보들을 고차원 벡터공간에 매핑한다. 이렇게 수치화된 정보는 강화학습 모델의 ‘상태’가 된다. ‘정책’을 바탕으로 최적의 ‘행동’을 수행하는 방식으로 동작한다.</li>
  <li>https://seo.tbwakorea.com/blog/what-is-chatgpt/</li>
</ul>

<h2 id="강화학습reinforcement-learning"><strong>강화학습(reinforcement-learning)</strong></h2>

<ul>
  <li><strong><em>강화학습</em></strong>은 컴퓨터 에이전트가 역동적인 환경에서 반복적인 시행착오 상호작용을 통해 작업 수행 방법을 학습하는 머신러닝 기법의 한 유형입니다.</li>
  <li>용어
    <ul>
      <li>외부 환경: 행동의 주체에서 입력 받는 모든 정보</li>
      <li>상태: 행동의 주체가 가지고 있는 과거 정보 + 외부 환경</li>
      <li>정책: 현재 상태에서 가장 최적의 선택을 하는 원칙</li>
      <li>행동: 상태와 정책을 통해서 외부 환경 및 나의 상태에 변화를 가하는 것</li>
      <li>episode: 일련의 행동 집합</li>
      <li>reward: 학습을 위해서 주어지는 행동에 대한 긍적적 혹은 부정적 피드백</li>
      <li>return: episode가 끝나고 주어지는 피드백</li>
    </ul>
  </li>
  <li><strong><em>강화학습은</em></strong> 정책과 상태에 따라서 연속적인 행동을 할 때, 그에 따른 보상이 주어지는 것을 보고 정책을 더 나은 방향으로 개선하는 학습방법이다.</li>
  <li>https://brunch.co.kr/@hansungdev/21</li>
</ul>

<h2 id="transformer란"><strong>transformer란?</strong></h2>

<ul>
  <li>자연어(글자, 말, 사람이 사용하는 문장)에서 의미(의미 벡터)를 추출하는 인공지능 모델</li>
  <li><strong>**트랜스포머 모델은 문장 속 단어와 같은 순차 데이터 내의 관계를 추적해 맥락과 의미를 학습하는 신경망이다.</strong>**</li>
  <li>용어
    <ul>
      <li>고차원 벡터 공간: 정보를 수학적으로 표현한 것
        <ul>
          <li>유사한 정보는 벡터 공간에서 가깝게 위치하며, 유사하지 않은 정보는 벡터 공간에서 멀리 위치한다.</li>
        </ul>
      </li>
      <li>임베딩: 단어나 문장을 고차원 벡터 공간에 매핑하는 것</li>
      <li>어테션 알고리즘: 문장을 임베딩 할 때, 단어의 위치, 순서, 빈도 등을 고려하여 문장의 정보를 수치화하는 알고리즘</li>
    </ul>
  </li>
  <li>https://blogs.nvidia.co.kr/2022/04/01/what-is-a-transformer-model/</li>
</ul>

<h2 id="reference">Reference</h2>
<ul>
  <li><strong>transformer를 처음 소개한 논문</strong>
    <ul>
      <li>https://arxiv.org/abs/1706.03762</li>
    </ul>
  </li>
  <li><strong>강화학습에 대한 현대적인 개념을 적립한 책</strong>
    <ul>
      <li>http://incompleteideas.net/book/the-book-2nd.html</li>
    </ul>
  </li>
  <li><strong>강화학습에서 한 동안 주로 사용되던 td-learning을 소개한 논문</strong>
    <ul>
      <li>https://www.csd.uwo.ca/~xling/cs346a/extra/tdgammon.pdf</li>
    </ul>
  </li>
  <li><strong>GPT를 소개한 논문</strong>
    <ul>
      <li>https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf</li>
    </ul>
  </li>
  <li><strong>reinforcement-learning concepts</strong>
    <ul>
      <li>https://towardsdatascience.com/reinforcement-learning-an-introduction-to-the-concepts-applications-and-code-ced6fbfd882d</li>
    </ul>
  </li>
  <li><strong>How ChatGPT actually works</strong>
    <ul>
      <li>https://www.assemblyai.com/blog/how-chatgpt-actually-works/</li>
    </ul>
  </li>
  <li><strong>**ChatGPT broke the Turing test — the race is on for new ways to assess AI</strong>**
    <ul>
      <li>https://www.nature.com/articles/d41586-023-02361-7</li>
    </ul>
  </li>
  <li><strong>GPT-4 Technical Report</strong>
    <ul>
      <li>https://arxiv.org/pdf/2303.08774.pdf</li>
    </ul>
  </li>
</ul>]]></content><author><name></name></author><category term="기타" /><summary type="html"><![CDATA[chatgpt란?]]></summary></entry><entry><title type="html">포트폴리오-부대권</title><link href="http://localhost:4000/%EA%B8%B0%ED%83%80/2023/10/03/%ED%8F%AC%ED%8A%B8%ED%8F%B4%EB%A6%AC%EC%98%A4-%EB%B6%80%EB%8C%80%EA%B6%8C.html" rel="alternate" type="text/html" title="포트폴리오-부대권" /><published>2023-10-03T00:00:00+09:00</published><updated>2023-10-03T00:00:00+09:00</updated><id>http://localhost:4000/%EA%B8%B0%ED%83%80/2023/10/03/%ED%8F%AC%ED%8A%B8%ED%8F%B4%EB%A6%AC%EC%98%A4-%EB%B6%80%EB%8C%80%EA%B6%8C</id><content type="html" xml:base="http://localhost:4000/%EA%B8%B0%ED%83%80/2023/10/03/%ED%8F%AC%ED%8A%B8%ED%8F%B4%EB%A6%AC%EC%98%A4-%EB%B6%80%EB%8C%80%EA%B6%8C.html"><![CDATA[<hr />

<ul>
  <li><strong>PART1</strong>: <strong>bdg.blog - 온프레미스 블로그 서비스</strong>
    <ul>
      <li>온프레미스 CI/CD 파이프라인 개발</li>
      <li>블로그 포스팅 서비스 bdg.blog 개발 (프론트앤드&amp;백앤드)</li>
    </ul>
  </li>
  <li><strong>PART2:</strong>  <strong>유지엘소프트 (도시과학 빅데이터 AI연구원 파견근무)</strong>
    <ul>
      <li>분산 파일시스템(glusterfs) 도입 및 <strong>성능 실험</strong></li>
      <li>slurm job컨테이너화</li>
      <li>사용자의 자원 사용률 모니터링 웹서비스 개발 (프론트앤드&amp;백앤드)</li>
      <li>다이나믹 리버스 프록시 서버 개발 및 성능 실험</li>
    </ul>
  </li>
</ul>

<hr />

<h1 id="part1-bdgblog---온프레미스-블로그-서비스">PART1: bdg.blog - 온프레미스 블로그 서비스</h1>

<p>온프레미스로 쿠버네티스 위에서 동작하는 블로그 서비스입니다. 블로그 포스팅과 간단한 토이프로젝트 들을 서비스하고 있습니다.</p>

<h2 id="1-온프레미스-cicd-파이프라인-개발">1. 온프레미스 CI/CD 파이프라인 개발</h2>

<h3 id="a-link">a. Link</h3>

<ul>
  <li>Github: https://github.com/deagwon97/bdg-blog-v2/tree/main/deploy</li>
  <li>Post: <a href="https://deagwon.com/post/%EC%98%A8%ED%94%84%EB%A0%88%EB%AF%B8%EC%8A%A4-%EC%84%9C%EB%B9%84%EC%8A%A4-%EA%B0%9C%EB%B0%9C-%EB%B0%8F-%EC%9A%B4%EC%98%81-%EA%B8%B0%EB%A1%9D-%EA%B0%9C%EB%B0%9C-%EB%8F%99%EA%B8%B0-%EB%94%94%EB%B0%94%EC%9D%B4%EC%8A%A4-%EA%B5%AC%EC%84%B1-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0-%EA%B5%AC%EC%84%B1-%ED%98%95%EC%83%81-%EA%B4%80%EB%A6%AC">https://deagwon.com/post/온프레미스-서비스-개발-및-운영-기록-개발-동기-디바이스-구성-클러스터-구성-형상-관리</a></li>
</ul>

<p><img alt="image" src="/images/78e03093-7919-47b9-9d49-14efc88fb13d" /></p>

<h3 id="b-클러스터-구조">b. 클러스터 구조</h3>

<p><img alt="image" src="/images/df3e466f-32e6-4aef-a52a-6e879e412516" /></p>

<p>클러스터에는 다양한 서비스들이 공존하며, 네임스페이스를 통해 구분됩니다. 앱의 소스 코드 및 배포를 위한 명세 파일은 하나의 GitHub 레포지토리에서 관리됩니다.</p>

<ul>
  <li>검은색 화살표:  소스코드를 Git에 push하면서 발생하는 자동 배포 과정</li>
  <li>주황색 화살표: ArgoCD를 활용한 Continuous Delivery</li>
  <li>파란색 화살표: Ingress 컨트롤러인 traefik이 외부에서 들어오는 요청을 중계하는 과정</li>
</ul>

<h3 id="d-마주했던-문제점-1---cluster-scope-중복-정의">d. 마주했던 문제점 1 - Cluster Scope 중복 정의</h3>

<ul>
  <li>문제점
    <ul>
      <li>Cluster Scope를 고려하지 않고, 여러 Namespace에서 Argo Workflows, Argo Events, Argo CD를 설치</li>
      <li>서로다른 namespace에서 Argo 설정이 충돌하는 상황 발생</li>
    </ul>
  </li>
  <li>해결
    <ul>
      <li>Cluster Scope에서 동작하는 자원들은 프로젝트와는 별도로 설치</li>
      <li>namespace 범위에서 동작하는 자원들만 프로젝트에 따라 추가하는 방식으로 분할</li>
    </ul>
  </li>
</ul>

<h3 id="e-마주했던-문제점-2---harbor의-helm-charts를-그대로-사용하면서-원하는-자원을-추가할-수-있을까">e. 마주했던 문제점 2 - Harbor의 Helm Charts를 그대로 사용하면서 원하는 자원을 추가할 수 있을까?</h3>

<ul>
  <li>문제점
    <ul>
      <li>Helm Chart를 통해서 Harbor를 설치할 경우, values.yaml 이외의 다른 자원을 추가할 수 없음</li>
      <li>새롭게 Helm Chart를 구성하는 것도 방법이지만, 나중에 Harbor 버전이 업데이트 될 때, 관리 포인트가 증가하는 문제가 존재</li>
    </ul>
  </li>
  <li>해결책
    <ul>
      <li>Helm과 kustomization을 결합하하여 문제를 해결</li>
    </ul>
  </li>
</ul>

<h2 id="2-블로그-포스팅-서비스-bdgblog-개발">2. 블로그 포스팅 서비스 bdg.blog 개발</h2>

<h3 id="a-link-1">a. Link</h3>

<ul>
  <li>Github: https://github.com/deagwon97/bdg-blog-v2/tree/main/src</li>
  <li>Post: <a href="https://deagwon.com/post/bdg-blog%EB%A5%BC-%EB%A7%8C%EB%93%A4%EB%A9%B4%EC%84%9C-%EB%93%A4%EC%97%88%EB%8D%98-%EA%B3%A0%EB%AF%BC%EA%B3%BC-%ED%95%B4%EA%B2%B0-%EB%B0%A9%EB%B2%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8-%EA%B5%AC%EC%A1%B0-%EC%82%AC%EC%9A%A9%ED%95%9C-%EB%8F%84%EA%B5%AC-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%B0%A9%EB%B2%95-%EA%B0%9C%EB%B0%9C-%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%B6%95">https://deagwon.com/post/bdg-blog를-만들면서-들었던-고민과-해결-방법-프로그램-구조-사용한-도구-테스트-방법-개발-환경-구축</a></li>
</ul>

<h3 id="b-프로그램-구조">b. 프로그램 구조</h3>

<p>프로그램의 가장 중요한 요소가 ‘요구사항을 만족하는 동작을 수행하는 것’ 이라면, 두 번째로 중요한 요소는 기능 확장성과 유지 보수성입니다. 저는 이 두가지 요소를 만족하는 서비스를 만들기 위해 다음과 같은 구조로 서비스를 만들었습니다.</p>

<p><img alt="image" src="/images/c48c62a4-d874-4ce8-8144-6afec6aaed12" /></p>

<h3 id="c-마주했던-문제점-1---테스트-코드가-db에-영향을-주는-문제">c. 마주했던 문제점 1 - 테스트 코드가 DB에 영향을 주는 문제</h3>

<ul>
  <li>문제점
    <ul>
      <li>처음 테스트 코드를 작성했을 때 DB에 직접적으로 값을 추가했다가 지우는 방식으로 테스트 코드를 작성함</li>
      <li>실제 배포되고 있는 서버에 테스트 내용이 순간적으로 반영되는 문제 발생</li>
    </ul>
  </li>
  <li>해결책
    <ul>
      <li>db transaction 을 활용하여, 테스트를 수행한 후 테스트가 성공하면 rollback하여 실제로 db에는 영향을 주지 않도록 구현</li>
    </ul>
  </li>
</ul>

<h3 id="d-마주했던-문제점-2---개발-환경과-배포-환경의-불일치">d. 마주했던 문제점 2 - 개발 환경과 배포 환경의 불일치</h3>

<ul>
  <li>배경
    <ul>
      <li>초기에는 컨테이너 없이 개발한 후 배포용 컨테이너를 만들고 배포</li>
    </ul>
  </li>
  <li>문제점
    <ul>
      <li>개발, 빌드, 배포 환경이 모두 달라 로컬에서 잘 빌드되는 코드도 실제 배포 환경에서는 빌드하지 못하는 문제 발생</li>
      <li>단순히 빌드 - 개발 - 배포를 하나의 컨테이너로 수행하면, 배포 시점에는 필요하지 않은 소스 코드나 프로그램이 포함되어, 배포 비용이 증가</li>
    </ul>
  </li>
  <li>해결
    <ul>
      <li>
        <p>VS Code의 devcontainer 사용하여 개발 - 빌드 환경 통일</p>

        <p>VS Code의 devcontainer를 활용하면 VScode editor가 컨테이너에 원격으로 접속하여 개발할 수 있었습니다. 이를 통해서 이미지를 빌드하는 환경과 개발 환경을 일치시켰습니다.</p>
      </li>
      <li>
        <p>Docker의 Multi Stage Build 사용하여 배포할 때 불필요한 파일 제거</p>

        <p>실제 배포 시에는 사용하지 않는 소스 코드와 프로그램을 제거하여 배포되는 컨테이너의 크기를 크게 줄일 수 있었습니다.</p>
      </li>
    </ul>
  </li>
</ul>

<h1 id="part2-유지엘소프트도시과학-빅데이터-ai연구원-파견근무">PART2: 유지엘소프트(도시과학 빅데이터 AI연구원 파견근무)</h1>

<h2 id="1-도시과학-빅데이터-ai연구원ubai란">1. 도시과학 빅데이터 AI연구원(UBAI)란?</h2>

<p>UBAI는 서울시립대학교 내에 위치하며, HPC 클러스터를 보유한 기관입니다. 교내외 연구원에게 고성능컴퓨팅 자원과 사용환경을 제공하고 있습니다. 저는 2022년 8월부터 지금까지 유지엘소프트에서 파트타임으로 근무하며 파견 형식으로 UBAI의 업무를 수행하고 있습니다. UBAI에서는 사용자 계정 관리, 시스템 문제 해결, 웹 어플리케이션(MyUBAI) 개발 등 다양한 업무를 수행합니다.</p>

<ul>
  <li>클러스터 스팩
    <ul>
      <li>CPU: Intel Xeon Gold 6240R 2.4GHz 48 cores, 6348R 2.6GHz 56 cores</li>
      <li>MEM: 768GB ~ 1024GB</li>
      <li>GPU: NVIDIA A100, NVIDIA RTX3090, NVIDIA A10</li>
    </ul>
  </li>
  <li>SLURM
    <ul>
      <li>SLURM(Simple Linux Utility for Resource Management)</li>
      <li>HPC(고성능 컴퓨팅) 클러스터에서 작업 스케줄링과 자원 관리를 위해 사용되는 오픈 소스의 자원 관리 시스템</li>
      <li>UBAI는 사용자에게 Linux 계정을 발급해 준 후, SLURM을 통해서 작업을 수행하는 방식으로 사용 클러스터를 사용</li>
    </ul>
  </li>
</ul>

<h2 id="2-분산-파일시스템glusterfs-도입-및-성능-실험">2. 분산 파일시스템(glusterfs) 도입 및 성능 실험</h2>

<ul>
  <li>소스코드: https://github.com/deagwon97/glusterfs-performance</li>
  <li>포스트: <a href="https://deagwon.com/post/NFS%EC%97%90%EC%84%9C-%EB%B6%84%EC%82%B0-%ED%8C%8C%EC%9D%BC-%EC%8B%9C%EC%8A%A4%ED%85%9C-Glusterfs%EB%A1%9C-%EC%A0%84%ED%99%98">https://deagwon.com/post/NFS에서-분산-파일-시스템-Glusterfs로-전환</a></li>
</ul>

<h3 id="a-배경">a. 배경</h3>

<p>기존의 파일시스템은 모든 Client 노드가 하나의 물리적 볼륨을 공유하는 NFS 를 사용하고 있었습니다. NFS에 연결된 노드 수와 사용량이 증가하면서 NFS I/O 속도가 감소하고, 메타 데이터가 충돌하는 등 여러 문제가 발생했습니다. 여러 분산 파일 시스템을 조사한 후 glusterfs를 도입하기로 결정했습니다. 하지만 glusterfs에서도 다양한 조합이 존재했고, 최적의 조합을 결정하기 위해 실험을 진행했습니다.</p>

<h3 id="b-실험을-통한-의사결정---최적의-glusterfs-조합-결정">b. 실험을 통한 의사결정 - 최적의 glusterfs 조합 결정</h3>

<p>4가지 조합에 대해, 단일파일과 다중 파일의 입출력 속도를 측정했습니다.</p>

<ul>
  <li>Distributed 8</li>
  <li>Disperse 8 (Redundancy 2)</li>
  <li>Distributed 4 Replicated 2</li>
  <li>Distributed 2 Disperse 4 (Redundancy 1)</li>
</ul>

<p>최대 2개의 볼륨이 고장 나더라도 모든 데이터를 복원할 수 있으며, 전체 하드디스크 용량의 75 %를 사용할 수 있는 조합 중, 가장 선능이 우수한  distributed 2, dispersed 4, redundancy 1 조합을 사용하기로 결정했습니다.</p>

<h3 id="c-마주했던-문제점---다중-파일-동시-입출력-구현">c. 마주했던 문제점 - 다중 파일 동시 입출력 구현</h3>

<ul>
  <li>배경
    <ul>
      <li>동시 파일 I/O 작업을 위해서 linux background process (&amp;) 사용</li>
    </ul>
  </li>
  <li>문제점
    <ul>
      <li>subprocess를 생성하는 overhead가 한 파일을 쓰는 속도와 유사하여 대역폭 측정이 불가능</li>
    </ul>
  </li>
  <li>해결책
    <ul>
      <li>Named Pipe (FIFO) 를 사용하여 subprocess를 생성하는 overhead를 94% 감소 시키고 유의미한 실험 결과를 얻음</li>
    </ul>
  </li>
</ul>

<h2 id="3-slrum-job-컨테이너-enroot-도입">3. SLRUM Job 컨테이너 enroot 도입</h2>

<h3 id="a-소개">a. 소개</h3>

<p>Slurm은 쿠버네티스나 도커와 같은 일반적인 컨테이너 도구를 지원하지 않습니다. 환경은 Linux Environment Modules을 통해서 구성하고 사용했었지만, 많은 문제점들이 있었습니다. 이를 해결하기위해 반쪽짜리 컨테이너 enroot를 도입했습니다.</p>

<ul>
  <li>포스트: <a href="https://deagwon.com/post/HPC-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0%EC%97%90-%EB%B0%98%EC%AA%BD-%EC%A7%9C%EB%A6%AC-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-enroot-%EB%A5%BC-%EC%A0%81%EC%9A%A9%ED%95%98%EB%A9%B0-%EB%B0%B0%EC%9A%B4-%EA%B2%83%EB%93%A4">https://deagwon.com/post/HPC-클러스터에-반쪽-짜리-컨테이너-enroot-를-적용하며-배운-것들</a></li>
</ul>

<h3 id="b-마주했던-문제점--pxe-boot">b. 마주했던 문제점 – pxe boot</h3>

<ul>
  <li>문제점
    <ul>
      <li>grubby를 사용한 kernel command line 수정이 안 됨</li>
    </ul>
  </li>
  <li>원인
    <ul>
      <li>HPC 클러스터는 PXE boot 방식을 통해서 부팅함</li>
    </ul>
  </li>
  <li>해결책
    <ul>
      <li>PXE 서버에서 노드별 부팅 설정파일에 kernel command line을 추가하여 해결</li>
    </ul>
  </li>
</ul>

<h2 id="4-사용자의-자원-사용률-모니터링-웹서비스-개발-프론트앤드백앤드">4. 사용자의 자원 사용률 모니터링 웹서비스 개발 (프론트앤드&amp;백앤드)</h2>

<h3 id="a-소개-1">a. 소개</h3>

<p>사용자가 제출한 slurm job의 실제 사용량을 기록하고, 조회하는 어플리케이션 입니다.</p>

<ul>
  <li>사이트 링크: https://myubai.uos.ac.kr/main</li>
</ul>

<p><img alt="image" src="/images/e4dbdab8-361c-4b8f-b64e-3e589f74929e" /></p>

<h3 id="a-개발-동기">a. 개발 동기</h3>

<p>대부분의 모니터링 프로그램은, 컨테이너 혹은 노드 단위의 자원 사용량을 수집하거나, 고정된 PID를 갖는 프로세스의 사용량만 추적할 수 있었습니다. 실시간으로 생성되고 종료되는 프로세스를 UID별로 수집하고 집계하면서도 시스템 부하를 최소화하는 사용률 집계 프로그램이 필요했습니다.</p>

<h3 id="b-사용한-도구">b. 사용한 도구</h3>

<ul>
  <li>mariadb, python api server, linux crontab, ssh, shell script</li>
</ul>

<h3 id="c-동작-방식">c. 동작 방식</h3>

<p><img alt="image" src="/images/f1042196-aef0-4f55-b905-9fddd7afe1d5" /></p>

<ol>
  <li>5분 간격으로 master node에서 100개의 노드에 ssh로 접근하여 프로세스별 자원 사용률을 측정합니다. (linux top command, nvidia pmon command)</li>
  <li>측정된 정보를 파싱하여 다시 master node에서 동작하는 python api server에 Post Call하면 서버는 입력받은 raw 데이터를 Maria DB에 저장합니다.</li>
  <li>사용자가 조회하는 비용을 줄이기 위해 1시간 간격으로 raw 데이터를 가공하여 다시 processed 테이블에 저장합니다.</li>
  <li>외부에서 접속 가능한 노드에 MyUBAI(웹 어플리케이션)를 배포하고, 사용자는 MyUBAI를 통해 자신의 사용률을 실시간으로 조회합니다.</li>
</ol>

<h3 id="d-마주했던-문제">d. 마주했던 문제</h3>

<ul>
  <li>배경
    <ul>
      <li>초기에는MyUBAI의 백앤드 서버가 Raw 데이터 테이블에 직접 접근하여 사용률을 집계함</li>
      <li>Raw 데이터 테이블의 인덱스가 적절하게 설정되지 않음</li>
    </ul>
  </li>
  <li>문제점
    <ul>
      <li>인덱스가 적절하게 설정되지 않아, 조회 시간 30s 이상 소요</li>
      <li>인덱스를 최적화 하더라도 조회 시간 1.7s이상 소요</li>
    </ul>
  </li>
  <li>해결
    <ul>
      <li>1시간 간격으로 raw 데이터를 가공하여 processed 테이블에 다시 저장하는 스크립트를 작성</li>
      <li>MyUBAI의 백앤드 서버는 processed 테이블을 조회하는 방식으로 수정하여 조회 속도를 다시 <strong>46ms로 단축</strong></li>
    </ul>
  </li>
</ul>

<h2 id="3-다이나믹-리버스-프록시-서버-개발-및-성능-실험">3. 다이나믹 리버스 프록시 서버 개발 및 성능 실험</h2>

<ul>
  <li>소스코드: https://github.com/deagwon97/subdomain-tcp-proxy</li>
  <li>포스트: <a href="https://deagwon.com/post/subdomain-%EA%B8%B0%EB%B0%98-%EB%8B%A4%EC%9D%B4%EB%82%98%EB%AF%B9-%EB%A6%AC%EB%B2%84%EC%8A%A4-%ED%94%84%EB%A1%9D%EC%8B%9C-%EC%84%9C%EB%B2%84-%EA%B0%9C%EB%B0%9C-%EB%B0%8F-%EC%84%B1%EB%8A%A5-%EB%B9%84%EA%B5%90">https://deagwon.com/post/subdomain-기반-다이나믹-리버스-프록시-서버-개발-및-성능-비교</a></li>
</ul>

<h3 id="a-소개-2">a. 소개</h3>

<p>UBAI를 통해서 연구하시는 분 중에는 Linux 및 환경 구축에 미숙한 분들도 계십니다. 이분들을 대상으로 사용자 교육 및 화상 지원을 진행했지만, 저 혼자 이 많은 분들을 모두 감당하는 것은 한계가 있었습니다. 이론적으로 외부접속이 가능한 노드에 동적 터널링 서버를 개발한다면, 사용자가 Web UI를 통해서 손쉽게 연구 환경을 구성하고, 연구를 진행할 수 있다고 판단하여 개발을 시작했습니다.</p>

<h3 id="b-실험을-통한-의사결정---다이나믹-리버스-프록시-서버의-개발-언어-선택-nodejs-vs-golang">b. 실험을 통한 의사결정 - 다이나믹 리버스 프록시 서버의 개발 언어 선택 Node.js vs golang</h3>

<ul>
  <li>배경
    <ul>
      <li>목적지의 ip, port가 동적으로 바뀌면 이를 실시간으로 포워딩하는 프로그램이 필요</li>
      <li>Node.js는 높은 동시성을 지원하며, I/O 작업에서 효율적</li>
      <li>golang은 고루틴(Goroutines)을 통해 간단하면서도 효과적인 동시성 프로그래밍이 가능하면서 컴파일 언어로 빠른 실행 속도를 제공함.</li>
      <li>두 언어 중 적합한 언어를 선택해야 함</li>
    </ul>
  </li>
  <li>실험 결과 비교
    <ul>
      <li>성능 비교
        <ul>
          <li>일부 조건에서는 Go가 Node.js보다 2~3배 빠르게 동작했지만, 대부분의 상황에서 유사한 성능을 보임</li>
        </ul>
      </li>
      <li>안정성 비교
        <ul>
          <li>Go: 서로 다른 5000개의 tcp connection을 안정적으로 유지함</li>
          <li>Node.js: tcp connection 수가 4000개를 넘어서면서 오류가 발생함</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>결론적으로 Go와 Node.js의 성능은 큰 차이가 없었습니다. 다만, 안정성 측면에서 Go가 Nod.js 보다 우수한 결과를 보여주었고, 처음 만들었던 Node.js 기반 중계 서버가 아닌 Go를 사용하기로 결정했습니다.</p>]]></content><author><name></name></author><category term="기타" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">이력서-부대권</title><link href="http://localhost:4000/%EA%B8%B0%ED%83%80/2023/10/02/%EC%9D%B4%EB%A0%A5%EC%84%9C-%EB%B6%80%EB%8C%80%EA%B6%8C.html" rel="alternate" type="text/html" title="이력서-부대권" /><published>2023-10-02T00:00:00+09:00</published><updated>2023-10-02T00:00:00+09:00</updated><id>http://localhost:4000/%EA%B8%B0%ED%83%80/2023/10/02/%EC%9D%B4%EB%A0%A5%EC%84%9C-%EB%B6%80%EB%8C%80%EA%B6%8C</id><content type="html" xml:base="http://localhost:4000/%EA%B8%B0%ED%83%80/2023/10/02/%EC%9D%B4%EB%A0%A5%EC%84%9C-%EB%B6%80%EB%8C%80%EA%B6%8C.html"><![CDATA[<h2 id="소개">소개</h2>

<blockquote>
  <p><strong>효율적인 시스템을 만들기 위해 고민하는 개발자 부대권입니다.</strong></p>
</blockquote>

<ul>
  <li>이메일: azaz09112@gmail.com</li>
  <li>깃허브: https://github.com/deagwon97</li>
  <li>블로그: https://deagwon.com</li>
</ul>

<h3 id="핵심역량">[핵심역량]</h3>

<ul>
  <li><strong>실험을 통해 성능을 평가하고 의사결정하는 능력</strong></li>
  <li><strong>온프레미스 쿠버네티스 클러스터 구축하고 운영하는 능력</strong></li>
  <li><strong>리눅스의 이해를 바탕으로한 시스템 프로그램 개발 능력</strong></li>
  <li><strong>프론트앤드&amp;백앤드 개발 능력</strong></li>
  <li><strong>클린 코드와 클린 아키텍처에 대한 이해</strong></li>
</ul>

<h3 id="학력">[학력]</h3>

<ul>
  <li>서울시립대학교 전자전기컴퓨터공학부 재학 중</li>
  <li>2024년 2월 졸업예정</li>
</ul>

<h3 id="개인-프로젝트---온프레미스-블로그-서비스">[개인 프로젝트] -  온프레미스 블로그 서비스</h3>

<ul>
  <li>온프레미스 CI/CD 파이프라인 개발</li>
  <li>블로그 포스팅 서비스 bdg.blog 개발 (프론트앤드&amp;백앤드)</li>
</ul>

<h3 id="파트타임---유지엘소프트-도시과학-빅데이터-ai연구원-파견근무">[파트타임] - 유지엘소프트 (도시과학 빅데이터 AI연구원 파견근무)</h3>

<ul>
  <li>[2022.08 ~ ]</li>
  <li>분산파일 시스템 도입 [2023.07 - 2023.08]
    <ul>
      <li>HPC 클러스터에서 사용되는 스토리지 서버를 NFS에서 Glusterfs로 전환</li>
      <li>실험을 통한 분산 파일시스템 성능 평가</li>
    </ul>
  </li>
  <li>slurm job컨테이너화 [2022.10 - 2022.11]
    <ul>
      <li>slurm Job 컨테이너 enroot 도입</li>
    </ul>
  </li>
  <li>MyUBAI 개발 [2022.10 - 2023.08]
    <ul>
      <li>사용자의 자원 사용률 모니터링 웹서비스 개발 (프론트앤드&amp;백앤드)</li>
      <li>다이나믹 리버스 프록시 서버 개발 및 성능 실험</li>
    </ul>
  </li>
</ul>

<h3 id="인턴---서울-시립대학교-고성능-인공시능-시스템-연구실">[인턴] - 서울 시립대학교 고성능 인공시능 시스템 연구실</h3>

<ul>
  <li>[2022.08 ~ 2023.06]</li>
  <li>이기종 GPU를 활용한 분산학습환경 구성 [2022.12 - 2023.06]
    <ul>
      <li>204개의 GPU를 이용하여 하나의 거대 인공지능 모델(Megatron-LM)을 학습할 수 있는 환경 구축 및 실험 스크립트 자성</li>
    </ul>
  </li>
  <li>ToxAI 개발 및 배포[2022.10 - 2022.12]
    <ul>
      <li>TorchServe를 활용한 인공지능 추론 모델 배포</li>
    </ul>
  </li>
</ul>

<h3 id="기술스택">[기술스택]</h3>

<ul>
  <li>K3s
    <ul>
      <li>온프레미스 환경으로 클러스터를 구축하고 운영 중
        <ul>
          <li>개인블로그 App, Harbor(Container Registry), Minio(Object File Storage), MariaDB(Database), Redis(Message Broker), Argo CD(CD tool), ArgoWorkflow&amp;ArgoEvents(CI tools)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Docker
    <ul>
      <li>대부분의 프로젝트 개발환경 및 배포환경을 도커라이징하여 사용</li>
      <li>배포를 위한 최적의 컨테이너를 만들기위해 노력</li>
    </ul>
  </li>
  <li>VScode &amp; devcontainer
    <ul>
      <li>VScode의 devcontainer를 활용하여 가상 개발환경을 구축하고 사용</li>
    </ul>
  </li>
  <li>Slurm
    <ul>
      <li>204개 GPU, 100대 노드 규모의 HPC 클러스터를 관리 중</li>
    </ul>
  </li>
  <li>Python
    <ul>
      <li>인공지능 프로젝트 및 Backend API 개발에서 주로 사용함</li>
    </ul>
  </li>
  <li>JavaScript/TypeScript
    <ul>
      <li>React 와 Next.js를 활용한 웹서비스 개발</li>
    </ul>
  </li>
  <li>GoLang
    <ul>
      <li>Backend API 개발</li>
      <li>Dynamic Reverse Proxy 서버 개발 및 성능 실험</li>
    </ul>
  </li>
  <li>MariaDB
    <ul>
      <li>인덱스 방법을 최적화하여 쿼리 조회 속도를 개선한 경험</li>
    </ul>
  </li>
</ul>]]></content><author><name></name></author><category term="기타" /><summary type="html"><![CDATA[소개]]></summary></entry><entry><title type="html">subdomain 기반 다이나믹 리버스 프록시 서버 개발 및 성능 비교</title><link href="http://localhost:4000/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC/2023/09/30/subdomain-%EA%B8%B0%EB%B0%98-%EB%8B%A4%EC%9D%B4%EB%82%98%EB%AF%B9-%EB%A6%AC%EB%B2%84%EC%8A%A4-%ED%94%84%EB%A1%9D%EC%8B%9C-%EC%84%9C%EB%B2%84-%EA%B0%9C%EB%B0%9C-%EB%B0%8F-%EC%84%B1%EB%8A%A5-%EB%B9%84%EA%B5%90.html" rel="alternate" type="text/html" title="subdomain 기반 다이나믹 리버스 프록시 서버 개발 및 성능 비교" /><published>2023-09-30T00:00:00+09:00</published><updated>2023-09-30T00:00:00+09:00</updated><id>http://localhost:4000/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC/2023/09/30/subdomain-%EA%B8%B0%EB%B0%98-%EB%8B%A4%EC%9D%B4%EB%82%98%EB%AF%B9-%EB%A6%AC%EB%B2%84%EC%8A%A4-%ED%94%84%EB%A1%9D%EC%8B%9C-%EC%84%9C%EB%B2%84-%EA%B0%9C%EB%B0%9C-%EB%B0%8F-%EC%84%B1%EB%8A%A5-%EB%B9%84%EA%B5%90</id><content type="html" xml:base="http://localhost:4000/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC/2023/09/30/subdomain-%EA%B8%B0%EB%B0%98-%EB%8B%A4%EC%9D%B4%EB%82%98%EB%AF%B9-%EB%A6%AC%EB%B2%84%EC%8A%A4-%ED%94%84%EB%A1%9D%EC%8B%9C-%EC%84%9C%EB%B2%84-%EA%B0%9C%EB%B0%9C-%EB%B0%8F-%EC%84%B1%EB%8A%A5-%EB%B9%84%EA%B5%90.html"><![CDATA[<p>subdomain 기반으로 목적지 서버를 식별하여 사용자를 중계해주는 다이나믹 리버스 프록시 서버를 개발했습니다.  처음 개발할 때는 <code class="highlighter-rouge">nodejs</code> 로 중계 서버를 만들었습니다. 하지만 생각보다 성능이 높지 않았고, <code class="highlighter-rouge">golang</code> 를 통해서 중계 서버를 만든다면 성능상 어떤 차이가 있을지 확인해보고 싶어 이 실험을 계획했습니다.</p>

<h1 id="배경-설명">배경 설명</h1>

<ul>
  <li>
    <p>리버스 프록시 서버란?</p>

    <p>리버스 프록시 서버는 클라이언트와 웹 서버(또는 여러 웹 서버) 사이에 위치하여 클라이언트의 요청을 대신 받아 웹 서버에 전달하고, 웹 서버의 응답을 다시 클라이언트에게 전달하는 중개자의 역할을 합니다.</p>
  </li>
  <li>
    <p>다이나믹 리버스 프록시 서버란?</p>

    <p>일반적인 용어는 아닙니다. 보통 Nginx, Traefik 과 같은 웹서버들은 정적인 설정을 지원합니다.  저는 클라이언트의 reqeust http header에서 subdomain을 파싱하여 목적지를 결정하는 중계 서버를 만들었고, 여기서는 이를 다이나믹 리버스 프록시 서버라고 부르겠습니다.</p>
  </li>
</ul>

<p>가장 단순한 동작은 아래와 같이 Client가 리버스 프록시 서버(중계 서버)로 요청을 보내면, 중계 서버는 요청의 header를 보고 적절한 서버로 데이터을 전달하는 것입니다. 이후 서버로부터 응답이 돌아오면 클라이언트에게 그대로 응답을 전달합니다.</p>

<p><img alt="image" src="/images/5db38129-4a48-4d9e-8fce-9fc1cff28f1a" /></p>

<p>실제로 https 요청을 보내면, 중계 서버는 client-중계서버 사이의 TCP connection을 생성하고, 중계서버-server 사이에도 TCP connection을 연결합니다. 두 connection이 모두 유효하다면 서버와 클라이언트는 모든 TCP packet을 주고받을 수 있습니다.</p>

<p><img alt="image" src="/images/b647d01a-20a7-4f47-a5fc-dc54d58d93cd" /></p>

<p>이번에는 클라이언트가 여러 개인 상황을 가정해 보겠습니다. 실제로 많은 웹 페이지들이 여러 개의  port를 통해 서버에 비동기로 데이터를 요청합니다. 이때 중계 서버는 (클라이언트-중계서버)를 연결하는 웹소켓, (중계서버-서버)을 연결하는 웹소켓을 한쌍으로 하여 각 소켓에서 들어오는 패킷을 적절히 중계해야합니다.</p>

<p><img alt="image" src="/images/62aa5f73-45e5-4dc5-8b94-8d9dc9bd15c9" /></p>

<p>또한 서로 다른 Client가 다른 서버로  연결될 수도 있습니다.</p>

<p><img alt="image" src="/images/e5f894e4-7928-4432-8fb4-4bb9afb367f5" /></p>

<p>위 상황들을 종합하면 아래와 같은 그림이 나옵니다. 서로 다른 클라이언트들이 각기 다른 서버로 연결되면서, 중계 서버는 클라이언트와 서버를 식별하여, 일치하는 곳으로 데이터를 전달해야합니다.</p>

<p><img alt="image" src="/images/d7d08003-93df-4fb4-b599-5d23625769b9" /></p>

<h1 id="실험-환경">실험 환경</h1>

<p>실험은 고성능 CPU(Intel Xeon Gold 6240R)에서 진행했습니다. 메모리 또한 756GB로 매우 충분해서 하드웨어 제약을 받지 않고 실험할 수 있었습니다. 중계 서버 및 실험 코드는 하나의 도커 컨테이너에서 진행했습니다. 따라서 실제 네트워크 트래픽을 고려하지는 않았습니다. 각 중계 서버가 서브도메인을 해석하여 TCP 연결을 형성하고 데이터를 주고 받는데 걸리는 시간을 측정했습니다.</p>

<ul>
  <li>OS: Centos7</li>
  <li>CPU: Intel Xeon Gold 6240R 2.4GHz 48 cores</li>
  <li>RAM: 756GB</li>
</ul>

<h1 id="실험-코드">실험 코드</h1>

<p>실험에 사용된 코드는 아래 github에 올라가 있고, dockerfile 및 devcontainer.json 파일을 가지고 있어, vscode를 통해서 환경을 손쉽게 구축하고 실험을 재현할 수 있습니다.</p>

<ul>
  <li>https://github.com/deagwon97/subdomain-tcp-proxy</li>
</ul>

<p>프로젝트는 총 3개의 파트로 나뉩니다.</p>

<ul>
  <li>Dynamic Reverse Proxy Server 구현 - Go
    <ul>
      <li>/subdomain-tcp-proxy/proxy-go</li>
      <li>go로 동작하는 중계 서버입니다.</li>
    </ul>
  </li>
  <li>Dynamic Reverse Proxy Server 구현 - Node.js
    <ul>
      <li>/subdomain-tcp-proxy/proxy-nodejs</li>
      <li>node.js로 동작하는 중계 서버입니다. typescript로 작성되었고, webpack으로 빌드했습니다.</li>
    </ul>
  </li>
  <li>proxy-test
    <ul>
      <li>/subdomain-tcp-proxy/proxy-test</li>
      <li>실험을 위한 코드입니다. go와 bash 스크립트로 작성했습니다. 테스트를 위해서 만든 서버는 간단한 웹소켓 서버입니다. 요청이 들어오면 들어온 요청을 그대로 반환합니다.</li>
    </ul>
  </li>
</ul>

<h2 id="테스트-코드">테스트 코드</h2>

<p>아래는 테스트코드의 로직을 보여주는 수도 코드입니다. 먼저 중계 서버를 실행하고, 주어진 수 만큼 목적지 서버를 go routine으로 실행합니다. 서버가 실행될 때까지 기다렸다가, NUM_OF_SERVER * NUM_OF_CLIENT 만큼 클라이언트를 만들어 각 클라이언트 마다 NUM_REPEAT 회 데이터를 전송합니다. 모든 데이터를 보내고 받는데 까지 걸리는 시간을 측정해서, 각 중계 서버마다 성능을 비교했습니다.</p>

<div class="language-go highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">중계_서버_실행</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span> <span class="o">:=</span> <span class="k">range</span> <span class="n">NUM_OF_SERVER</span> <span class="p">{</span>
    <span class="n">app_host</span> <span class="o">:=</span> <span class="s">"0.0.0.0:app포트"</span>
    <span class="n">암호화된_문자열</span> <span class="o">=</span> <span class="n">암호화</span><span class="p">(</span><span class="s">"app-host"</span><span class="p">)</span>
    <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">hosts</span> <span class="n">파일에</span> <span class="s">"0.0.0.0   암호화된_문자열.service.com:중계서버포트"</span> <span class="n">문장</span> <span class="n">추가</span>
    <span class="p">(</span><span class="n">비동기</span> <span class="n">동작</span><span class="p">)</span> <span class="p">{</span>
       <span class="n">서버</span> <span class="s">"app-host"</span> <span class="n">실행</span>
    <span class="p">}</span>
<span class="p">}</span>
    
<span class="n">모든_서버가_실행될_때까지_대기</span><span class="p">()</span>

<span class="n">시작시간</span> <span class="o">:=</span> <span class="n">now</span><span class="p">()</span>

<span class="k">for</span>  <span class="n">i</span> <span class="o">:=</span> <span class="k">range</span> <span class="n">NUM_OF_SERVER</span> <span class="p">{</span>
    <span class="k">for</span> <span class="n">j</span><span class="o">:=</span> <span class="k">range</span> <span class="n">NUM_OF_CLIENT</span> <span class="p">{</span>
        <span class="p">(</span><span class="n">비동기</span> <span class="n">동작</span><span class="p">){</span>
            <span class="n">클라이언트</span> <span class="n">실행</span>
            <span class="k">for</span> <span class="n">k</span> <span class="o">:=</span> <span class="k">range</span> <span class="n">NUM_REPEAT</span><span class="p">{</span>
                <span class="n">중계</span> <span class="n">서버로</span> <span class="n">DATA_SIZE</span> <span class="n">만큼의</span> <span class="n">데이터</span> <span class="n">전송</span>
            <span class="p">}</span>
        <span class="p">}</span>
        <span class="n">클라이언트가</span> <span class="n">모든</span> <span class="n">응답을</span> <span class="n">받을</span> <span class="n">때</span> <span class="n">까지</span> <span class="n">대기</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="n">끝시간</span> <span class="o">:=</span> <span class="n">now</span><span class="p">()</span>

<span class="n">출력</span><span class="p">(</span><span class="n">종료시간</span> <span class="o">-</span> <span class="n">시작시간</span><span class="p">)</span>
</code></pre></div></div>

<h1 id="실험-결과">실험 결과</h1>

<p>가장 먼저 연결가능한 최대 서버 수를 측정했습니다. 서버당 클라이언트 수는 1개, 데이터 사이즈는 TCP 패킷의 최소 크기인 20 Byte 로 고정하고 서버수를 500개 부터 500개씩 증가 시키면서 7000개까지 실험했습니다.</p>

<table>
  <thead>
    <tr>
      <th>NUM_OF_CLIENT</th>
      <th>NUM_OF_REPEAT</th>
      <th>DATA_SIZE(Byte)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>1</td>
      <td>20</td>
    </tr>
  </tbody>
</table>

<h3 id="go">Go</h3>

<ul>
  <li>500 ~ 5000 구간 : 모든 데이터 교환 성공</li>
  <li>5000 ~ 5500 구간: 일부 데이터 손실</li>
  <li>6000 ~ 구간: 중계 서버 에서 오류 발생</li>
</ul>

<h3 id="nodejs">Node.js</h3>

<ul>
  <li>500 ~ 4000 구간: 모든 데이터 교환 성공</li>
  <li>4000 ~ 구간: 중계 서버에서 오류 발생</li>
</ul>

<p>서버 수가 증가할 때, Go가 Node.js에 비해서 더 안정적인 성능을 보여주고 있습니다.</p>

<h2 id="server-수에-따른-데이터-전송-시간초">SERVER 수에 따른 데이터 전송 시간(초)</h2>

<p>가장 먼저 서버당 클라이언트 수, 반복 수, 데이터 크기를 다음과 같이 고정하고 서버 수가 증가할 때 중계 서버의 성능을 비교했습니다. 서버당 클라이언트 수를 10개로 고정하고 전체 커넥션의 오류가 발생하지 않는 구간인 0 ~ 3000 개 구간에서 실험을 진행했습니다. 예를 들어 클라이언트 10개 서버 275개는 총 2750개의 connection을 형성합니다.</p>

<table>
  <thead>
    <tr>
      <th>NUM_OF_CLIENT</th>
      <th>NUM_OF_REPEAT</th>
      <th>DATA_SIZE(Byte)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>10</td>
      <td>1000</td>
      <td>1024</td>
    </tr>
  </tbody>
</table>

<p>아래 보이는 바와 같이, Go가 Node에 비해서 전반적으로 빠르게 데이터를 처리합니다.</p>

<p><img alt="image" src="/images/820eee52-83b9-4a90-b93b-55ab2ae9d79d" /></p>

<table>
  <thead>
    <tr>
      <th>NUM_OF_SERVER</th>
      <th>GO</th>
      <th>NODEJS</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>50</td>
      <td>1.814738</td>
      <td>3.191617</td>
    </tr>
    <tr>
      <td>75</td>
      <td>2.645334</td>
      <td>3.505688</td>
    </tr>
    <tr>
      <td>100</td>
      <td>3.541519</td>
      <td>3.379056</td>
    </tr>
    <tr>
      <td>125</td>
      <td>3.936755</td>
      <td>4.525397</td>
    </tr>
    <tr>
      <td>150</td>
      <td>5.129159</td>
      <td>6.366753</td>
    </tr>
    <tr>
      <td>175</td>
      <td>5.92851</td>
      <td>7.470977</td>
    </tr>
    <tr>
      <td>200</td>
      <td>6.180126</td>
      <td>8.649865</td>
    </tr>
    <tr>
      <td>225</td>
      <td>6.911448</td>
      <td>8.355023</td>
    </tr>
    <tr>
      <td>250</td>
      <td>7.897144</td>
      <td>9.623627</td>
    </tr>
    <tr>
      <td>275</td>
      <td>7.972524</td>
      <td>7.972524</td>
    </tr>
  </tbody>
</table>

<h2 id="client-수에-따른-데이터-전송-시간초">CLIENT 수에 따른 데이터 전송 시간(초)</h2>

<p>두번째는 다음과 같이 서버 수, 반복 수, 데이터 크기를 고정하고 클라이언트 수가 증가할 때, 성능 비교입니다.</p>

<table>
  <thead>
    <tr>
      <th>NUM_OF_SERVER</th>
      <th>NUM_OF_REPEAT</th>
      <th>DATA_SIZE(Byte)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>10</td>
      <td>1000</td>
      <td>1024</td>
    </tr>
  </tbody>
</table>

<p>서버 수를 늘렸을 때와 동일하게, Go가 Node.js 보다 근소하게 높은 성능을 보입니다. 특히, 클라이언트 수가 250개 ~ 275개 구간에서는 Go가 두배 이상 빠른 처리속도를 보여주고 있습니다.</p>

<p><img alt="image" src="/images/da233158-9f08-438e-a1f7-48fa3a7d172f" /></p>

<table>
  <thead>
    <tr>
      <th>NUM_OF_CLIENT</th>
      <th>GO</th>
      <th>NODEJS</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>50</td>
      <td>1.792352</td>
      <td>2.651158</td>
    </tr>
    <tr>
      <td>75</td>
      <td>2.414255</td>
      <td>3.357894</td>
    </tr>
    <tr>
      <td>100</td>
      <td>3.011296</td>
      <td>3.624805</td>
    </tr>
    <tr>
      <td>125</td>
      <td>4.343298</td>
      <td>3.347146</td>
    </tr>
    <tr>
      <td>150</td>
      <td>4.332794</td>
      <td>7.49678</td>
    </tr>
    <tr>
      <td>175</td>
      <td>5.40624</td>
      <td>5.063743</td>
    </tr>
    <tr>
      <td>200</td>
      <td>5.51915</td>
      <td>7.94199</td>
    </tr>
    <tr>
      <td>225</td>
      <td>6.48191</td>
      <td>7.948503</td>
    </tr>
    <tr>
      <td>250</td>
      <td>8.255354</td>
      <td>16.593525</td>
    </tr>
    <tr>
      <td>275</td>
      <td>8.656713</td>
      <td>16.408483</td>
    </tr>
  </tbody>
</table>

<h1 id="결론">결론</h1>

<p>Goroutines는 가벼운 스레드와 같은 동시성 모델을 사용합니다. 많은 수의 고루틴을 동시에 실행할 수 있어 동시성 처리에 매우 효율적이라고 알려져있습니다. 또한 I/O 바운드 작업뿐만 아니라 CPU 바운드 작업에서도 우수한 성능을 보이기 때문에 docker, kubernetes, traefik, prometheus 등 다양한 프로그램들을 만들 때 사용됩니다.</p>

<p>하지만, 단일 스레드에서 동작 함에도 불구하고 이벤트 루프를 사용하여 비동기 I/O를 처리하는 Node.js가 Go에 비해서 유사한 성능을 보입니다. 이는 Go에서 connection을 연결할 때 마다 Goroutine을 생성하는데,  Goroutines을 생성할 때 발생하는 overhead가 영향을 주는 것으로 추정됩니다.</p>

<p>전체적인 성능에서 큰 차이가 없지만, 안정성 측면에서 더 우수한 성능을 보이는 go dynamic reverse proxy 서버를 중계 서버로 사용하기로 결정했습니다.</p>

<h1 id="reference">Reference</h1>

<ul>
  <li>https://go.dev/doc/</li>
  <li>https://go.dev/doc/effective_go#goroutines</li>
  <li>https://pkg.go.dev/io</li>
  <li>https://www.npmjs.com/package/websocket</li>
  <li><a href="https://ko.wikipedia.org/wiki/%EB%A6%AC%EB%B2%84%EC%8A%A4_%ED%94%84%EB%A1%9D%EC%8B%9C">https://ko.wikipedia.org/wiki/리버스_프록시</a></li>
  <li>Forouzan, Behrouz A. <em>Data Communications and Networking.</em> Publisher, year.</li>
</ul>]]></content><author><name></name></author><category term="네트워크" /><summary type="html"><![CDATA[subdomain 기반으로 목적지 서버를 식별하여 사용자를 중계해주는 다이나믹 리버스 프록시 서버를 개발했습니다. 처음 개발할 때는 nodejs 로 중계 서버를 만들었습니다. 하지만 생각보다 성능이 높지 않았고, golang 를 통해서 중계 서버를 만든다면 성능상 어떤 차이가 있을지 확인해보고 싶어 이 실험을 계획했습니다.]]></summary></entry><entry><title type="html">HPC 클러스터에 반쪽 짜리 컨테이너 enroot 를 적용하며 배운 것들</title><link href="http://localhost:4000/%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88/2023/09/30/HPC-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0%EC%97%90-%EB%B0%98%EC%AA%BD-%EC%A7%9C%EB%A6%AC-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-enroot-%EB%A5%BC-%EC%A0%81%EC%9A%A9%ED%95%98%EB%A9%B0-%EB%B0%B0%EC%9A%B4-%EA%B2%83%EB%93%A4.html" rel="alternate" type="text/html" title="HPC 클러스터에 반쪽 짜리 컨테이너 enroot 를 적용하며 배운 것들" /><published>2023-09-30T00:00:00+09:00</published><updated>2023-09-30T00:00:00+09:00</updated><id>http://localhost:4000/%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88/2023/09/30/HPC-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0%EC%97%90-%EB%B0%98%EC%AA%BD-%EC%A7%9C%EB%A6%AC-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-enroot-%EB%A5%BC-%EC%A0%81%EC%9A%A9%ED%95%98%EB%A9%B0-%EB%B0%B0%EC%9A%B4-%EA%B2%83%EB%93%A4</id><content type="html" xml:base="http://localhost:4000/%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88/2023/09/30/HPC-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0%EC%97%90-%EB%B0%98%EC%AA%BD-%EC%A7%9C%EB%A6%AC-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-enroot-%EB%A5%BC-%EC%A0%81%EC%9A%A9%ED%95%98%EB%A9%B0-%EB%B0%B0%EC%9A%B4-%EA%B2%83%EB%93%A4.html"><![CDATA[<h1 id="배경">배경</h1>

<p>현재 관리하고 있는 HPC 클러스터는 100대의 연산 노드가 Centos7을 사용하고 있습니다. 클러스터의 사용자는 접속이 가능한 gate노드에 ssh로 접속하여 slurm 명령어를 통해서 작업을 제출합니다. slurm은 작업 스케줄링 도구로, 사용자가 제출한 작업을 적절한 연산 노드에 할당하여 작업을 수행합니다. slurm은 cgroup을 사용하여 사용자가 실행한 프로세스의 자원(cpu, memory, gpu)를 제한할 수 있습니다. 또한 사용자는 클러스터에 설치된 Linux Environment Modules 중 필요한 환경을 load 하여 사용합니다. 만약 여기에 필요한 환경이 없다면 권한이 있는 경로에 컴파일된 바이너리 실행파일 혹은 파이썬 가상환경을 직접 설치하여 사용하고 있습니다.</p>

<p><img alt="image" src="/images/7bc5601f-95a1-4008-bb77-92ad2da061b4" /></p>

<h1 id="문제점">문제점</h1>

<p>Linux Environment Modules는 사용자가 여러 버전의 애플리케이션, 라이브러리, 그리고 기타 소프트웨어 패키지를 쉽게 로드하거나 언로드할 수 있도록 도와주는 툴입니다. 국내에 많은 연구기관에서 사용되고 있지만, 다양한 문제점을 가지고 있습니다.</p>

<h3 id="운영체제-의존">운영체제 의존</h3>

<p>Linux Environment Modules는 Host 운영체제에 의존하여 동작합니다. 사용자가 Ubuntu와 같은 다른 운영체제의 패키지를 사용하고자 한다면 사용에 제한이 있습니다.</p>

<h3 id="불완전한-격리"><strong>불완전한 격리</strong></h3>

<p>Linux Environment Modules는 완전한 환경 격리를 제공하지 않습니다. 따라서 서로 다른 의존성 라이브러리가 시스템에 설치되어 있을 때 문제가 발생할 수 있습니다.</p>

<h3 id="충돌"><strong>충돌</strong></h3>

<p>불완전한 격리의 연장선으로 충돌 문제가 있습니다. 사용자가 여러 모듈을 동시에 로드할 때, 라이브러리나 의존성 충돌이 발생할 수 있습니다.</p>

<h3 id="관리-포인트-증가">관리 포인트 증가</h3>

<p>Linux Environment Modules의 환경은 관리자만 생성할 수 있습니다. 사용자의 요청할 때마다 관리자는 새로운 환경을 빌드하고 등록해야 합니다.</p>

<h2 id="해결방법">해결방법</h2>

<p>처음 생각한 방법은 Docker와 같은 컨테이너를 도입하는 것입니다. 혹은 클러스터에 쿠버네티스를 설치한다면 사용자가 원하는 이미지를 사용해 완전히 환경을 격리할 수 있다고 생각했습니다. 하지만 여기에는 몇 가지 문제가 있었습니다. 우선 기존의 Slurm + Linux Environment Modules 사용자를 고려해야 한다는 점입니다. 기존의 사용자는 몇 년간 위 환경으로 연구를 진행해 왔고, 사용하던 환경을 그대로 쓰고 싶어 했습니다.</p>

<p>따라서 기존의 Slurm과 호환되는 커테이너를 사용해야 합니다. 하지만, Docker 및 K8s는 슬럼과 호환되지 않습니다. Slurm은 자체적으로 cgroup을 사용해 job 별 자원을 제한합니다. 하지만 이러한 기능이 K8s나 Docker와 충돌하기 때문에 Slurm과 함께 사용할 수 없었습니다.</p>

<p>여기서 찾은 해결책은 Slurm을 그대로 사용하면서 NVIDIA 사에서 개발한 Enroot라는 반쪽 짜리 컨테이너를 도입하는 것입니다. Enroot는 HCP 클러스터에서 컨테이너와 같은 방식으로 환경을 분리하기 위해 만들어진 프로그램입니다. CNI를 따르지 않으며 자원을 제약하는 기능이 없습니다. 단순히 linux namespace를 통해 환경을 격리하는 기능만 제공합니다. 하지만 docker image를 enroot image로 변환하는 기능을 제공하기 때문에, 사용자가 손쉽게 컨테이너 이미지를 만들 수 있고, slurm에서 enroot 관련 플러그인을 제공하고 있습니다. 또한 NVIDIA 사에서 개발한 만큼, NVIDIA GPU 사용 기능을 기본적으로 제공합니다. enroot를 사용하면 현재 클러스터의 설정을 크게 바꾸지 않고 컨테이너 환경을 구축할 수 있다고 생각해 enroot를 사용하기로 결정했습니다.</p>

<p><img alt="image" src="/images/ff2206c1-259b-4038-87f2-807d5f9ad2bc" /></p>

<ul>
  <li>https://github.com/NVIDIA/enroot</li>
</ul>

<h1 id="설치-방법">설치 방법</h1>

<h2 id="커널-커맨드-및-커널-파라미터-수정">커널 커맨드 및 커널 파라미터 수정</h2>

<p>enroot 를 설치하기 위해서는 커널 커맨드 및 커널 파라미터를 수정해야 합니다. 아래 문서를 참고하면서 하나씩 진행하겠습니다.</p>

<ul>
  <li>https://github.com/NVIDIA/enroot/blob/master/doc/requirements.md
    <ul>
      <li><code class="highlighter-rouge">./enroot-check_*.run --verify</code></li>
    </ul>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="o">[</span>root@gate1 container]# ./enroot-check_<span class="k">*</span>.run <span class="nt">--verify</span> 
  Kernel version:
    
  Linux version 3.10.0-1127.el7.x86_64 <span class="o">(</span>root@tgm-master.hpc<span class="o">)</span> <span class="o">(</span>gcc version 4.8.5 20150623 <span class="o">(</span>Red Hat 4.8.5-39<span class="o">)</span> <span class="o">(</span>GCC<span class="o">)</span> <span class="o">)</span> <span class="c">#1 SMP Thu May 7 14:42:14 KST 2020</span>
    
  Kernel configuration:
    
  CONFIG_NAMESPACES                 : OK
  CONFIG_USER_NS                    : OK
  CONFIG_SECCOMP_FILTER             : OK
  CONFIG_OVERLAY_FS                 : OK <span class="o">(</span>module<span class="o">)</span>
  CONFIG_X86_VSYSCALL_EMULATION     : KO <span class="o">(</span>required <span class="k">if </span>glibc &lt;<span class="o">=</span> 2.13<span class="o">)</span>
  CONFIG_VSYSCALL_EMULATE           : KO <span class="o">(</span>required <span class="k">if </span>glibc &lt;<span class="o">=</span> 2.13<span class="o">)</span>
  CONFIG_VSYSCALL_NATIVE            : KO <span class="o">(</span>required <span class="k">if </span>glibc &lt;<span class="o">=</span> 2.13<span class="o">)</span>
    
  Kernel <span class="nb">command </span>line:
    
  <span class="k">**</span>namespace.unpriv_enable<span class="o">=</span>1         : KO
  user_namespace.enable<span class="o">=</span>1           : KO<span class="k">**</span>
  <span class="nv">vsyscall</span><span class="o">=</span>native                   : KO <span class="o">(</span>required <span class="k">if </span>glibc &lt;<span class="o">=</span> 2.13<span class="o">)</span>
  <span class="nv">vsyscall</span><span class="o">=</span>emulate                  : KO <span class="o">(</span>required <span class="k">if </span>glibc &lt;<span class="o">=</span> 2.13<span class="o">)</span>
    
  Kernel parameters:
    
  <span class="k">**</span>user.max_user_namespaces          : KO<span class="k">**</span>
  user.max_mnt_namespaces           : OK
    
  Extra packages:
    
  <span class="k">**</span>nvidia-container-cli              : KO<span class="k">**</span> 
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="grubby를-사용한-kernel-command-line-수정">grubby를 사용한 kernel command line 수정</h3>

<p>노드의 부팅이미지가 디스크에 있는 경우 grubby 를 이용해서 kernel의 실행 커맨드를 쉽게 수정할 수 있습니다. enroot를 설치한 클러스터에서 게이트 노드, 관리 노드는 아래와 같이 부팅 설정을 변경하고 시스템을 재부팅하여 손쉽게 적용했습니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>grubby <span class="nt">--args</span><span class="o">=</span><span class="s2">"namespace.unpriv_enable=1 user_namespace.enable=1"</span> <span class="nt">--update-kernel</span><span class="o">=</span><span class="s2">"</span><span class="si">$(</span>grubby <span class="nt">--default-kernel</span><span class="si">)</span><span class="s2">"</span>

<span class="nb">echo</span> <span class="s1">'user.max_user_namespaces=15076'</span> <span class="o">&gt;&gt;</span> /etc/sysctl.conf

sysctl <span class="nt">--system</span>
</code></pre></div></div>

<h3 id="pxelinuxcfg-파일을-통한-kernel-command-line-수정">pxelinux.cfg 파일을 통한 kernel command line 수정</h3>

<p>하지만, 계산 노드는 pxe boot 라는 방식을 이용합니다. pxe(preboot execution environment) boot란 네트워크를 통해 컴퓨터를 부팅하는 기술입니다. pxe server에 저장된 커널 이미지를 pxe client 노드들이 네트워크를 통해서 다운받고, 이를 부팅하는 방식으로 동작합니다. 마스터 노드가 pxe 서버 역할을 하기 때문에, 만약 계산 노드들의 부팅 이미지, 혹은 설정을 변경하기 위해서는 마스터 노드의 pxe 관련 설정을 수정해야 합니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/path/to/RBOOT/efi64/pxelinux.cfg
</code></pre></div></div>

<p>마스터 노드의 위 경로에 노드별로 부팅 설정 파일이 저장되어 있었습니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="o">[</span>root@master pxelinux.cfg]# <span class="nb">ls
</span>C0A86401  C0A86412  C0A86423  C0A86434  C0A86445  C0A86456  C0A86467  C0A86478  C0A86489
C0A86402  C0A86413  C0A86424  C0A86435  C0A86446  C0A86457  C0A86468  C0A86479  C0A8648A
C0A86403  C0A86414  C0A86425  C0A86436  C0A86447  C0A86458  C0A86469  C0A8647A  C0A8648B
C0A86404  C0A86415  C0A86426  C0A86437  C0A86448  C0A86459  C0A8646A  C0A8647B  C0A8648C
C0A86405  C0A86416  C0A86427  C0A86438  C0A86449  C0A8645A  C0A8646B  C0A8647C  C0A8648D
...

<span class="o">[</span>root@master pxelinux.cfg]# <span class="nb">cat </span>C0A86401
DEFAULT TGMkernel 

LABEL TGMkernel
   KERNEL http://192.168.100.1/KERNEL/kernel.img
   APPEND <span class="nv">initrd</span><span class="o">=</span>http://192.168.100.1/KERNEL/n033_ramfs.tgm quiet 
		rd_NO_DM <span class="nv">ip</span><span class="o">=</span>eth0:dhcp <span class="nv">ETHERNET</span><span class="o">=</span>eth0 <span class="nv">NISDOMAIN</span><span class="o">=</span>TGM rw <span class="nv">selinux</span><span class="o">=</span>0 
		net.ifnames<span class="o">=</span>0 <span class="nv">biosdevname</span><span class="o">=</span>0 intel_idle.max_cstate<span class="o">=</span>0 processor.max_cstate<span class="o">=</span>1 
		ipv6.disable<span class="o">=</span>1 <span class="nv">cgroup_enable</span><span class="o">=</span>memory <span class="nv">swapaccount</span><span class="o">=</span>1 <span class="nv">intel_pstate</span><span class="o">=</span>disable <span class="nv">rdblacklist</span><span class="o">=</span>nouveau 
		nouveau.modeset<span class="o">=</span>0 <span class="nv">vga</span><span class="o">=</span>normal nofb i915.modeset<span class="o">=</span>0 <span class="nv">spectre_v2</span><span class="o">=</span>off nospectre_v1 nospectre_v2 
		nopti rhgb nomodeset <span class="nv">video</span><span class="o">=</span>vesafb:off <span class="nv">panic</span><span class="o">=</span>60 
		nfs.nfs4_unique_id<span class="o">=</span>3dc56ea0-d930-464c-80e6-1ec1f9f4b1c1  
</code></pre></div></div>

<p>해당 파일마다  <strong><code class="highlighter-rouge">namespace.unpriv_enable=1 user_namespace.enable=1</code></strong> 라인을 추가하여 pxe 설정파일을 수정했습니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>

<span class="nb">cd</span> /path/to/RBOOT/efi64/

<span class="nb">cp</span> <span class="nt">-pr</span> pxelinux.cfg pxelinux.cfg.bk

<span class="nv">list</span><span class="o">=</span><span class="sb">`</span><span class="nb">ls </span>pxelinux.cfg<span class="sb">`</span>

<span class="k">for </span>text <span class="k">in</span> <span class="nv">$list</span>
<span class="k">do
    </span><span class="nb">echo</span> <span class="nv">$text</span>
    <span class="nb">sed</span> <span class="nt">-e</span> <span class="s1">'$s/$/namespace.unpriv_enable=1 user_namespace.enable=1/'</span> <span class="nt">-s</span> <span class="nv">$text</span> <span class="o">&gt;</span> <span class="nv">$text</span>
<span class="k">done</span>
</code></pre></div></div>

<p>그 결과, 모든 계산 노드의 커널 커맨드가 수정되었습니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>root@tgm-master pxelinux.cfg]# <span class="nb">cat </span>C0A86401
DEFAULT TGMkernel 

LABEL TGMkernel
   KERNEL http://pxe-server-ip/KERNEL/kernel.img
   APPEND <span class="nv">initrd</span><span class="o">=</span>http://pxe-server-ip/KERNEL/n0XX_ramfs.tgm quiet 
		rd_NO_DM <span class="nv">ip</span><span class="o">=</span>eth0:dhcp <span class="nv">ETHERNET</span><span class="o">=</span>eth0 <span class="nv">NISDOMAIN</span><span class="o">=</span>TGM rw <span class="nv">selinux</span><span class="o">=</span>0 
		net.ifnames<span class="o">=</span>0 <span class="nv">biosdevname</span><span class="o">=</span>0 intel_idle.max_cstate<span class="o">=</span>0 processor.max_cstate<span class="o">=</span>1 
		ipv6.disable<span class="o">=</span>1 <span class="nv">cgroup_enable</span><span class="o">=</span>memory <span class="nv">swapaccount</span><span class="o">=</span>1 <span class="nv">intel_pstate</span><span class="o">=</span>disable <span class="nv">rdblacklist</span><span class="o">=</span>nouveau 
		nouveau.modeset<span class="o">=</span>0 <span class="nv">vga</span><span class="o">=</span>normal nofb i915.modeset<span class="o">=</span>0 <span class="nv">spectre_v2</span><span class="o">=</span>off nospectre_v1 nospectre_v2 
		nopti rhgb nomodeset <span class="nv">video</span><span class="o">=</span>vesafb:off <span class="nv">panic</span><span class="o">=</span>60 
		nfs.nfs4_unique_id<span class="o">=</span>3dc56ea0-d930-464c-80e6-1ec1f9f4b1c1  
		<span class="k">**</span>namespace.unpriv_enable<span class="o">=</span>1 user_namespace.enable<span class="o">=</span>1<span class="k">**</span>
</code></pre></div></div>

<h3 id="kernel-parameters-수정">Kernel parameters 수정</h3>

<p>커널 파라미터는 <code class="highlighter-rouge">/etc/sysctl.conf</code> 를 수정하여 변경할 수 있는데, 모든 계산 노드 etc 폴더가 마스터 노드에 NFS로 마운트되어 있습니다. 따라서 마스터 노드에서 일괄적으로 수정이 가능합니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>root@tgm-master NODES]#
<span class="nv">list</span><span class="o">=</span><span class="sb">`</span><span class="nb">ls</span> ./<span class="k">*</span>/etc/sysctl.conf<span class="sb">`</span>

<span class="k">for </span>loc <span class="k">in</span> <span class="nv">$list</span>
<span class="k">do
    </span><span class="nb">echo</span> <span class="s1">'user.max_user_namespaces=15076'</span> <span class="o">&gt;&gt;</span> <span class="nv">$loc</span>
<span class="k">done</span>
</code></pre></div></div>

<p>이후 모든 계산노드를 재부팅하여 설정을 갱신했습니다.</p>

<h2 id="nvidia-container-cli-설치">nvidia-container-cli 설치</h2>

<p>enroot로 gpu를 사용하기 위해서는 nvidia-container-cli이 필요합니다. 아래 가이드를 참고해 설치했습니다.</p>

<ul>
  <li>https://github.com/NVIDIA/libnvidia-container</li>
  <li>https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#installation-guide</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># yum 레파지토리 추가</span>
<span class="nv">distribution</span><span class="o">=</span><span class="si">$(</span><span class="nb">.</span> /etc/os-release<span class="p">;</span><span class="nb">echo</span> <span class="nv">$ID$VERSION_ID</span><span class="si">)</span>    <span class="o">&amp;&amp;</span> curl <span class="nt">-s</span> <span class="nt">-L</span> https://nvidia.github.io/libnvidia-container/<span class="nv">$distribution</span>/libnvidia-container.repo | <span class="nb">sudo tee</span> /etc/yum.repos.d/nvidia-container-toolkit.repo
yum-config-manager <span class="nt">--enable</span> libnvidia-container-experimental
yum clean expire-cache
<span class="c"># nvidia-container-cli 설치</span>
yum <span class="nb">install</span> <span class="nt">-y</span> libnvidia-container1
yum <span class="nb">install</span> <span class="nt">-y</span> libnvidia-container-tools
</code></pre></div></div>

<ul>
  <li>
    <p>nvidia_uvm이 없는 문제 해결</p>

    <p>일부 노드에서  NVIDIA driver가 완전하기 실행되지 않고, UVM 커널 모듈이 빠진 경우 아래와 같은 오류가 발생했습니다. <code class="highlighter-rouge">nvidia-container-cli -k info</code> 커맨드를 통해서 드라이버를 다시 로드하여 해결했습니다. 만약 같은 문제가 반복된다면, 시스템 데몬으로 등록하여 리로드를 강제할 수 있다고 합니다.</p>

    <p>(https://github.com/NVIDIA/enroot/issues/105)</p>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># nvidia_uvm 없음.</span>
<span class="c">#[WARN] Kernel module nvidia_uvm is not loaded. Make sure the NVIDIA device driver is installed and loaded.</span>
<span class="nv">$# </span>nvidia-container-cli <span class="nt">-k</span> info
</code></pre></div></div>

<ul>
  <li>
    <p>libnvidia-ml.so 못 찾는 문제 해결</p>

    <p>찾아보니 debian 계열의 운영체제에서 유사한 에러가 발생했고, 원인은  /sbin/ldconfig 와 관련된 경로가 달라서 생기는 오류라고 합니다.</p>

    <p>이 클러스터는 centos7이기 때문에 완전히 같은 원인은 아니겠지만, 비슷한 이유로 ldconfig를 실행하지 못해 공유 라이브러리 링커가 잘 연결되지 않았다면, *.so 관련 에러가 발생할 수 있을 것이라 생각했습니다. <code class="highlighter-rouge">ldconfig</code>를 수동으로 실행했더니 문제가 해결됐습니다.</p>
  </li>
</ul>

<h2 id="다시-enroot-pre-requirement-검사">다시 Enroot pre-requirement 검사</h2>

<p>필요한 설정들을 마치고 다시 enroot-pre-requirement를 실행하여 시스템 설정이 잘 적용 됐는지 확인했습니다.</p>

<ul>
  <li><code class="highlighter-rouge">./enroot-check_*.run --verify</code></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>root@gate1 container]# ./enroot-check_<span class="k">*</span>.run <span class="nt">--verify</span> 
Kernel version:

Linux version 3.10.0-1127.el7.x86_64 <span class="o">(</span>root@tgm-master.hpc<span class="o">)</span> <span class="o">(</span>gcc version 4.8.5 20150623 <span class="o">(</span>Red Hat 4.8.5-39<span class="o">)</span> <span class="o">(</span>GCC<span class="o">)</span> <span class="o">)</span> <span class="c">#1 SMP Thu May 7 14:42:14 KST 2020</span>

Kernel configuration:

CONFIG_NAMESPACES                 : OK
CONFIG_USER_NS                    : OK
CONFIG_SECCOMP_FILTER             : OK
CONFIG_OVERLAY_FS                 : OK <span class="o">(</span>module<span class="o">)</span>
CONFIG_X86_VSYSCALL_EMULATION     : KO <span class="o">(</span>required <span class="k">if </span>glibc &lt;<span class="o">=</span> 2.13<span class="o">)</span>
CONFIG_VSYSCALL_EMULATE           : KO <span class="o">(</span>required <span class="k">if </span>glibc &lt;<span class="o">=</span> 2.13<span class="o">)</span>
CONFIG_VSYSCALL_NATIVE            : KO <span class="o">(</span>required <span class="k">if </span>glibc &lt;<span class="o">=</span> 2.13<span class="o">)</span>

Kernel <span class="nb">command </span>line:

<span class="k">**</span>namespace.unpriv_enable<span class="o">=</span>1         : OK
user_namespace.enable<span class="o">=</span>1           : OK<span class="k">**</span>
<span class="nv">vsyscall</span><span class="o">=</span>native                   : KO <span class="o">(</span>required <span class="k">if </span>glibc &lt;<span class="o">=</span> 2.13<span class="o">)</span>
<span class="nv">vsyscall</span><span class="o">=</span>emulate                  : KO <span class="o">(</span>required <span class="k">if </span>glibc &lt;<span class="o">=</span> 2.13<span class="o">)</span>

Kernel parameters:

user.max_user_namespaces          : OK
user.max_mnt_namespaces           : OK

Extra packages:

<span class="k">**</span>nvidia-container-cli              : OK<span class="k">**</span> 
</code></pre></div></div>

<h2 id="enroot-설치----httpsgithubcomnvidiaenroot">Enroot 설치 -  https://github.com/NVIDIA/enroot</h2>

<p><strong>nvidia-container-cli</strong> 마찬가지로 master 노드에 yum으로 간단하게 설치할 수 있습니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>3. enroot 설치<span class="o">(</span>https://github.com/NVIDIA/enroot<span class="o">)</span>
<span class="nb">arch</span><span class="o">=</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span>
yum <span class="nb">install</span> <span class="nt">-y</span> epel-release
yum <span class="nb">install</span> <span class="nt">-y</span> https://github.com/NVIDIA/enroot/releases/download/v3.4.0/enroot-hardened-3.4.0-2.el7.<span class="k">${</span><span class="nv">arch</span><span class="k">}</span>.rpm
yum <span class="nb">install</span> <span class="nt">-y</span> https://github.com/NVIDIA/enroot/releases/download/v3.4.0/enroot-hardened+caps-3.4.0-2.el7.<span class="k">${</span><span class="nv">arch</span><span class="k">}</span>.rpm
</code></pre></div></div>

<p>enroot 를 설치하면 노드마다 <code class="highlighter-rouge">/etc/enroot/enroot.conf</code> 라는 경로에 설정파일이 생성됩니다. 이 설정 파일을 수정하여 enroot를 커스텀할 수 있다고 합니다. 현재 클러스터 상황에 맞게 일부 설정을 수정하였습니다.</p>

<ul>
  <li>
    <p>runtime, data, temp 경로를 /disk 로 수정</p>

    <p>현재 클러스터는 사용자 계정이 NFS 볼륨에 마운트 되어 있습니다. enroot의 runtime, data, temp 경로를 /home/user 아래에 생성하면, 손쉽게 컨테이너를 동기화할 수 있지만, NFS 볼륨은 사용량이 많아 IO 가 매우 느리다는 단점이 있습니다. 특히 패키지 설치와 같은 쓰기 작업 속도가 매우 느리기 때문에 disk 볼륨을 런타임 및 데이터 경로로 사용하기로 결정했다. 둘의 차이를 비교해본 결과 nfs 볼륨을 사용할 때보다 훨씬 빠른 작업 속도를 보였습니다.</p>
  </li>
  <li>
    <p>이미지 압축 옵션 변경</p>

    <p>enroot는 다양한 압축 알고리즘을 지원합니다. 이 클러스터는 스토리지 공간에 여유가 있기 때문에, 컨테이너 이미지가 커도 압축 속도가 빠른 gzip 알고리즘을 사용하도록 변경했습니다. 또한 특정 레이어 사이즈가 스토리지 블록 사이즈 보다 클 경우, 이미지를 export하지 못하는 문제가 있었는데, 이를 해결하기 위해 fragments를 허용하는 옵션을 추가했습니다.</p>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># /etc/enroot/enroot.conf</span>
<span class="nv">ENROOT_RUNTIME_PATH</span><span class="o">=</span>/disk/enroot/<span class="si">$(</span><span class="nb">id</span> <span class="nt">-u</span><span class="si">)</span>/runtime
<span class="nv">ENROOT_DATA_PATH</span><span class="o">=</span>/disk/enroot/<span class="si">$(</span><span class="nb">id</span> <span class="nt">-u</span><span class="si">)</span>/data
<span class="nv">ENROOT_CACHE_PATH</span><span class="o">=</span>/disk/enroot/<span class="si">$(</span><span class="nb">id</span> <span class="nt">-u</span><span class="si">)</span>/cache
<span class="nv">ENROOT_TEMP_PATH</span><span class="o">=</span>/disk/enroot/<span class="si">$(</span><span class="nb">id</span> <span class="nt">-u</span><span class="si">)</span>
<span class="nv">ENROOT_SQUASH_OPTIONS</span><span class="o">=</span><span class="s1">'-comp gzip -noD -always-use-fragments'</span>
ENROOT_MAX_PROCESSORS      10
</code></pre></div></div>

<h1 id="결론">결론</h1>

<p>이제 사용자가 자유롭게 도커 컨테이너로부터 작업 환경을 가져올 수 있게 됐습니다. 더욱이 NFS에 의존하지 않으면서 환경을 구축하고, 실행할 수 있기 때문에 작업 속도가 크게 증가했습니다.</p>

<p>저로서는 이번 enroot를 설치하면서 많은 공부가 되었습니다.  HPC 클러스터에 의존하는 설정 덕분에 다양한 문제들을 마주했고, 이 문제들을 해결해 가면서 운영체제, HPC 구성에 대한 이해를 높일 수 있는 시간이었습니다.</p>

<h1 id="reference">Reference</h1>

<ul>
  <li>https://slurm.schedmd.com/SLUG19/NVIDIA_Containers.pdf</li>
  <li>https://slurm.schedmd.com/qos.html</li>
  <li>https://github.com/NVIDIA/enroot</li>
  <li><strong>“Performance Analysis of Container-based Virtualization for High Performance Computing Environments”</strong> by Kozhirbayev, Zhandos, and Richard O. Sinnott.</li>
</ul>]]></content><author><name></name></author><category term="컨테이너" /><summary type="html"><![CDATA[배경]]></summary></entry><entry><title type="html">bdg.blog를 만들면서 들었던 고민과 해결 방법- 프로그램 구조, 사용한 도구, 테스트 방법, 개발 환경 구축</title><link href="http://localhost:4000/%ED%81%B4%EB%A6%B0%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B3%90/2023/09/29/bdg-blog%EB%A5%BC-%EB%A7%8C%EB%93%A4%EB%A9%B4%EC%84%9C-%EB%93%A4%EC%97%88%EB%8D%98-%EA%B3%A0%EB%AF%BC%EA%B3%BC-%ED%95%B4%EA%B2%B0-%EB%B0%A9%EB%B2%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8-%EA%B5%AC%EC%A1%B0-%EC%82%AC%EC%9A%A9%ED%95%9C-%EB%8F%84%EA%B5%AC-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%B0%A9%EB%B2%95-%EA%B0%9C%EB%B0%9C-%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%B6%95.html" rel="alternate" type="text/html" title="bdg.blog를 만들면서 들었던 고민과 해결 방법- 프로그램 구조, 사용한 도구, 테스트 방법, 개발 환경 구축" /><published>2023-09-29T00:00:00+09:00</published><updated>2023-09-29T00:00:00+09:00</updated><id>http://localhost:4000/%ED%81%B4%EB%A6%B0%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B3%90/2023/09/29/bdg-blog%EB%A5%BC-%EB%A7%8C%EB%93%A4%EB%A9%B4%EC%84%9C-%EB%93%A4%EC%97%88%EB%8D%98-%EA%B3%A0%EB%AF%BC%EA%B3%BC-%ED%95%B4%EA%B2%B0-%EB%B0%A9%EB%B2%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8-%EA%B5%AC%EC%A1%B0-%EC%82%AC%EC%9A%A9%ED%95%9C-%EB%8F%84%EA%B5%AC-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%B0%A9%EB%B2%95-%EA%B0%9C%EB%B0%9C-%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%B6%95</id><content type="html" xml:base="http://localhost:4000/%ED%81%B4%EB%A6%B0%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B3%90/2023/09/29/bdg-blog%EB%A5%BC-%EB%A7%8C%EB%93%A4%EB%A9%B4%EC%84%9C-%EB%93%A4%EC%97%88%EB%8D%98-%EA%B3%A0%EB%AF%BC%EA%B3%BC-%ED%95%B4%EA%B2%B0-%EB%B0%A9%EB%B2%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8-%EA%B5%AC%EC%A1%B0-%EC%82%AC%EC%9A%A9%ED%95%9C-%EB%8F%84%EA%B5%AC-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%B0%A9%EB%B2%95-%EA%B0%9C%EB%B0%9C-%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%B6%95.html"><![CDATA[<h2 id="bdgblog란">bdg.blog란?</h2>

<p>개인적으로 공부한 내용을 정리하고, 적용해보기 위해서 만든 서비스입니다. 서비스의 기능 자체는 “블로그 생성”, “수정”, “삭제”, “조회”와 “토이프로젝트 연결”로 매우 단순합니다. 블로그 서비스를 만들면서 다음과 같은 항목들에 대해 고민했고 어떻게 해결했는지 소개합니다.</p>

<hr />

<ol>
  <li>프로그램 구조
    <ul>
      <li>기능 확장과 유지보수를 쉽게 만들려면 어떤 구조를 사용해야 할까?</li>
    </ul>
  </li>
  <li>사용한 도구
    <ul>
      <li>프론트앤드-백앤드를 같이 작업을 할 때 중복되는 작업을 줄이는 방법이 있을까?</li>
      <li>하나의 파일로 엔티티를 관리할 방법이 없을까?</li>
    </ul>
  </li>
  <li>테스트 방법
    <ul>
      <li>단위 테스트는 어떻게 수행하는 것이 좋을까?</li>
      <li>E2E(end to end) 테스트는 어떻게 수행할까?</li>
      <li>프론트 엔드는 어떻게 테스트할까?</li>
    </ul>
  </li>
  <li>개발 환경
    <ul>
      <li>개발 환경과 빌드 환경을 동일하게 만드는 방법</li>
      <li>개발 및 빌드에만 필요한 환경을 제외하고 배포 이미지를 만드는 방법</li>
    </ul>
  </li>
</ol>

<hr />

<p>소스코드는 아래 깃허브에서 확인하실 수 있습니다.</p>
<ul>
  <li>github: https://github.com/deagwon97/bdg-blog-v2/</li>
</ul>

<hr />
<h1 id="1-프로그램-구조">1. 프로그램 구조</h1>

<h2 id="기능-확장과-유지보수를-쉽게-만들려면-어떤-구조를-사용해야-할까">기능 확장과 유지보수를 쉽게 만들려면 어떤 구조를 사용해야 할까?</h2>

<p>프로그램의 가장 중요한 요소가 ‘요구사항을 만족하는 동작을 수행하는 것’ 이라면, 두 번째로 중요한 요소는 <strong>기능 확장성</strong>과 <strong>유지 보수성</strong>입니다. 저는 단순히 블로그를 만들어 보는 것보다는 더 좋은 구조로 블로그를 만들기 위해서 다음과 같은 구조를 적용했습니다.</p>

<p><img alt="image" src="/images/a7074e08-7802-48c5-9b6e-3907651f2fd3" /></p>

<p>요구사항이 최상위에 존재하며 하위로 갈수록 구체적인 구현이 만들어지는 구조입니다. 백앤드는 요구사항을 만족하는 서비스 클래스를 가지고 있습니다. 그리고 이 서비스가 제대로 동작하는 데 필요한 레파지토리(DB와 상호작용) 명세, 스토리지(Object Storage와 상호작용) 명세, 컨트롤러 명세를 정의합니다. 하위에 있는 클래스들은 상위 클래스의 명세를 만족하게 만들었습니다.</p>

<p>위 구조를 통해서 post 테이블에 접근하는 로직이 변경되더라도 서비스의 명세를 만족한다면 상위의 다른 클래스에 아무런 영향도 끼치지 않습니다. 단순히 관심있는 영역의 코드만 변경하면 간단하게 기능을 수정할 수 있습니다.</p>

<p>실제로 npm의 <strong><code class="highlighter-rouge">dependency-cruiser</code></strong> 모듈을 사용해서 서버 디렉터리 안에 있는 파일들의 의존관계를 시각화 하면 아래와 같은 모습을 보입니다.</p>

<p><img alt="image" src="/images/9b1ac643-d99c-4c7b-94a8-610446ac0a38" /></p>

<p>모든 클래스는 서비스에 의존하며 서로의 존재를 신경 쓰지 않습니다. 오로지 서비스만이 요구사항을 만족하기 위한 로직을 결정하며 하위 클래스들은 이를 따릅니다.</p>
<h1 id="2-사용한-도구">2. 사용한 도구</h1>

<h2 id="프론트앤드-백앤드를-같이-작업을-할-때-중복되는-작업을-줄일-방법이-있을까">프론트앤드-백앤드를 같이 작업을 할 때, 중복되는 작업을 줄일 방법이 있을까?</h2>

<h3 id="언어---typescript">언어 - Typescript</h3>

<p>이전에 작업했던 프로젝트는 프론트는 ReactJS, 백앤드는 DJango나 Golang-gin을 사용해서 만들었습니다. 만약 각 부분별로 팀이 나눠져 있다면 크게 상관을 수도 있지만, 혼자 작업하는 데 프론트와 백앤드의 언어가 다르다는 점은 상당히 불편했습니다.</p>

<ul>
  <li>언어별 네이밍 컨벤션 상이
    <ul>
      <li>python: snake_case</li>
      <li>javascript: camelCase, PascalCase</li>
      <li>go: PascalCase, camelCase</li>
    </ul>
  </li>
  <li>호환되는 데이터 타입 상이
    <ul>
      <li>python, js: 동적 타입</li>
      <li>go, typescript: 정적 타입</li>
    </ul>
  </li>
</ul>

<p>이런 문제들은 보통 django, go-gin과 같은 프레임워크를 쓰면 많은 부분이 해결되지만, 그럼에도 수작업으로 컨버터를 일일이 만드는 경우가 종종 발생합니다. 이를 최소화하기 위해 프론트와 백을 하나의 언어(Typescript)로 개발하기로 결정했습니다.</p>

<h3 id="웹-프레임워크---nextjs">웹 프레임워크 - NextJS</h3>

<p>NextJS란 full-stack 웹 어플리케이션 개발을 위해서 만들어진 리액트 프레임워크입니다. 기본적으로 React의 구성요소들을 사용하면서 다양한 추가 기능을 제공합니다. 특히 <code class="highlighter-rouge">API Routes</code> 를 통해서 별도의 백앤드 서버 없이 자체적으로 public API를 만들 수 있습니다. 프론트엔드와 백앤드의 엔티티, 인터페이스를 하나의 프로젝트에 정의하고 하위 모듈이 이를 구현하는 구조를 만들기 위해 NextJS를 선택했습니다.</p>

<h3 id="컨트롤러-tool---telefunc">컨트롤러 tool - telefunc</h3>

<p>NextJS를 사용한다고 하더라도, 결국 통신은 http 프로토콜을 사용해야 합니다. 백에서 정의한 함수를 프론트에서 사용하기 위해서는 백앤드가 http 프로토콜에 맞는 end-point를 정의해야 하고, 프론트는 이 api를 사용하는 코드를 추가해야 합니다.</p>

<p>저는 이 과정이 불필요하다고 생각했습니다. 백앤드에서 정의한 함수를 프론트에서 단순히 <code class="highlighter-rouge">import</code> 해서 사용하고 싶었고, telefunc이라는 패키지를 발견했습니다. telefunc은 이 요구사항을 충족시켜주는 훌륭한 도구입니다. telefunc은 서버와 클라이언트 사이의 통신을 함수 호출로 추상화 합니다. 개발자는 단순히 서버의 함수를 호출하지만, 실제로는 telefunc이 http 요청을 보내고 응답을 클라이언트로 반환합니다. 또한 추가적으로 필요한 Cookie와 같은 http 헤더들을 <code class="highlighter-rouge">getContext</code>를 통해서 사용할 수도 있습니다. 따라서 아래 예시와 같은 구현이 가능해 집니다.</p>

<p><img alt="image" src="/images/956ffe19-27aa-4c97-b7e8-6ff021d466fc" /></p>

<p>telefunc을 사용함으로써 http 프로토콜을 전혀 신경 쓰지 않고, 프론트와 백은 하나의 코드로 구현할 수 있었습니다. (하지만 컨트롤러 모듈은 따로 분리했습니다. 만약 특정한 이유로 외부 API를 사용해야 한다면 telefunc에 의존하지 않고 기능을 확장할 수도 있습니다.)</p>

<h3 id="type-generator---prisma">type generator - prisma</h3>

<p>prisma는 typescript에서 사용되는 유용한 orm 도구입니다. 하지만 저는 orm 보다도 type과 DDL 생성을 통해서 얻는 이점이 더 크다고 생각합니다. 백앤드와 데이터베이스 사이의 상호작용은 불필요한 작업을 많이 만듭니다. 백앤드에서 DB에 사용할 객체들의 타입을 정의하면 데이터베이스에서 이를 만족하면서 DB의 특성을 고려한 DDL을 다시 작성해야 합니다. prisma는 <code class="highlighter-rouge">schema.prisma</code> 하나로 이 문제를 모두 해결해 줍니다. <code class="highlighter-rouge">schema.prisma</code> 를 작성하고, <code class="highlighter-rouge">prisma db push</code> 커맨드를 실행하면 DDL이 실행면서 원하는 데이터를 저장할 수 있는 테이블들이 자동으로 만들어지고, <code class="highlighter-rouge">prisma generate</code> 커맨드로 prisma shema와 호환되는 typescript 타입까지 생성됩니다.</p>

<p><img alt="image" src="/images/0602c51e-ca7a-4509-8e82-4897853f7d65" /></p>

<h1 id="3-테스트">3. 테스트</h1>

<p>테스트 코드는 그 자체로 프로그램 명세서 역할을 합니다. 프로그램이 동작하는 실질적인 예시를 제공하기 때문에, 잘 작성된 테스트 코드를 읽어보면 이 프로그램이 어떤 동작을 수행하는지 단번에 알 수 있습니다. 또한, CI/CD 파이프 라인에서 테스트 코드를 추가하면, 자동화된 배포 과정에서 코드를 검증할 수 있기 때문에 안정적인 배포가 가능해집니다.</p>

<p>백엔드는 요소들이 모듈로 캡슐화되어 있습니다. 하위 클래스가 상위 클래스에 의존하는 방식으로 구현되기 때문에 몇 가지 부분만 고려한다면 테스트 코드를 손쉽게 만들 수 있었습니다. 신경 써야 하는 부분은 데이터에 저장되는 영역입니다. 테스트를 위해서 데이터베이스에 값을 수정하면, 실제 서비스에 영향을 끼칩니다. 이 문제를 해결하는 데는 여러 가지 방법이 있습니다.</p>

<h3 id="단위-테스트---mock-객체">단위 테스트 - Mock 객체</h3>

<p>프론트앤드는 사용자에게 보이는 요소입니다. 물론 프론트앤드를 테스트하는 것만으로도 앱이 잘 동작하는지 확인할 수 있습니다. 하지만 테스트를 통과하지 못했을 경우, 어떤 영역에서 문제가 발생했는지 디버깅하기 어렵다는 단점이 있습니다. 이러한 문제를 해결하기 위해서는 모듈별 단위 테스트가 필요합니다.</p>

<p>단위 테스트를 수행하는 대표적인 방법은 Mock 객체를 사용하는 것입니다. Mock 객체는 원본 객체의 행동을 모방하는 객체로, 테스트할 함수가 사용하는 다른 모듈의 행동을 모조하여 사용할 수 있습니다. 이를 통해 다른 모듈의 동작에 아무런 영향도 주지 않으면서 원하는 모듈만 테스트할 수 있습니다.</p>

<p>하지만, Repository 모듈은 Mock 객체를 통해서 테스트를 수행하면, DB의 특정 동작을 무시하거나, 실제 동작과 불일치할 수 있습니다. 또한 DB의 동작을 모방하는 Mock객체를 만드는 것은 Mock 객체의 설정을 복잡하게 만들어 테스트 코드의 유지보수를 어렵게 하기도 합니다.</p>

<p>저는 이러한 문제점을 고려하여 DB의 transaction을 통해서 repository 모듈을 테스트하고, 차례로 상위 계층을 테스트하는 방법을 선택했습니다.</p>

<h3 id="repository-테스트---db-transaction">Repository 테스트 - DB Transaction</h3>

<p>transaction은 연속적인 쿼리 동작에 원자성을 부여하기 위해서 사용됩니다. transaction 내에서 쿼리들을 수행하는 도중, 문제가 발생하면 해당 transaction은 실행하기 전으로 DB를 되돌립니다. Repository 모듈을 테스트한 후 Transaction을 롤백하면, 실제 DB의 어떤 값도 변경하지 않으면서 테스트를 수행할 수 있습니다.</p>

<p>저는 아래와 같은 방식으로 <code class="highlighter-rouge">testRepoWithRollback</code> 함수를 정의하고 repository 모듈을 테스트했습니다. 더미 데이터를 생성하는 코드만 만들어주면 함수를 테스트할 수 있습니다. 테스트가 끝난 후 <code class="highlighter-rouge">throw new Error('prisma rollback')</code> 명령을 실행해서, transaction을 <code class="highlighter-rouge">rollback</code> 합니다.</p>

<div class="language-tsx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// transaction으로 테스트를 수행하는 함수 정의</span>
<span class="k">export</span> <span class="kd">const</span> <span class="nx">testRepoWithRollback</span> <span class="o">=</span> <span class="k">async</span> <span class="p">(</span>
  <span class="nx">testMessage</span><span class="p">:</span> <span class="kr">string</span><span class="p">,</span>
  <span class="nx">testFunction</span><span class="p">:</span> <span class="p">(</span><span class="nx">p</span><span class="p">:</span> <span class="nx">PrismaClient</span><span class="p">,</span> <span class="nx">repo</span><span class="p">:</span> <span class="nx">IRepository</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="nb">Promise</span><span class="o">&lt;</span><span class="k">void</span><span class="o">&gt;</span>
<span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
  <span class="nx">test</span><span class="p">(</span><span class="nx">testMessage</span><span class="p">,</span> <span class="k">async</span> <span class="p">()</span> <span class="o">=&gt;</span> <span class="p">{</span>
    <span class="kd">const</span> <span class="nx">prisma</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">PrismaClient</span><span class="p">()</span>
    <span class="kd">const</span> <span class="nx">transaction</span> <span class="o">=</span> <span class="k">async</span> <span class="p">()</span> <span class="o">=&gt;</span> <span class="p">{</span>
      <span class="k">await</span> <span class="nx">prisma</span><span class="p">.</span><span class="nx">$transaction</span><span class="p">(</span><span class="k">async</span> <span class="p">(</span><span class="nx">tx</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
        <span class="kd">const</span> <span class="nx">p</span> <span class="o">=</span> <span class="nx">tx</span> <span class="k">as</span> <span class="nx">PrismaClient</span>
        <span class="kd">const</span> <span class="nx">repo</span> <span class="o">=</span> <span class="nx">repoFactory</span><span class="p">(</span><span class="nx">p</span><span class="p">)</span>
        <span class="k">await</span> <span class="nx">testFunction</span><span class="p">(</span><span class="nx">p</span><span class="p">,</span> <span class="nx">repo</span><span class="p">)</span>
        <span class="k">throw</span> <span class="k">new</span> <span class="nb">Error</span><span class="p">(</span><span class="dl">'</span><span class="s1">prisma rollback</span><span class="dl">'</span><span class="p">)</span>
      <span class="p">})</span>
    <span class="p">}</span>
    <span class="k">await</span> <span class="nx">expect</span><span class="p">(</span><span class="nx">transaction</span><span class="p">).</span><span class="nx">rejects</span><span class="p">.</span><span class="nx">toThrow</span><span class="p">(</span><span class="dl">'</span><span class="s1">prisma rollback</span><span class="dl">'</span><span class="p">)</span>
    <span class="nx">prisma</span><span class="p">.</span><span class="nx">$disconnect</span><span class="p">()</span>
  <span class="p">})</span>
<span class="p">}</span>
<span class="c1">// ----------------</span>
<span class="c1">// 실제 테스트 함수</span>
<span class="nx">testRepoWithRollback</span><span class="p">(</span>
  <span class="dl">'</span><span class="s1">updatePost</span><span class="dl">'</span><span class="p">,</span>
  <span class="k">async</span> <span class="p">(</span><span class="nx">p</span><span class="p">:</span> <span class="nx">PrismaClient</span><span class="p">,</span> <span class="nx">repo</span><span class="p">:</span> <span class="nx">IRepository</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
		<span class="c1">// 더미 데이터 생성</span>
    <span class="kd">const</span> <span class="nx">dummyPost</span> <span class="o">=</span> <span class="k">await</span> <span class="nx">p</span><span class="p">.</span><span class="nx">post</span><span class="p">.</span><span class="nx">create</span><span class="p">({</span>
      <span class="na">data</span><span class="p">:</span> <span class="p">{</span>
        <span class="na">title</span><span class="p">:</span> <span class="dl">'</span><span class="s1">testTitle</span><span class="dl">'</span><span class="p">,</span>
        <span class="na">uriTitle</span><span class="p">:</span> <span class="dl">'</span><span class="s1">testTitle</span><span class="dl">'</span><span class="p">,</span>
        <span class="na">content</span><span class="p">:</span> <span class="dl">'</span><span class="s1">testContent</span><span class="dl">'</span><span class="p">,</span>
        <span class="na">thumbnail</span><span class="p">:</span> <span class="dl">'</span><span class="s1">testThumbnail</span><span class="dl">'</span><span class="p">,</span>
        <span class="na">published</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
        <span class="na">category</span><span class="p">:</span> <span class="p">{</span>
          <span class="na">connectOrCreate</span><span class="p">:</span> <span class="p">{</span>
            <span class="na">where</span><span class="p">:</span> <span class="p">{</span>
              <span class="na">name</span><span class="p">:</span> <span class="dl">'</span><span class="s1">testCategory</span><span class="dl">'</span>
            <span class="p">},</span>
            <span class="na">create</span><span class="p">:</span> <span class="p">{</span>
              <span class="na">name</span><span class="p">:</span> <span class="dl">'</span><span class="s1">testCategory</span><span class="dl">'</span>
            <span class="p">}</span>
          <span class="p">}</span>
        <span class="p">}</span>
      <span class="p">}</span>
    <span class="p">})</span>
		<span class="c1">// 동작 테스트</span>
    <span class="kd">const</span> <span class="nx">updatedPost</span> <span class="o">=</span> <span class="k">await</span> <span class="nx">repo</span><span class="p">.</span><span class="nx">postRepo</span><span class="p">.</span><span class="nx">updatePost</span><span class="p">(</span>
      <span class="nx">dummyPost</span><span class="p">.</span><span class="nx">id</span><span class="p">,</span>
      <span class="dl">'</span><span class="s1">updatedTitle</span><span class="dl">'</span><span class="p">,</span>
      <span class="dl">'</span><span class="s1">updatedContent</span><span class="dl">'</span><span class="p">,</span>
      <span class="dl">'</span><span class="s1">updatedCategory</span><span class="dl">'</span><span class="p">,</span>
      <span class="dl">'</span><span class="s1">updatedThumbnail</span><span class="dl">'</span><span class="p">,</span>
      <span class="kc">false</span>
    <span class="p">)</span>
    <span class="kd">const</span> <span class="nx">post</span> <span class="o">=</span> <span class="k">await</span> <span class="nx">p</span><span class="p">.</span><span class="nx">post</span><span class="p">.</span><span class="nx">findUnique</span><span class="p">({</span>
      <span class="na">where</span><span class="p">:</span> <span class="p">{</span>
        <span class="na">id</span><span class="p">:</span> <span class="nx">dummyPost</span><span class="p">.</span><span class="nx">id</span>
      <span class="p">}</span>
    <span class="p">})</span>
		<span class="c1">// 동작 확인</span>
    <span class="nx">expect</span><span class="p">(</span><span class="nx">post</span><span class="p">).</span><span class="nx">not</span><span class="p">.</span><span class="nx">toBeNull</span><span class="p">()</span>
    <span class="nx">expect</span><span class="p">(</span><span class="nx">post</span><span class="p">?.</span><span class="nx">title</span><span class="p">).</span><span class="nx">toBe</span><span class="p">(</span><span class="nx">updatedPost</span><span class="p">.</span><span class="nx">title</span><span class="p">)</span>
    <span class="nx">expect</span><span class="p">(</span><span class="nx">post</span><span class="p">?.</span><span class="nx">content</span><span class="p">).</span><span class="nx">toBe</span><span class="p">(</span><span class="nx">updatedPost</span><span class="p">.</span><span class="nx">content</span><span class="p">)</span>
    <span class="nx">expect</span><span class="p">(</span><span class="nx">post</span><span class="p">?.</span><span class="nx">categoryName</span><span class="p">).</span><span class="nx">toBe</span><span class="p">(</span><span class="nx">updatedPost</span><span class="p">.</span><span class="nx">categoryName</span><span class="p">)</span>
    <span class="nx">expect</span><span class="p">(</span><span class="nx">post</span><span class="p">?.</span><span class="nx">thumbnail</span><span class="p">).</span><span class="nx">toBe</span><span class="p">(</span><span class="nx">updatedPost</span><span class="p">.</span><span class="nx">thumbnail</span><span class="p">)</span>
    <span class="nx">expect</span><span class="p">(</span><span class="nx">post</span><span class="p">?.</span><span class="nx">published</span><span class="p">).</span><span class="nx">toBe</span><span class="p">(</span><span class="nx">updatedPost</span><span class="p">.</span><span class="nx">published</span><span class="p">)</span>
  <span class="p">}</span>
<span class="p">)</span>
</code></pre></div></div>

<h3 id="e2e-테스트---개발용-데이터베이스-분리">E2E 테스트 - 개발용 데이터베이스 분리</h3>

<p>단위 테스트는 개별 컴포넌트가 올바르게 동작한다는 것을 보장합니다. 하지만, 컴포넌트 간의 통합에서 발생하는 문제는 찾아내지 못합니다. E2E 테스트는 이러한 문제들을 찾아내고, 애플리케이션 전체가 사용자 관점에서 올바르게 동작하는지 확인할 수 있습니다.</p>

<p><code class="highlighter-rouge">조회</code> 에 해당하는 기능들은 실제 배포되고 있는 서비스에서도 e2e 테스트가 가능합니다. 하지만 DB에 특정 값을 저장하거나, 수정하는 기능은 실제 서비스에 영향을 줄 수 있기 때문에, 개발용 DB를 따로 사용해야 합니다.</p>

<p>향후 생성 및 조회에 관한 e2e 테스트가 필요하다고 느껴지면, 개발용 데이터베이스를 구축할 예정입니다. 지금은 조회에 해당하는 기능만 테스트하고 있습니다.</p>

<h3 id="e2e-테스트----프론트엔드-테스트-스크립트-생성-자동화">E2E 테스트 -  프론트엔드 테스트 스크립트 생성 자동화</h3>

<p>프론트 코드는 UI 변경이 잦고 테스트 코드를 작성하는데 시간이 많이 필요합니다. 저는 테스트 코드를 자동으로 생성해 주는 playwright를 사용했습니다. 정해진 시나리오를 화면에 직접 클릭하면 playwight는 이 과정을 아래와 같이 코드로 변환해 줍니다.</p>

<div class="language-tsx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="p">{</span> <span class="nx">test</span> <span class="p">}</span> <span class="k">from</span> <span class="dl">'</span><span class="s1">@playwright/test</span><span class="dl">'</span>

<span class="kd">const</span> <span class="nx">user</span> <span class="o">=</span> <span class="nx">JSON</span><span class="p">.</span><span class="nx">parse</span><span class="p">(</span><span class="nx">JSON</span><span class="p">.</span><span class="nx">stringify</span><span class="p">(</span><span class="nx">require</span><span class="p">(</span><span class="dl">'</span><span class="s1">./.auth/user.json</span><span class="dl">'</span><span class="p">)))</span>

<span class="nx">test</span><span class="p">(</span><span class="dl">'</span><span class="s1">login test</span><span class="dl">'</span><span class="p">,</span> <span class="k">async</span> <span class="p">({</span> <span class="nx">page</span> <span class="p">})</span> <span class="o">=&gt;</span> <span class="p">{</span>
  <span class="k">await</span> <span class="nx">page</span><span class="p">.</span><span class="nx">goto</span><span class="p">(</span><span class="dl">'</span><span class="s1">http://localhost:3000/main</span><span class="dl">'</span><span class="p">)</span>
  <span class="k">await</span> <span class="nx">page</span><span class="p">.</span><span class="nx">getByRole</span><span class="p">(</span><span class="dl">'</span><span class="s1">link</span><span class="dl">'</span><span class="p">,</span> <span class="p">{</span> <span class="na">name</span><span class="p">:</span> <span class="dl">'</span><span class="s1">loginIcon</span><span class="dl">'</span> <span class="p">}).</span><span class="nx">click</span><span class="p">()</span>
  <span class="k">await</span> <span class="nx">page</span><span class="p">.</span><span class="nx">locator</span><span class="p">(</span><span class="dl">'</span><span class="s1">input[type="text"]</span><span class="dl">'</span><span class="p">).</span><span class="nx">click</span><span class="p">()</span>
  <span class="k">await</span> <span class="nx">page</span><span class="p">.</span><span class="nx">locator</span><span class="p">(</span><span class="dl">'</span><span class="s1">input[type="text"]</span><span class="dl">'</span><span class="p">).</span><span class="nx">fill</span><span class="p">(</span><span class="nx">user</span><span class="p">.</span><span class="nx">email</span><span class="p">)</span>
  <span class="k">await</span> <span class="nx">page</span><span class="p">.</span><span class="nx">locator</span><span class="p">(</span><span class="dl">'</span><span class="s1">input[type="text"]</span><span class="dl">'</span><span class="p">).</span><span class="nx">press</span><span class="p">(</span><span class="dl">'</span><span class="s1">Tab</span><span class="dl">'</span><span class="p">)</span>
  <span class="k">await</span> <span class="nx">page</span><span class="p">.</span><span class="nx">locator</span><span class="p">(</span><span class="dl">'</span><span class="s1">input[type="password"]</span><span class="dl">'</span><span class="p">).</span><span class="nx">fill</span><span class="p">(</span><span class="nx">user</span><span class="p">.</span><span class="nx">password</span><span class="p">)</span>
  <span class="k">await</span> <span class="nx">page</span><span class="p">.</span><span class="nx">locator</span><span class="p">(</span><span class="dl">'</span><span class="s1">input[type="password"]</span><span class="dl">'</span><span class="p">).</span><span class="nx">press</span><span class="p">(</span><span class="dl">'</span><span class="s1">Enter</span><span class="dl">'</span><span class="p">)</span>
  <span class="k">await</span> <span class="nx">page</span><span class="p">.</span><span class="nx">getByRole</span><span class="p">(</span><span class="dl">'</span><span class="s1">button</span><span class="dl">'</span><span class="p">,</span> <span class="p">{</span> <span class="na">name</span><span class="p">:</span> <span class="dl">'</span><span class="s1">ALL</span><span class="dl">'</span> <span class="p">}).</span><span class="nx">click</span><span class="p">()</span>
  <span class="k">await</span> <span class="nx">page</span><span class="p">.</span><span class="nx">getByRole</span><span class="p">(</span><span class="dl">'</span><span class="s1">button</span><span class="dl">'</span><span class="p">,</span> <span class="p">{</span> <span class="na">name</span><span class="p">:</span> <span class="dl">'</span><span class="s1">기타</span><span class="dl">'</span> <span class="p">}).</span><span class="nx">click</span><span class="p">()</span>
<span class="p">})</span>
</code></pre></div></div>

<h3 id="테스트-구조도">테스트 구조도</h3>

<p>위에서 언급한 내용을 정리하면 아래 이미지와 같습니다. repository 모듈은 transaction을 통해서 테스트했고, service의 함수들은 transaction으로 동작하는 repository 객체를 입력받아서 같은 방식으로 테스트했습니다. 이후 조회 및 로그인 기능에 해당하는 e2e 기능테스트를 playwright로 구현했습니다.</p>

<p><img alt="image" src="/images/33f08d4d-6530-48e2-8a2a-f447f932a445" /></p>

<p>테스트 코드를 작성하는 방식이 매우 간소화됐기 때문에, 빠르게 테스트 코드를 작성하고 기능을 추가할 수 있습니다. 또한, 기능을 변경할 때, 오류 없이 요구사항을 잘 충족하는지 즉각적으로 확인할 수가 있어서 효율적인 프로그램이 가능해 졌습니다. 현재는 service 모듈과 repository 모듈에 존재하는 모든 함수를 테스트하고 있습니다.</p>

<h1 id="4-개발-환경">4. 개발 환경</h1>

<p>개발 환경을 구축하는 것은 중요한 문제입니다. 환경이 제대로 구성되지 않은 상태에서 개발하다 보면 다음과 같은 문제가 발생합니다.</p>

<table>
  <tbody>
    <tr>
      <td>“내 노트북에서는 됐는데…. 왜 서버에서는 안 되지?”</td>
    </tr>
    <tr>
      <td>“내 노트북에서는 잘 보이는데…. 왜 모바일은 안 보이지?”</td>
    </tr>
  </tbody>
</table>

<p>이 문제를 해결하기 위해서 개발환경과 빌드환경을 일치시켰습니다. 그리고 배포환경에서는 빌드환경과 유사하게 구성하면서 배포에는 불필요한 환경들을 제외하고 시스템을 구축했습니다.</p>

<h2 id="개발-환경과-빌드-환경을-동일하게-만드는-방법">개발 환경과 빌드 환경을 동일하게 만드는 방법</h2>

<p>vscode는 서버에서 실행되는 container에 ssh로 접속하는 기능을 지원합니다. 또한 접속한 컨테이너에서 필요한 플러그인, 워크스페이스 설정 등을 하나의 파일 devcontainer.json으로 관리할 수 있습니다. 빌드 환경과 개발 환경이 완벽히 일치하기 때문에, 프로젝트를 배포할 때, 환경을 걱정할 필요가 없어졌습니다.</p>

<p>또한 서비스의 특정 도메인을 개발 컨테이너의 개발용 포트로 라우팅 했습니다. 이를 통해 라이브 서버를 https 도메인이 붙은 상태로 테스트할 수 있게 구현했습니다.</p>

<p><img alt="image" src="/images/9f0fbece-1a58-402c-855e-49e80f7becc6" /></p>

<p>이러한 환경 구성은 다양한 장점들이 있습니다. 모바일 기기나 윈도우 기기 등, 다양한 환경에서 화면이 어떻게 보이는 지 실시간으로 확인할 수 있어서, 배포 전에 개발된 기능들이 어떻게 동작 하는지 충분히 확인 할 수 있습니다. 더욱이 실제 개발 컨테이너는 서버에서 동작하기 때문에 ssh키만 있다면 어디서든지 개발환경에 바로 접속하여 개발이 가능합니다.</p>

<h2 id="개발-및-빌드에만-필요한-환경을-제외하고-배포-이미지를-만드는-방법">개발 및 빌드에만 필요한 환경을 제외하고 배포 이미지를 만드는 방법</h2>

<p>docker의 multi-stage build를 사용하면 빌드 환경과 배포 환경을 유사하게 가져가면서 불필요한 환경을 제외했습니다.</p>

<p><img alt="image" src="/images/e433667e-a34c-4a8c-a892-ed2eceb981dc" /></p>

<p>먼저 builder stage에서 프로젝트 개발 및 빌드에 필요한 환경을 구성하고 빌드합니다.  이후 server stage에서 빌드된 파일들을 가져와서 실행합니다.</p>

<h2 id="reference">Reference</h2>

<ul>
  <li>https://stackoverflow.com/questions/73007221/how-to-unit-test-a-transaction-wrapped-function-in-prisma</li>
  <li>https://telefunc.com/</li>
  <li>https://playwright.dev/</li>
  <li>https://nextjs.org/docs</li>
  <li>https://www.prisma.io/</li>
  <li>Martin, Robert C. 2017. Clean Architecture: A Craftsman’s Guide to Software Structure and Design. Prentice Hall.</li>
  <li>Martin, Robert C. 2008. Clean Code: A Handbook of Agile Software Craftsmanship. Prentice Hall.</li>
</ul>]]></content><author><name></name></author><category term="클린 아키텍쳐" /><summary type="html"><![CDATA[bdg.blog란?]]></summary></entry><entry><title type="html">온프레미스 서비스 개발 및 운영 기록 - 개발 동기, 디바이스 구성, 클러스터 구성, 형상 관리</title><link href="http://localhost:4000/%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4/2023/09/29/%EC%98%A8%ED%94%84%EB%A0%88%EB%AF%B8%EC%8A%A4-%EC%84%9C%EB%B9%84%EC%8A%A4-%EA%B0%9C%EB%B0%9C-%EB%B0%8F-%EC%9A%B4%EC%98%81-%EA%B8%B0%EB%A1%9D-%EA%B0%9C%EB%B0%9C-%EB%8F%99%EA%B8%B0-%EB%94%94%EB%B0%94%EC%9D%B4%EC%8A%A4-%EA%B5%AC%EC%84%B1-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0-%EA%B5%AC%EC%84%B1-%ED%98%95%EC%83%81-%EA%B4%80%EB%A6%AC.html" rel="alternate" type="text/html" title="온프레미스 서비스 개발 및 운영 기록 - 개발 동기, 디바이스 구성, 클러스터 구성, 형상 관리" /><published>2023-09-29T00:00:00+09:00</published><updated>2023-09-29T00:00:00+09:00</updated><id>http://localhost:4000/%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4/2023/09/29/%EC%98%A8%ED%94%84%EB%A0%88%EB%AF%B8%EC%8A%A4-%EC%84%9C%EB%B9%84%EC%8A%A4-%EA%B0%9C%EB%B0%9C-%EB%B0%8F-%EC%9A%B4%EC%98%81-%EA%B8%B0%EB%A1%9D-%EA%B0%9C%EB%B0%9C-%EB%8F%99%EA%B8%B0-%EB%94%94%EB%B0%94%EC%9D%B4%EC%8A%A4-%EA%B5%AC%EC%84%B1-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0-%EA%B5%AC%EC%84%B1-%ED%98%95%EC%83%81-%EA%B4%80%EB%A6%AC</id><content type="html" xml:base="http://localhost:4000/%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4/2023/09/29/%EC%98%A8%ED%94%84%EB%A0%88%EB%AF%B8%EC%8A%A4-%EC%84%9C%EB%B9%84%EC%8A%A4-%EA%B0%9C%EB%B0%9C-%EB%B0%8F-%EC%9A%B4%EC%98%81-%EA%B8%B0%EB%A1%9D-%EA%B0%9C%EB%B0%9C-%EB%8F%99%EA%B8%B0-%EB%94%94%EB%B0%94%EC%9D%B4%EC%8A%A4-%EA%B5%AC%EC%84%B1-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0-%EA%B5%AC%EC%84%B1-%ED%98%95%EC%83%81-%EA%B4%80%EB%A6%AC.html"><![CDATA[<p>bdg.blog는 온프레미스로 쿠버네티스 위에서 동작하는 블로그 서비스입니다. bdg.blog는 ‘AWS Route 53’과 ‘Github’을 제외한 모든 기능을 온프레미스로 배포하고 있습니다. 이번 포스트에서는 쿠버네티스를 활용한 온프레미스 CI/CD 파이프라인의 구축 경험을 소개합니다.</p>

<hr />

<ul>
  <li>개발 동기
    <ul>
      <li>비용 문제</li>
      <li>공부 목적</li>
    </ul>
  </li>
  <li>디바이스 구성</li>
  <li>클러스터 구성
    <ul>
      <li>Kubernetes - K3s</li>
      <li>bdg.blog</li>
      <li>Harbor</li>
      <li>Minio</li>
      <li>Argo Events, Workflows, CD</li>
    </ul>
  </li>
  <li>형상 관리
    <ul>
      <li>kustomization</li>
      <li>helm chart + kustomization</li>
    </ul>
  </li>
</ul>

<hr />
<h1 id="개발-동기">개발 동기</h1>

<h2 id="비용-문제">비용 문제</h2>

<p>처음 블로그 서비스를 배포했을 때는 AWS를 사용했습니다. 컨테이너 없이 AWS 위에 서버를 실행해서 배포하는 구조로 간단한 구조였습니다. 하지만 가장 낮은 스팩으로 배포하더라도 데이터베이스 비용, 인스턴스 운영 비용이 발생한다는 단점이 있었습니다.</p>

<h2 id="공부-목적">공부 목적</h2>

<p>온프레미스에서 앱, DB, 스토리지 서버, CI/CD 파이프라인을 모두 구축하는 것은 상업적 관점에서 봤을 때 비효율적입니다. 하지만 클라우드에서 해결해주는 여러 문제를 직접 겪어 보면 시스템을 공부하는 데 큰 도움이 될 것으로 생각해 이 프로젝트를 시작했습니다.</p>

<h1 id="디바이스-구성">디바이스 구성</h1>

<p>2개의 노트북을 묶어 하나의 쿠버네티스 클러스터를 구성했습니다. 네트워크 스위치는 가정용 공유기를 사용하고 있으며, Public IP의 80 포트, 443 포트가 이 클러스터로 연결됩니다.</p>

<p><img alt="image" src="/images/93f29256-b61c-482b-b132-6f3cc79e3750" /></p>

<ul>
  <li>2개의 노트북으로 구성</li>
  <li>ubuntu 22.04</li>
  <li>k3s v1.25.7</li>
</ul>

<h3 id="비용-측면">비용 측면</h3>

<p>위의 구성으로 24시간동안 항상 서버를 실행하고 있습니다. 혼자 사는데 필요한 생활 전력(냉장고, 에어컨, 각종 전자기기, 데스크탑 컴퓨터)을 포함하여 전기세를 한달에 2 ~ 3만원 정도 지출하고 있습니다. 생활 전기 비용이 포함되어 있기 때문에 명확한 비교는 힘들지만, 크게 부담되는 비용은 아닙니다. 만약 이 서비스를 모두 AWS에서 운영했을 때와 비교해도 비용면에서 충분히 효율적이라고 판단했습니다.</p>

<h1 id="클러스터-구성">클러스터 구성</h1>

<p>하나의 쿠버네티스 클러스터에 아래 앱들이 고유의 namespace를 가지고 운영되고 있습니다. 형상을 정의하는 yaml파일들은 github에 저장되며, 아래 링크에서 확인하실 수 있습니다.</p>

<ul>
  <li>https://github.com/deagwon97/bdg-blog-v2/tree/main/deploy</li>
</ul>

<p><img alt="image" src="/images/45520b0d-a4b4-4a2a-82ed-c6265293a5f5" /></p>

<h3 id="kubernetes---k3s">Kubernetes - K3s</h3>

<p>구축하려는 클러스터는 고성능 서버가 아닌 노트북 위에 설치해야 합니다. 실제 K8s와 호환되면서도 Edge Device에서 잘 동작하는 K3s로 클러스터를 구성하기로 했습니다. K3s는 containerd(컨테이너 런타임), flannel (CNI), traefik(Ingress Controller)를 기본 설정으로 사용합니다. 다른 옵션을 구성할 수도 있지만, 불필요하다고 판단하고 기본 설정을 그대로 사용했습니다.</p>

<h3 id="bdgblog">bdg.blog</h3>

<p>NextJs로 개발한 블로그 서비스입니다. 링크에 자세한 설명이 포함되어 있습니다.</p>

<ul>
  <li><a href="https://deagwon.com/post/bdg-blog%EB%A5%BC-%EB%A7%8C%EB%93%A4%EB%A9%B4%EC%84%9C-%EB%93%A4%EC%97%88%EB%8D%98-%EA%B3%A0%EB%AF%BC%EA%B3%BC-%ED%95%B4%EA%B2%B0-%EB%B0%A9%EB%B2%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8-%EA%B5%AC%EC%A1%B0-%EC%82%AC%EC%9A%A9%ED%95%9C-%EB%8F%84%EA%B5%AC-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%B0%A9%EB%B2%95-%EA%B0%9C%EB%B0%9C-%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%B6%95">https://deagwon.com/post/bdg-blog를-만들면서-들었던-고민과-해결-방법-프로그램-구조-사용한-도구-테스트-방법-개발-환경-구축</a></li>
</ul>

<h3 id="harbor">Harbor</h3>

<p>초기에는 AWS의 ECR를 사용했습니다. 비용 문제로인해서 Harbor로 이전하는 것을 선택했습니다.</p>

<h3 id="minio">Minio</h3>

<p>Image File을 저장하기 위한 Object Storage 입니다. bdg.blog에서는 minio에 이미지 다운로드 및 업로드를 위한 presigned url을 발급하여 클라이언트로 전달합니다. 클라이언트는 발급받은 URL로 minio 서버에 파일을 바로 업로드합니다.</p>

<h3 id="argo-events-workflows-cd">Argo Events, Workflows, CD</h3>

<p>CI/CD 구축을 위해서 사용한 도구들 입니다. 처음에는 Jenkins를 사용했지만, 잦은 plugin 업데이트 문제, 네이티브로 쿠버네티스 컨테이너를 지원하지 않는 문제 등을 이유로 Argo로 이전했습니다. 링크(<a href="https://deagwon.com/post/KubernetesArgoCD-Argo-WorkflowsEvents-%EB%8F%84%EC%9E%85%EA%B8%B0">https://deagwon.com/post/KubernetesArgoCD-Argo-WorkflowsEvents-도입기</a>)에 자세히 정리해 두었습니다.</p>
<ul>
  <li>마주했던 문제점<br />
 단순히 공식문서에 나온 방법으로 CI 파이프라인을 구축하면, namespcae별로 구분되는 argo ci를 구성할 수 없었습니다. namespace 속에 argoci를 구축한 후, 다른 namespace에 독립적인 argoci를 설치하려고 했었습니다. 분명히 namespace가 분리되어 있음에도 불구하고, 두 argoci는 동시에 동작하지 못 했습니다.</li>
  <li>원인<br />
 argo events와 argo workflows의 설치 스크립트를 살펴보면 CustomResourceDefinition 을 생성하며 ClusterRole 을 정의합니다. 그리고 이 둘은 하나의 Cluster Scope에서 동작합니다. 만약 B 프로젝트를 위해서 ClusterRole 수정하면, 기존의 A 프로젝트는 정상적으로 동작하지 못하게 되는 것입니다.</li>
  <li>해결책<br />
이 문제를 해결하기 위해 Cluster Scope에서 동작하는 CustomResourceDefinition 과 ClusterRole 는 따로 설치하고, namespace 범위에서 동작하는 자원들만 분리했더니 Argo Events, Argo CD 를 프로젝트단위로 설치할 수 있었습니다.</li>
</ul>

<p><img alt="image" src="/images/10b72dbd-da9b-42ee-9e1c-8d721dcf35fc" /></p>

<p><img alt="image" src="/images/730b1afc-d3c2-4809-86cf-5cbe4956ae5f" /></p>

<h1 id="형상-관리">형상 관리</h1>

<h2 id="kustomization">kustomization</h2>

<p>프로젝트의 모든 앱은 kustomization 으로 관리하고 있습니다. 아래와 같이 자원 명세를 작성하고 <code class="highlighter-rouge">kubectl apply -k</code> 명령을 통해서 배포합니다. 또한 이 명세서는 모두 git과 argo cd를 통해서 관리합니다. argo cd는 git에 올라간 형상과 실제 클러스터 형상을 비교하고 차이점을 알려 줍니다. (자동으로 형상을 동기화할 수 있지만, 현재는 형상이 잘 유지되고 있는지 확인하는 용도로만 사용합니다.)</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">------- production 폴더 구조 -------</span>
<span class="c1"># 프로비저닝 순서에 따라서 yaml 파일에 순서를 부여했습니다.</span>
<span class="s">production</span>
<span class="pi">|--</span> <span class="err">00namespace.yaml</span>
<span class="err">|</span><span class="s">-- 01dockerconfig.json # gitignore</span>
<span class="err">|</span><span class="s">-- 01dockerconfig.json.example</span>
<span class="err">|</span><span class="s">-- 01nextjs.env        # gitignore</span>
<span class="err">|</span><span class="s">-- 01nextjs.env.example</span>
<span class="err">|</span><span class="s">-- 03serviceAccount.yaml</span>
<span class="err">|</span><span class="s">-- 04deployment.yaml</span>
<span class="err">|</span><span class="s">-- 05service.yaml</span>
<span class="err">|</span><span class="s">-- 11issuer.yaml</span>
<span class="err">|</span><span class="s">-- 12certificate.yaml</span>
<span class="err">|</span><span class="s">-- 13middleWare.yaml</span>
<span class="err">|</span><span class="s">-- 14ingressRouter.yaml</span>
<span class="err">`</span><span class="s">-- kustomization.yaml</span>

<span class="err">-</span><span class="s">------ kustomization.yaml -------</span>
<span class="err">a</span><span class="s">piVersion: kustomize.config.k8s.io/v1beta1</span>
<span class="err">k</span><span class="s">ind: Kustomization</span>
<span class="err">n</span><span class="s">amespace: bdg-blog</span>
<span class="err">m</span><span class="s">etadata:</span>
  <span class="s">name: arbitrary</span>
<span class="err">#</span><span class="s"># generate secret only first time</span>
<span class="err">#</span><span class="s"> secretGenerator:</span>
<span class="err">#</span><span class="s">   - name: bdg-blog</span>
<span class="err">#</span><span class="s">     envs:</span>
<span class="err">#</span><span class="s">     - 01nextjs.env</span>
<span class="err">#</span><span class="s">   - name: bdg-blog-regcred</span>
<span class="err">#</span><span class="s">     files:</span>
<span class="err">#</span><span class="s">       - .dockerconfigjson=01dockerconfig.json</span>
<span class="err">#</span><span class="s">     type: kubernetes.io/dockerconfigjson</span>
<span class="err">r</span><span class="s">esources:</span>
  <span class="s">- 00namespace.yaml</span>
  <span class="s">- 03serviceAccount.yaml</span>
  <span class="s">- 04deployment.yaml</span>
  <span class="s">- 05service.yaml</span>
  <span class="s">- 11issuer.yaml</span>
  <span class="s">- 12certificate.yaml</span>
  <span class="s">- 13middleWare.yaml</span>
  <span class="s">- 14ingressRouter.yaml</span>
</code></pre></div></div>

<h2 id="helm-chart">Helm Chart</h2>

<p>쿠버네티스 패키지를 관리하는 방법은 kustomize 말고도 다양합니다. 일부 오픈 소스는 Helm Chart를 통해서 패키지를 배포하기도 합니다. 이 프로젝트에서 사용된 컨테이너 레지스트리 Harbor 또한 Helm Chart를 사용합니다.</p>

<p>하지만 Helm은 일부자원을 추가하는데 제약이 있습니다. 정의된 values.yaml 파일을 수정할 수만 있습니다. 만약 PersistentVoulme을 생성하거나, ingress, issuer와 같은 자원을 추가로 만들고 관리하기 위해서는 새로운 helm chart를 패키징해야 합니다.</p>

<p>저는 배포되는 Harbor의 Helm Chart를 그대로 사용하면서도, 원하는 자원들을 추가하기 위해 kustomize와 helm을 결합해서 사용했습니다.</p>

<p><img alt="image" src="/images/b2cf6afd-164f-4069-86d4-9236af39e4cd" /></p>

<p>이렇게 구성하면, 나중에 Harbor의 Helm Chart가 업데이트되더라도, 다시 Chart를 처음부터 작성하지 않고 해당 Chart의 버전만 업데이트할 수 있습니다. 또한, 형상이 모두 코드로 표현되기 때문에, ArgoCD를 통한 Continuous Deployment가 가능합니다.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">kustomize.config.k8s.io/v1beta1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Kustomization</span>
<span class="na">namespace</span><span class="pi">:</span> <span class="s">bdg-blog-harbor</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">bdg-blog-harbor</span>
<span class="na">generatorOptions</span><span class="pi">:</span>
  <span class="na">disableNameSuffixHash</span><span class="pi">:</span> <span class="no">true</span>
<span class="na">resources</span><span class="pi">:</span>
<span class="pi">-</span> <span class="s">00namespace.yaml</span>
<span class="pi">-</span> <span class="s">01harbor-pv.yaml</span>
<span class="pi">-</span> <span class="s">02harbor-pvc.yaml</span>
<span class="pi">-</span> <span class="s">03issuer.yaml</span>
<span class="pi">-</span> <span class="s">04certificate.yaml</span>
<span class="pi">-</span> <span class="s">05ingress.yaml</span>
<span class="na">helmCharts</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">includeCRDs</span><span class="pi">:</span> <span class="no">true</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">harbor</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">bdg-blog-harbor</span>
  <span class="na">releaseName</span><span class="pi">:</span> <span class="s">harbor</span>
  <span class="na">repo</span><span class="pi">:</span> <span class="s">https://helm.goharbor.io</span>
  <span class="na">valuesFile</span><span class="pi">:</span> <span class="s">06harbor-helm-values.yaml</span>
  <span class="na">version</span><span class="pi">:</span> <span class="s">1.11.1</span>
</code></pre></div></div>

<p>주의할 점은 argocd config에서 <code class="highlighter-rouge">enable-helm</code>을 설정해야 helmChart를 argocd에서 사용할 수 있습니다.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ConfigMap</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">argocd-cm</span>
<span class="na">data</span><span class="pi">:</span>
  <span class="na">kustomize.buildOptions</span><span class="pi">:</span> <span class="s">--enable-helm</span>
  <span class="s">...</span>
</code></pre></div></div>

<h1 id="클러스터-구조-및-의존-관계">클러스터 구조 및 의존 관계</h1>

<p><img alt="image" src="/images/9b7a70fc-5581-4232-b467-1132e9f916f0" /></p>

<p>쿠버네티스 클러스터에는 다양한 서비스들이 동작하며, 네임스페이스를 통해 구분됩니다. 앱의 소스 코드 및 배포를 위한 명세 파일은 하나의 GitHub 레포지토리에서 관리됩니다.</p>

<ul>
  <li>MariaDB, Redis, Minio, NextJS 로 구성된 블로그</li>
  <li>CI/CD tools: kaniko, harbor, argo workflows, argo events, argo cd</li>
</ul>

<h3 id="continuous-integration----검은색-화살표">Continuous Integration -  검은색 화살표</h3>

<p>소스코드를 git에 push하면서 발생하는 일련의 자동 배포 과정입니다. git은 argo events에 webhook을 보내고, argo events는 정해진 workflow를 실행하면서 kaniko로 컨테이너 이미지를 빌드합니다. 이후 빌드가 완료되면 이미지를 harbor repository에 push합니다. 마지막으로 <code class="highlighter-rouge">kubectl restart rollout deployment bdg-blog -n bdg-blog</code> 명령어를 실행하면서 기존의 컨테이너들을 교체하면서 소스코드가 서비스에 적용됩니다.</p>

<h3 id="continuous-delivery---주황색-화살표">Continuous Delivery - 주황색 화살표</h3>

<p>ArgoCD를 활용한 Continuous Delivery  과정입니다. bdg.blog의 클러스터 명세는 secret 및 config 설정을 제외한 모든 코드가 kustomization.yaml 파일에 작성되어 있고, 이 파일은 동일한 git repository에 저장됩니다. 클러스터 명세를 수정하여 git에 push하면, ArgoCD는 이 명세의 설정과 클러스터의 상태를 비교하여 변경사항을 반영하도록 구성했습니다.</p>

<h3 id="network-flow---파란색-화살표">Network Flow - 파란색 화살표</h3>

<p>Ingress 컨트롤러인 traefik이 외부에서 들어오는 요청을 중계하는 과정을 보여줍니다. bdg.blog 외에도 harbor, minio, argo 모두 관리용 web ui를 제공합니다. 클라이언트가 요청한 도메인에 따라서 적절한 앱으로 요청이 라우팅 됩니다.</p>

<h2 id="reference">Reference</h2>

<ul>
  <li>https://k3s.io/</li>
  <li>https://goharbor.io/</li>
  <li>https://min.io/</li>
  <li>https://argoproj.github.io/</li>
  <li>https://kustomize.io/</li>
  <li>https://helm.sh/</li>
  <li>https://trstringer.com/helm-kustomize/</li>
</ul>]]></content><author><name></name></author><category term="쿠버네티스" /><summary type="html"><![CDATA[bdg.blog는 온프레미스로 쿠버네티스 위에서 동작하는 블로그 서비스입니다. bdg.blog는 ‘AWS Route 53’과 ‘Github’을 제외한 모든 기능을 온프레미스로 배포하고 있습니다. 이번 포스트에서는 쿠버네티스를 활용한 온프레미스 CI/CD 파이프라인의 구축 경험을 소개합니다.]]></summary></entry><entry><title type="html">chatting app 개발</title><link href="http://localhost:4000/%EB%B0%B1%EC%95%A4%EB%93%9C/2023/09/24/chatting-app-%EA%B0%9C%EB%B0%9C.html" rel="alternate" type="text/html" title="chatting app 개발" /><published>2023-09-24T00:00:00+09:00</published><updated>2023-09-24T00:00:00+09:00</updated><id>http://localhost:4000/%EB%B0%B1%EC%95%A4%EB%93%9C/2023/09/24/chatting-app-%EA%B0%9C%EB%B0%9C</id><content type="html" xml:base="http://localhost:4000/%EB%B0%B1%EC%95%A4%EB%93%9C/2023/09/24/chatting-app-%EA%B0%9C%EB%B0%9C.html"><![CDATA[<p>토이 프로젝트로 익명 채팅방을 만들었습니다. websocket을 통해서 사용자가 서버에 메시지을 보내면 서버는 다른 사용자에게 메시지를 전달하는 간단한 프로젝트 입니다. 채팅 앱은 bdg.blog 소스코드에 포함되어 있습니다.</p>

<ul>
  <li>앱 링크: <a href="https://deagwon.com/chat">bdg.chat</a></li>
  <li>github: https://github.com/deagwon97/bdg-blog-v2/</li>
</ul>

<p><img alt="image" src="/images/f370aa56-4261-4cbc-b0ac-c390168b9cd5" /></p>

<h3 id="기능-명세">기능 명세</h3>

<p>우선 구체적인 기능을 글로 정리했습니다.</p>

<ul>
  <li>사용자는 채팅방에 입장하는 순간 랜덤하게 이름을 부여받는다.</li>
  <li>사용자가 채팅방에 입장하면 기존에 채팅방에 입장한 사람들은 “XX가 입장했습니다.”라는 메세지를 받는다.</li>
  <li>사용자가 텍스트를 입력하고 엔터키 혹은 전송 버튼을 누르면 메시지가 서버로 전달된다.</li>
  <li>서버는 사용자가 전송한 메시지와 사용자의 이름을 다른 사용자들에게 전송한다.</li>
  <li>사용자가 브라우저는 닫거나 다른 페이지로 이동하면 기존에 채팅방에 입장한 사람들은 “XX가 나갔습니다.”라는 메시지를 받는다.</li>
</ul>

<h3 id="고려사항">고려사항</h3>

<p>bdg blog는 2개의 replicaSet을 가지는 deployment으로 배포됩니다. 서로 다른 pod가 채팅방의 메시지를 공유하기 위해서는 메시지 브로커가 필요합니다.</p>

<p><img alt="image" src="/images/5dafabf7-2818-4604-861c-d3c754fb825f" /></p>

<h2 id="구현">구현</h2>

<h3 id="서버">서버</h3>

<p>서버가 실행되는 시점에 메시지 브로커 redis와 연결되는 publisher객체와 subscriber객체를 싱글톤으로 생성합니다. 이후 서버는 클라이언트의 web socket connection 생성하는 요청을 기다립니다.</p>

<div class="language-tsx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// server/chat/redisSingleton.ts</span>
<span class="k">import</span> <span class="p">{</span> <span class="nx">Redis</span> <span class="p">}</span> <span class="k">from</span> <span class="dl">'</span><span class="s1">ioredis</span><span class="dl">'</span>

<span class="kd">const</span> <span class="nx">globalRedis</span> <span class="o">=</span> <span class="nx">globalThis</span> <span class="k">as</span> <span class="nx">unknown</span> <span class="k">as</span> <span class="p">{</span>
  <span class="na">redisPub</span><span class="p">:</span> <span class="nx">Redis</span> <span class="o">|</span> <span class="kc">undefined</span>
  <span class="na">redisSub</span><span class="p">:</span> <span class="nx">Redis</span> <span class="o">|</span> <span class="kc">undefined</span>
<span class="p">}</span>

<span class="k">export</span> <span class="kd">const</span> <span class="nx">redisPub</span> <span class="o">=</span>
  <span class="nx">globalRedis</span><span class="p">.</span><span class="nx">redisPub</span> <span class="o">??</span>
  <span class="k">new</span> <span class="nx">Redis</span><span class="p">({</span>
    <span class="na">host</span><span class="p">:</span> <span class="nx">process</span><span class="p">.</span><span class="nx">env</span><span class="p">.</span><span class="nx">NEXT_PUBLIC_REDIS_HOST</span>
  <span class="p">})</span>

<span class="k">export</span> <span class="kd">const</span> <span class="nx">getRedisSub</span> <span class="o">=</span> <span class="k">async</span> <span class="p">()</span> <span class="o">=&gt;</span> <span class="p">{</span>
  <span class="k">if</span> <span class="p">(</span><span class="nx">globalRedis</span><span class="p">.</span><span class="nx">redisSub</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="nx">globalRedis</span><span class="p">.</span><span class="nx">redisSub</span>
  <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="nx">globalRedis</span><span class="p">.</span><span class="nx">redisSub</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Redis</span><span class="p">({</span>
      <span class="na">host</span><span class="p">:</span> <span class="nx">process</span><span class="p">.</span><span class="nx">env</span><span class="p">.</span><span class="nx">NEXT_PUBLIC_REDIS_HOST</span>
    <span class="p">})</span>
    <span class="k">await</span> <span class="nx">globalRedis</span><span class="p">.</span><span class="nx">redisSub</span><span class="p">.</span><span class="nx">subscribe</span><span class="p">(</span><span class="dl">'</span><span class="s1">bdg-chat-user-data</span><span class="dl">'</span><span class="p">,</span> <span class="p">(</span><span class="nx">err</span><span class="p">,</span> <span class="nx">count</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
      <span class="k">if</span> <span class="p">(</span><span class="nx">err</span><span class="p">)</span> <span class="p">{</span>
        <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="s2">``</span><span class="na">error</span><span class="p">:</span> <span class="nx">Subscribed</span> <span class="nx">to</span> <span class="nx">NULL</span> <span class="nx">channels</span><span class="p">.</span> <span class="nx">NULL</span><span class="s2">``</span><span class="p">)</span>
      <span class="p">}</span>
    <span class="p">})</span>
    <span class="k">return</span> <span class="nx">globalRedis</span><span class="p">.</span><span class="nx">redisSub</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<div class="language-tsx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// server/chat/chatSocketHandler.ts</span>
<span class="k">import</span> <span class="p">{</span> <span class="nx">NextApiRequest</span> <span class="p">}</span> <span class="k">from</span> <span class="dl">'</span><span class="s1">next</span><span class="dl">'</span>
<span class="k">import</span> <span class="p">{</span> <span class="nx">Server</span> <span class="p">}</span> <span class="k">from</span> <span class="dl">'</span><span class="s1">socket.io</span><span class="dl">'</span>
<span class="k">import</span> <span class="p">{</span> <span class="nx">NextApiResponseWithSocket</span> <span class="p">}</span> <span class="k">from</span> <span class="dl">'</span><span class="s1">socket.d</span><span class="dl">'</span>
<span class="k">import</span> <span class="p">{</span> <span class="nx">redisPub</span><span class="p">,</span> <span class="nx">getRedisSub</span> <span class="p">}</span> <span class="k">from</span> <span class="dl">'</span><span class="s1">server/chat/redisSingleton</span><span class="dl">'</span>
<span class="k">import</span> <span class="nx">Redis</span> <span class="k">from</span> <span class="dl">'</span><span class="s1">ioredis</span><span class="dl">'</span>

<span class="kd">let</span> <span class="nx">io</span><span class="p">:</span> <span class="nx">Server</span> <span class="o">|</span> <span class="kc">null</span> <span class="o">=</span> <span class="kc">null</span>
<span class="kd">let</span> <span class="nx">redisSub</span><span class="p">:</span> <span class="nx">Redis</span> <span class="o">|</span> <span class="kc">null</span> <span class="o">=</span> <span class="kc">null</span>

<span class="kd">const</span> <span class="nx">ChatSocketHandler</span> <span class="o">=</span> <span class="k">async</span> <span class="p">(</span>
  <span class="nx">_</span><span class="p">:</span> <span class="nx">NextApiRequest</span><span class="p">,</span>
  <span class="nx">res</span><span class="p">:</span> <span class="nx">NextApiResponseWithSocket</span>
<span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
  <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="nx">res</span><span class="p">.</span><span class="nx">socket</span><span class="p">.</span><span class="nx">server</span><span class="p">.</span><span class="nx">io</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="nx">io</span><span class="p">)</span> <span class="p">{</span>
      <span class="nx">io</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Server</span><span class="p">(</span><span class="nx">res</span><span class="p">.</span><span class="nx">socket</span><span class="p">.</span><span class="nx">server</span><span class="p">)</span>
    <span class="p">}</span>
    <span class="nx">res</span><span class="p">.</span><span class="nx">socket</span><span class="p">.</span><span class="nx">server</span><span class="p">.</span><span class="nx">io</span> <span class="o">=</span> <span class="nx">io</span>
    <span class="kd">let</span> <span class="nx">userName</span> <span class="o">=</span> <span class="dl">''</span>

    <span class="c1">// create websocket connection</span>
    <span class="c1">// when new client connects</span>
    <span class="nx">io</span><span class="p">.</span><span class="nx">on</span><span class="p">(</span><span class="dl">'</span><span class="s1">connection</span><span class="dl">'</span><span class="p">,</span> <span class="k">async</span> <span class="p">(</span><span class="nx">socket</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
      <span class="c1">// create redis sub</span>
      <span class="nx">redisSub</span> <span class="o">=</span> <span class="k">await</span> <span class="nx">getRedisSub</span><span class="p">()</span>

      <span class="nx">socket</span><span class="p">.</span><span class="nx">on</span><span class="p">(</span><span class="dl">'</span><span class="s1">client-server-chat</span><span class="dl">'</span><span class="p">,</span> <span class="p">(</span><span class="nx">msg</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
        <span class="nx">userName</span> <span class="o">=</span> <span class="nx">msg</span><span class="p">?.</span><span class="nx">userName</span> <span class="k">as</span> <span class="kr">string</span>
        <span class="nx">redisPub</span><span class="p">.</span><span class="nx">publish</span><span class="p">(</span>
          <span class="dl">'</span><span class="s1">bdg-chat-user-data</span><span class="dl">'</span><span class="p">,</span>
          <span class="nx">JSON</span><span class="p">.</span><span class="nx">stringify</span><span class="p">({</span>
            <span class="p">...{</span>
              <span class="na">message</span><span class="p">:</span> <span class="nx">msg</span>
            <span class="p">}</span>
          <span class="p">})</span>
        <span class="p">)</span>
      <span class="p">})</span>

      <span class="nx">socket</span><span class="p">.</span><span class="nx">on</span><span class="p">(</span><span class="dl">'</span><span class="s1">disconnect</span><span class="dl">'</span><span class="p">,</span> <span class="p">()</span> <span class="o">=&gt;</span> <span class="p">{</span>
        <span class="nx">redisPub</span><span class="p">.</span><span class="nx">publish</span><span class="p">(</span>
          <span class="dl">'</span><span class="s1">bdg-chat-user-data</span><span class="dl">'</span><span class="p">,</span>
          <span class="nx">JSON</span><span class="p">.</span><span class="nx">stringify</span><span class="p">({</span>
            <span class="p">...{</span>
              <span class="na">message</span><span class="p">:</span> <span class="p">{</span>
                <span class="na">type</span><span class="p">:</span> <span class="dl">'</span><span class="s1">notice</span><span class="dl">'</span><span class="p">,</span>
                <span class="na">userName</span><span class="p">:</span> <span class="nx">userName</span><span class="p">,</span>
                <span class="na">message</span><span class="p">:</span> <span class="s2">``</span><span class="nx">NULL님이</span> <span class="nx">나갔습니다</span><span class="p">.</span><span class="s2">``</span>
              <span class="p">}</span>
            <span class="p">}</span>
          <span class="p">})</span>
        <span class="p">)</span>
        <span class="nx">socket</span><span class="p">.</span><span class="nx">disconnect</span><span class="p">()</span>
        <span class="k">return</span>
      <span class="p">})</span>

      <span class="nx">redisSub</span><span class="p">.</span><span class="nx">on</span><span class="p">(</span><span class="dl">'</span><span class="s1">message</span><span class="dl">'</span><span class="p">,</span> <span class="p">(</span><span class="nx">_</span><span class="p">,</span> <span class="nx">message</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
        <span class="kd">const</span> <span class="nx">redisMessage</span> <span class="o">=</span> <span class="nx">JSON</span><span class="p">.</span><span class="nx">parse</span><span class="p">(</span><span class="nx">message</span><span class="p">)</span>
        <span class="nx">socket</span><span class="p">.</span><span class="nx">emit</span><span class="p">(</span><span class="dl">'</span><span class="s1">server-client-chat</span><span class="dl">'</span><span class="p">,</span> <span class="nx">redisMessage</span><span class="p">.</span><span class="nx">message</span><span class="p">)</span>
      <span class="p">})</span>
    <span class="p">})</span>
  <span class="p">}</span>
  <span class="nx">res</span><span class="p">.</span><span class="nx">end</span><span class="p">()</span>
<span class="p">}</span>

<span class="k">export</span> <span class="k">default</span> <span class="nx">ChatSocketHandler</span>
</code></pre></div></div>

<h3 id="클라이언트">클라이언트</h3>

<p>사용자가 채팅방에 입장하는 순간 이름을 서버로부터 이름을 부여받습니다. 이후 webSocket을 연결하고, 부여받은 이름을 통해서 입장 메시지를 서버에 전달합니다.</p>

<p>다음부터는 <code class="highlighter-rouge">socket.emit</code> 함수와 <code class="highlighter-rouge">socket.on</code> 함수를 사용해 서버로부터 메시지를 주고받도록 구현했습니다.</p>

<div class="language-tsx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">const</span> <span class="nx">initSocketCallback</span> <span class="o">=</span> <span class="nx">useCallback</span><span class="p">(</span><span class="k">async</span> <span class="p">()</span> <span class="o">=&gt;</span> <span class="p">{</span>
  <span class="k">if</span> <span class="p">(</span><span class="nx">userName</span> <span class="o">===</span> <span class="dl">''</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span>
  <span class="p">}</span>
  <span class="k">await</span> <span class="nx">fetch</span><span class="p">(</span><span class="dl">'</span><span class="s1">/api/socket</span><span class="dl">'</span><span class="p">)</span>
  <span class="nx">socket</span> <span class="o">=</span> <span class="nx">io</span><span class="p">(</span><span class="dl">''</span><span class="p">,</span> <span class="p">{</span>
    <span class="na">path</span><span class="p">:</span> <span class="dl">'</span><span class="s1">/socket.io</span><span class="dl">'</span><span class="p">,</span>
    <span class="na">transports</span><span class="p">:</span> <span class="p">[</span><span class="dl">'</span><span class="s1">websocket</span><span class="dl">'</span><span class="p">],</span>
    <span class="na">secure</span><span class="p">:</span> <span class="nx">process</span><span class="p">.</span><span class="nx">env</span><span class="p">.</span><span class="nx">NODE_ENV</span> <span class="o">===</span> <span class="dl">'</span><span class="s1">production</span><span class="dl">'</span>
  <span class="p">})</span> <span class="k">as</span> <span class="nx">Socket</span>

  <span class="nx">socket</span><span class="p">.</span><span class="nx">emit</span><span class="p">(</span><span class="dl">'</span><span class="s1">client-server-chat</span><span class="dl">'</span><span class="p">,</span> <span class="p">{</span>
    <span class="na">type</span><span class="p">:</span> <span class="dl">'</span><span class="s1">notice</span><span class="dl">'</span><span class="p">,</span>
    <span class="na">userName</span><span class="p">:</span> <span class="nx">userName</span><span class="p">,</span>
    <span class="na">message</span><span class="p">:</span> <span class="s2">``</span><span class="nx">NULL님이</span> <span class="nx">입장했습니다</span><span class="p">.</span><span class="s2">``</span>
  <span class="p">}</span> <span class="k">as</span> <span class="nx">ChatMessage</span><span class="p">)</span>

  <span class="nx">socket</span><span class="p">.</span><span class="nx">on</span><span class="p">(</span><span class="dl">'</span><span class="s1">server-client-chat</span><span class="dl">'</span><span class="p">,</span> <span class="p">(</span><span class="nx">msg</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
    <span class="nx">setChatMessageList</span><span class="p">((</span><span class="nx">chatMessageList</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">[...</span><span class="nx">chatMessageList</span><span class="p">,</span> <span class="nx">msg</span><span class="p">])</span>
  <span class="p">})</span>
	<span class="p">},</span> <span class="p">[</span><span class="nx">userName</span><span class="p">]</span>
<span class="p">)</span>

<span class="nx">useEffect</span><span class="p">(()</span> <span class="o">=&gt;</span> <span class="p">{</span>
  <span class="nx">initSocketCallback</span><span class="p">()</span>
<span class="p">},</span> <span class="p">[</span><span class="nx">initSocketCallback</span><span class="p">])</span>

<span class="kd">const</span> <span class="nx">sendChat</span> <span class="o">=</span> <span class="p">()</span> <span class="o">=&gt;</span> <span class="p">{</span>
  <span class="k">if</span> <span class="p">(</span><span class="nx">input</span> <span class="o">===</span> <span class="dl">''</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span>
  <span class="p">}</span>
  <span class="k">if</span> <span class="p">(</span><span class="nx">socket</span> <span class="o">===</span> <span class="kc">null</span><span class="p">)</span> <span class="p">{</span>
    <span class="nx">initSocketCallback</span><span class="p">()</span>
    <span class="k">return</span>
  <span class="p">}</span>
  <span class="nx">socket</span><span class="p">.</span><span class="nx">emit</span><span class="p">(</span><span class="dl">'</span><span class="s1">client-server-chat</span><span class="dl">'</span><span class="p">,</span> <span class="p">{</span>
    <span class="na">type</span><span class="p">:</span> <span class="dl">'</span><span class="s1">chat</span><span class="dl">'</span><span class="p">,</span>
    <span class="na">userName</span><span class="p">:</span> <span class="nx">userName</span><span class="p">,</span>
    <span class="na">message</span><span class="p">:</span> <span class="nx">input</span>
  <span class="p">}</span> <span class="k">as</span> <span class="nx">ChatMessage</span><span class="p">)</span>
  <span class="nx">setInput</span><span class="p">(</span><span class="dl">''</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div>

<h3 id="reference">Reference</h3>

<ul>
  <li>https://github.com/redis/ioredis</li>
  <li>https://github.com/socketio/socket.io-client</li>
</ul>]]></content><author><name></name></author><category term="백앤드" /><summary type="html"><![CDATA[토이 프로젝트로 익명 채팅방을 만들었습니다. websocket을 통해서 사용자가 서버에 메시지을 보내면 서버는 다른 사용자에게 메시지를 전달하는 간단한 프로젝트 입니다. 채팅 앱은 bdg.blog 소스코드에 포함되어 있습니다.]]></summary></entry><entry><title type="html">NFS에서 분산 파일 시스템 Glusterfs로 전환</title><link href="http://localhost:4000/%EA%B8%B0%ED%83%80/2023/09/16/NFS%EC%97%90%EC%84%9C-%EB%B6%84%EC%82%B0-%ED%8C%8C%EC%9D%BC-%EC%8B%9C%EC%8A%A4%ED%85%9C-Glusterfs%EB%A1%9C-%EC%A0%84%ED%99%98.html" rel="alternate" type="text/html" title="NFS에서 분산 파일 시스템 Glusterfs로 전환" /><published>2023-09-16T00:00:00+09:00</published><updated>2023-09-16T00:00:00+09:00</updated><id>http://localhost:4000/%EA%B8%B0%ED%83%80/2023/09/16/NFS%EC%97%90%EC%84%9C-%EB%B6%84%EC%82%B0-%ED%8C%8C%EC%9D%BC-%EC%8B%9C%EC%8A%A4%ED%85%9C-Glusterfs%EB%A1%9C-%EC%A0%84%ED%99%98</id><content type="html" xml:base="http://localhost:4000/%EA%B8%B0%ED%83%80/2023/09/16/NFS%EC%97%90%EC%84%9C-%EB%B6%84%EC%82%B0-%ED%8C%8C%EC%9D%BC-%EC%8B%9C%EC%8A%A4%ED%85%9C-Glusterfs%EB%A1%9C-%EC%A0%84%ED%99%98.html"><![CDATA[<p>기존의 파일시스템은 모든 Client 노드가 하나의 물리적 볼륨을 공유하는 NFS 를 사용하고 있었습니다.  NFS에 연결된 노드 수와 사용량이 증가하면서 NFS I/O 속도가 감소하고, 메타 데이터가 충돌하는 등 여러 문제가 발생했습니다. 아무리 하드웨어 레벨에서 RAID 6로 묶여있더라도, 100대의 노드에서 발생하는 모든 파일 입출력을 감당하는 것은 성능과 안정성에 문제가 있다고 판단했습니다. 여러 분산 파일 시스템을 조사한 후 glusterfs를 도입하기로 결정했습니다.</p>

<p>실험에 사용한 소스코드는 아래 깃허브 링크를 참고해주시기 바랍니다.</p>
<ul>
  <li>https://github.com/deagwon97/glusterfs-performance</li>
</ul>

<p><img alt="image" src="/images/b35d3cdf-e3c5-4477-890c-9c5c40f447fd" /></p>

<p>현재 사용하고 있는 클러스터는 40GBps(최소 20GBps ~ 최대 40GBps)의 네트워크 대역폭을 가지며 단일 NFS 서버의 I/O 컨트롤러 대역폭은 약 300MBps(RAID Controller, 64 bits width, 33MHz clock)입니다. 메모리 및 CPU 성능은 충분히 높기 때문에, 하드디스크 컨트롤러에서 I/O 병목이 발생한다는 것을 알 수 있습니다. 분산 파일 시스템은 이러한 I/O 컨트롤러 병목 현상을 일부 해소할 수 있습니다.</p>

<p><img alt="image" src="/images/9ed0f095-3218-4982-a333-47f5c0220913" /></p>

<p>분산 파일 시스템은 NFS와 다르게 파일들을 여러개 노드에 분산하여 저장합니다. 파일을 저장하는 방식에 따라서 I/O 대역폭이 최대 “단일 I/O 대역폭 * 서버 수“ 만큼 올라갑니다. 또한 스토리지 공간과 성능을 최대로 사용하지 않고, erasure code나 데이터 복제를 사용하면 내결함성(Fault Tolerance)을 높일 수 도 있습니다.</p>

<p>glusterfs는 다양한 구조를 지원합니다. 성능을 극대화하는 조합(distribute), 안정성을 극대화하는 조합(replicated), 성능과 안정성을 추구하면서 저장공간 효율을 높이는 조합(dispersed) 등으로 볼륨을 구성할 수 있습니다. 현재 운행중인 클러스터에 가장 적합한 조합을 찾기위해 각 조합별 성능을 평가하는 실험을 진행했습니다.</p>

<h1 id="glusterfs-란">glusterfs 란?</h1>

<p>실험 소개에 앞서 glusterfs에서 사용되는 용어와 구조에 대해서 간단하게 알아보겠습니다.</p>

<table>
  <tbody>
    <tr>
      <td>glusterfs는 클라우드 스토리지 및 미디어 스트리밍과 같은 데이터 집약적인 작업에 적합한 확장성있는 네트워크 파일 시스템입니다.</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>
    <p><strong>Brick 이란?</strong></p>

    <p>Brick이란 Glusterfs의 기본 스토리지 단위 이며 리눅스 파일 시스템에서 폴더로 표현됩니다. 디스크 볼륨 전체를 brick으로 사용할 수도 있고, 디스크 볼륨을 나누어 여러개의 brick을 구성할 수도 있습니다.</p>
  </li>
</ul>

<p>각 스토리지 서버에서 관리 데몬(glusterd)이 서로 통신하며 brick process(glusterfsd)를 관리합니다. brick process(glusterfsd)는 기본 디스크 저장소(XFS Filesystem)에 접근해 전달받을 요청을 수행합니다. 사용자는 FUSE를 통해서 만들어진 gluster 파일 시스템에 마운트하여 데이터에 접근합니다. 각 노드들은 TCP/IP 혹은 RDMA 를 통해서 통신할 수 있습니다.</p>

<p>여러 기업과 기관에서 N PB 크기의  파일 시스템 볼륨을 구성하여 운영하는 사례를 찾아볼 수 있을 만큼, 높은 용량의 분산 파일 시스템을 구축할 수 있습니다.</p>

<p><img alt="image" src="/images/4895724c-f261-4353-9ac2-e85296920991" /></p>

<h1 id="glusterfs-볼륨-유형">glusterfs 볼륨 유형</h1>

<p>앞에서 glusterfs는 다양한 볼륨 유형 갖는다고 언급했습니다. 유형별 구조와 특징을 알아보겠습니다.</p>

<h3 id="1-distributed-glusterfs-volume">1. Distributed Glusterfs Volume</h3>

<p>glusterfs의 가장 기본적인 형태입니다. 저장할 파일들을 각각 서로다른 brick에 나누어 저장합니다. brick을 추가하는 만큼 저장공간을 그대로 확장할 수 있습니다. 또한 서로 다른 brick에 io 컨트롤러가 각각 존재한다면, 다중 파일의 IO 속도가 brick의 수 만큼 증가합니다. 한마디로 가장 안정성이 떨어지지만, 가장 높은 성능을 보이는 볼륨입니다.</p>

<ul>
  <li>여러개의 파일들을 #bricks 만큼 나누어 각각의 brick에 저장</li>
  <li>하나의 brick 이라도 손실될 경우, 데이터 무결성이 깨짐</li>
  <li>전체 클러스터 용량 = 단일 brick 용량 * #bricks</li>
  <li>네트워크 대역폭은 NFS와 동일하게 소비</li>
  <li>단일 파일 I/O 속도 = brick I/O 속도</li>
  <li>다중 파일 동시 I/O 속도 = brick I/O 속도 * #bricks (네트워크 속도는 고려하지 않음)</li>
</ul>

<p><img alt="image" src="/images/c232439e-a4b4-401c-bf19-d3db62f82387" /></p>

<h3 id="2-replicated-glusterfs-volume">2. <strong>**Replicated Glusterfs Volume</strong>**</h3>

<p>극단적인 안정성을 추구하는 볼륨입니다. 모든 파일들을 각 brick에 저장합니다. 따라서 모든 brick이 동시에 고장나지 않는 이상 전체 데이터의 무결성이 지켜집니다. 하지만, brick 수를 늘리더라도 저장할 수 있는 데이터의 양은 고정됩니다. 또한 파일을 복제하는 overhead와 네트워크 사용량의 증가로 IO 속도는 감소합니다.</p>

<ul>
  <li>사용가능한 전체 클러스터 용량 = 단일 brick 용량</li>
  <li>다중/단일 파일 I/O 속도 = brick I/O 속도 - 파일 복제 속도</li>
  <li>네트워크 대역폭을 #bricks 배 소비</li>
  <li>파일을 #bricks 만큼 복제하여 각 brick에 저장</li>
  <li>모든 brick이 고장나지만 않으면 전체 데이터를 복구 가능</li>
</ul>

<p><img alt="image" src="/images/e0342821-8895-4277-9b6c-161af3fe7721" /></p>

<h3 id="3-dispersed-glusterfs-volume">3. <strong>Dispersed Glusterfs Volume</strong></h3>

<p>Dispersed glusterfs volume은 안정성과 가용성을 적절히 혼합한 형태의 볼륨입니다. 이 volume은 삭제 코드(eraser code)를 기반으로 동작합니다. 하나의 파일을 brick 수 만큼 분할하고 신뢰성을 보장하기 위한 정보를 추가해 부분 데이터를 생성합니다. redundancy 데이터를 추가하면서 데이터의 중복이 발생하기 때문에 사용할 수 있는 최대 스토리지 용량은 감소하지만, redundancy 수 만큼 brick이 고장난다고 해도, 전체 데이터를 복구할 수 있습니다.</p>

<ul>
  <li>redundancy : 허용되는 실패 brick 수</li>
  <li>파일을 분할, 복제하는 overhead 존재</li>
  <li>전체 클러스터 용량 = 단일 brick 용량 * ( #bricks - redundancy )</li>
  <li>네트워크 대역폭을  #bricks / ( #bricks - redundancy ) 배 소비</li>
  <li>redundancy 만큼의 birck이 손실되어도 데이터 무결성(data integrity)이 유지</li>
  <li>파일 읽기 쓰기 속도 = 단일 brick 속도 *  (#bricks) / (redundancy + 1 + alpha)
    <ul>
      <li>alpha: 파일 분할, 복제 overhead</li>
    </ul>
  </li>
</ul>

<p><img alt="image" src="/images/327f93b1-2606-4305-8034-46cb4d98ee1d" /></p>

<h3 id="4-distributed-replicated-glusterfs-volume">4. <strong>Distributed Replicated Glusterfs Volume</strong></h3>

<p>distributed 볼륨은 replicated 볼륨과 혼합하여 사용할 수 도 있습니다. distributed set 마다 서로 다른 파일들을 저장하면서 distributed set 속의 brick들은 replicated 볼륨으로 구성되어 있습니다. 하나의 distributed set 전체가 고장난다면 데이터 무결성이 손상되는 구조이지만, distributed set 내부의 모든 brick들이 데이터를 서로 중복해서 가지기 때문에 높은 안정성을 보입니다. 이 처럼 Distributed Replicated 볼륨은 dispersed 볼륨과 유사하게 안정성과 성능 모두 챙길 수 있습니다.</p>

<ul>
  <li>distributed와 replicated를 결합한 분산 스토리지</li>
  <li>distributed의 구성 요소로 brick이 아닌 replicated 스토리지를 사용</li>
  <li>replicated set에서는 replicated 만큼 동일한 데이터를 복제</li>
  <li>전체 스토리지 용량
    <ul>
      <li>단일 brick 용량 * ( #bricks / replica 수 )</li>
    </ul>
  </li>
  <li>네트워크 대역폭 ( #bricks / replica 수 ) 배 소비</li>
  <li>단일 파일 I/O 속도 = 단일 brick 속도 - overhead</li>
  <li>다중 파일 I/O 속도 = 단일 파일 I/O 속도 * (distributed size)</li>
</ul>

<p><img alt="image" src="/images/76dd6c12-40b9-4119-91d4-2367aca50d3b" /></p>

<h3 id="5-distributed-dispersed-glusterfs-volume">5. <strong>**Distributed Dispersed Glusterfs V</strong>**olume</h3>

<p>마지막 조합은 distributed와 dispersed를 결합한 volume입니다. distributed replicated volume과 다르게 distributed set의 brick들은 dispersed volume으로 구성됩니다.</p>

<ul>
  <li>distribute와 disperse를 결합한 분산 스토리지</li>
  <li>distribute의 구성 요소로 brick이 아닌 dispersed 스토리지를 사용</li>
  <li>파일들은 distributed 크기 만큼 나눠져 각 dispersed set에 저장</li>
  <li>전체 클러스터 용량
= 단일 brick 용량 * ( dispersed size - redundancy )</li>
  <li>네트워크 대역폭 ( dispersed size - redundancy ) / dispersed size 배 소비</li>
  <li>단일 파일 I/O 속도 
= 단일 brick 속도 *  (dispersed size) / (redundancy + 1 + alpha)</li>
  <li>다중 파일 I/O 속도 = 단일 파일 I/O 속도 * (distributed size)</li>
</ul>

<p><img alt="image" src="/images/c2b2dce6-ed15-4e72-9a7c-a90c2f95bdfb" /></p>

<h1 id="실험-구성">실험 구성</h1>

<h2 id="실험-조합-결정">실험 조합 결정</h2>

<p>14TB 하드디스크 3개를 RAID 5로 구성한 하나의 볼륨을 Brick으로 사용합니다. 노드 마다 하나의 Brick을 가지도록 구성하고 4개의 서로다른 glusterfs 볼륨을 구성하여 성능을 비교했습니다. 또한 기존의 nfs 파일 시스템도 동일한 조건에서 어떤 성능이 나오는지 함께 확인했습니다.</p>

<h3 id="1-distributed-8">1. Distributed 8</h3>

<p>파일을 8개의 노드에 모두 분산하여 저장하는 방식입니다. 단일 파일 I/O 성능은 nfs와 유사하지만, 다중 파일을 동시에 I/O할 경우, I/O controller를 동시에 사용할 수 있기 때문에, 대역폭이 최대 8배로 증가할 것으로 예상합니다.</p>

<p><img alt="image" src="/images/8a5b21e0-6035-42d5-81d6-f8029ba420b8" /></p>

<h3 id="2-disperse-8-redundancy-2">2. Disperse 8 (Redundancy 2)</h3>

<p>하나의 파일을 8개로 쪼개고 erasure code를 추가해 8개 노드에 저장하는 방식입니다. 파일의 크기가 작을 경우에는 단일 볼륨보다 성능이 떨어지지만, 파일의 크기가 커지면, 단일 파일이라도 io 속도가 증가할 것으로 예상됩니다.</p>

<p><img alt="image" src="/images/97dcacef-710f-48cc-8620-fc76c07abc94" /></p>

<h3 id="3-distributed-4-replicated-2">3. Distributed 4 Replicated 2</h3>

<p>파일들을 4개의 replicated set에 분산해서 저장하는 방식입니다. 단일 파일의 경우 파일을 복제하는 overhead가 존재해 단일 볼륨보다는 속도가 느릴 것으로 보입니다. 특히 파일의 크기가 커질 수록 복제 overhead가 증가하여 대역폭이 감소할 것으로 예상합니다. 하지만, 크기가 작은 다중 파일은 4개의 분산 replicated set에 나누어 저장되기 때문에 높은 성능을 보일 것으로 보입니다.</p>

<p><img alt="image" src="/images/528adc07-0f28-4c2e-97d7-7c6177ce2a61" /></p>

<h3 id="4-distributed-2-disperse-4-redundancy-1">4. Distributed 2 Disperse 4 (Redundancy 1)</h3>

<p>파일들을 2개의 disperse set으로 나누어 저장합니다. disperse set에서는 단일 파일이 각각 4개의 조각으로 분할되어 각 볼륨에 저장됩니다. 파일의 수와 크기가 크다면 높은 대역폭을 보일 것으로 예상합니다.</p>

<p><img alt="image" src="/images/b59af180-c40e-4a04-80b1-07fccea291bc" /></p>

<h2 id="실험-환경-구성">실험 환경 구성</h2>

<h3 id="1-gluster-volume-생성">1. gluster volume 생성</h3>

<p>이제 8개 노드에 gluster를 설치하고 4가지 gluster volume을 생성합니다. 이후 별도 client 노드에 gluster volume들을 마운트하여 실험을 진행합니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># n001 ~ n008 노드에 gluster volume 설정</span>

<span class="c"># 1. 모든 노드에 gluster 설치</span>
yum <span class="nb">install </span>centos-release-gluster
yum <span class="nb">install </span>glusterfs-server

<span class="c"># 2. /etc/glusterfs/glusterd.vol 파일 생성</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> /etc/glusterfs
<span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> &gt; /etc/glusterfs/glusterd.vol 
volume management
    type mgmt/glusterd
    option working-directory /var/lib/glusterd
    option transport-type socket
    option transport.socket.keepalive-time 10
    option transport.socket.keepalive-interval 2
    option transport.socket.read-fail-log off
    option transport.socket.listen-port 24007
    option ping-timeout 0
    option event-threads 1
    option max-port  60999
end-volume
</span><span class="no">EOF
</span>systemctl start glusterd
systemctl start glusterfsd

<span class="c"># 3. /dev/sda xfs으로 포맷하고 /mnt/gluster 경로에 마운트</span>
mkfs.xfs /dev/sda <span class="nt">-f</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> /mnt/gluster
mount /dev/sda /mnt/gluster

<span class="c"># 4. gluster peer prove</span>
ssh n001
gluster peer probe n002
gluster peer probe n003
gluster peer probe n004
gluster peer probe n005
gluster peer probe n006
gluster peer probe n007
gluster peer probe n008

<span class="c"># 볼륨 생성</span>
gluster volume create dp8rd2 disperse 8 redundancy 2 transport tcp <span class="se">\</span>
n001:/mnt/gluster/dp8rd2 <span class="se">\</span>
n002:/mnt/gluster/dp8rd2 <span class="se">\</span>
n003:/mnt/gluster/dp8rd2 <span class="se">\</span>
n004:/mnt/gluster/dp8rd2 <span class="se">\</span>
n005:/mnt/gluster/dp8rd2 <span class="se">\</span>
n006:/mnt/gluster/dp8rd2 <span class="se">\</span>
n007:/mnt/gluster/dp8rd2 <span class="se">\</span>
n008:/mnt/gluster/dp8rd2
gluster volume start dp8rd2

gluster volume create dt4rp2 replica 2 transport tcp <span class="se">\</span>
n001:/mnt/gluster/dt4rp2 <span class="se">\</span>
n002:/mnt/gluster/dt4rp2 <span class="se">\</span>
n003:/mnt/gluster/dt4rp2 <span class="se">\</span>
n004:/mnt/gluster/dt4rp2 <span class="se">\</span>
n005:/mnt/gluster/dt4rp2 <span class="se">\</span>
n006:/mnt/gluster/dt4rp2 <span class="se">\</span>
n007:/mnt/gluster/dt4rp2 <span class="se">\</span>
n008:/mnt/gluster/dt4rp2
gluster volume start dt4rp2

gluster volume create dt8 transport tcp <span class="se">\</span>
n001:/mnt/gluster/dt8 <span class="se">\</span>
n002:/mnt/gluster/dt8 <span class="se">\</span>
n003:/mnt/gluster/dt8 <span class="se">\</span>
n004:/mnt/gluster/dt8 <span class="se">\</span>
n005:/mnt/gluster/dt8 <span class="se">\</span>
n006:/mnt/gluster/dt8 <span class="se">\</span>
n007:/mnt/gluster/dt8 <span class="se">\</span>
n008:/mnt/gluster/dt8
gluster volume start dt8

gluster volume create dt2dp4rd1 disperse 4 redundancy 1 transport tcp <span class="se">\</span>
n001:/mnt/gluster/dt2dp4rd1 <span class="se">\</span>
n002:/mnt/gluster/dt2dp4rd1 <span class="se">\</span>
n003:/mnt/gluster/dt2dp4rd1 <span class="se">\</span>
n004:/mnt/gluster/dt2dp4rd1 <span class="se">\</span>
n005:/mnt/gluster/dt2dp4rd1 <span class="se">\</span>
n006:/mnt/gluster/dt2dp4rd1 <span class="se">\</span>
n007:/mnt/gluster/dt2dp4rd1 <span class="se">\</span>
n008:/mnt/gluster/dt2dp4rd1

gluster volume start dt2dp4rd1
</code></pre></div></div>

<h3 id="2-gluster-volume-mount">2. gluster volume mount</h3>

<p>client노드도 gluster를 설치하고 4가지 gluster volume을 마운트 합니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ssh client

<span class="c"># 1. gluster 설치</span>
yum <span class="nb">install </span>centos-release-gluster

<span class="c"># 2. volume mount</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> /client/gluster/dp8rd2
<span class="nb">mkdir</span> <span class="nt">-p</span> /client/gluster/dt2dp4rd1
<span class="nb">mkdir</span> <span class="nt">-p</span> /client/gluster/dt4rp2
<span class="nb">mkdir</span> <span class="nt">-p</span> /client/gluster/dt8

mount <span class="nt">-t</span> glusterfs n001:dp8rd2 /client/gluster/dp8rd2
mount <span class="nt">-t</span> glusterfs n001:dt2dp4rd1 /client/gluster/dt2dp4rd1
mount <span class="nt">-t</span> glusterfs n001:dt4rp2 /client/gluster/dt4rp2
mount <span class="nt">-t</span> glusterfs n001:dt8 /client/gluster/dt8
</code></pre></div></div>

<h3 id="3-glusterfs-cache-off">3. glusterfs cache off</h3>

<p>cache 없이 단순히 file I/O의 성능을 측정하기 위해서 생성한 4개의 gluster volume의 cache설정을 모두 off 했습니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gluster volume list
gluster volume <span class="nb">set </span>dt8 performance.write-behind off
gluster volume <span class="nb">set </span>dp8rd2 performance.write-behind off
gluster volume <span class="nb">set </span>dt4rp2 performance.write-behind off
gluster volume <span class="nb">set </span>dt2dp4rd1 performance.write-behind off

gluster volume <span class="nb">set </span>dt8 performance.read-ahead off
gluster volume <span class="nb">set </span>dp8rd2 performance.read-ahead off
gluster volume <span class="nb">set </span>dt4rp2 performance.read-ahead off
gluster volume <span class="nb">set </span>dt2dp4rd1 performance.read-ahead off

gluster volume <span class="nb">set </span>dt8 performance.cache-invalidation on
gluster volume <span class="nb">set </span>dp8rd2 performance.cache-invalidation on
gluster volume <span class="nb">set </span>dt4rp2 performance.cache-invalidation on
gluster volume <span class="nb">set </span>dt2dp4rd1 performance.cache-invalidation on
</code></pre></div></div>

<h3 id="3-실험-소스-코드">3. 실험 소스 코드</h3>

<p>실험은 3개의 스크립트로 진행했습니다.</p>

<h3 id="multiplesh">multiple.sh</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>

test_io<span class="o">()</span> <span class="o">{</span>

    <span class="nb">local </span><span class="nv">vol</span><span class="o">=</span><span class="nv">$1</span>
    <span class="nb">local </span><span class="nv">bs</span><span class="o">=</span><span class="nv">$2</span>
    <span class="nb">local </span><span class="nv">separately_count</span><span class="o">=</span><span class="nv">$3</span>

    <span class="c"># pids=()</span>
    <span class="nv">commands</span><span class="o">=()</span>

    <span class="nb">mkdir</span> <span class="nt">-p</span> <span class="nv">$vol</span>

    <span class="nb">rm</span> <span class="nt">-rf</span> <span class="nv">$vol</span>/testfile<span class="k">*</span>
    <span class="nb">rm</span> <span class="nt">-rf</span> ./log/log<span class="k">*</span>

    <span class="nv">PIPE</span><span class="o">=</span>my_sync_pipe
    <span class="nb">mkfifo</span> <span class="nv">$PIPE</span>
    
    <span class="nb">local </span><span class="nv">i</span><span class="o">=</span>1
    <span class="k">for</span> <span class="o">((</span> <span class="nv">i</span><span class="o">=</span>1<span class="p">;</span> i&lt;<span class="o">=</span><span class="nv">$separately_count</span><span class="p">;</span> i++ <span class="o">))</span>
    <span class="k">do</span>
        <span class="o">(</span>
            <span class="nb">read</span> <span class="nt">-r</span> &lt; <span class="nv">$PIPE</span>
            <span class="nb">dd </span><span class="k">if</span><span class="o">=</span>/dev/zero <span class="nv">of</span><span class="o">=</span><span class="nv">$vol</span>/testfile<span class="nv">$i</span> <span class="nv">bs</span><span class="o">=</span><span class="nv">$bs</span> <span class="nv">count</span><span class="o">=</span>1  2&gt;&gt; ./log/log<span class="nv">$i</span>
        <span class="o">)</span> &amp;
    <span class="k">done

    for </span>i <span class="k">in</span> <span class="si">$(</span><span class="nb">seq </span>1 <span class="nv">$NUM_PROCESSES</span><span class="si">)</span><span class="p">;</span> <span class="k">do
        </span><span class="nb">echo</span> <span class="s2">"Go"</span> <span class="o">&gt;</span> <span class="nv">$PIPE</span>
    <span class="k">done

    </span><span class="nb">wait
    rm</span> <span class="nv">$PIPE</span>
    
    <span class="nb">rm</span> <span class="nt">-rf</span> <span class="nv">$vol</span>/testfile<span class="k">*</span>
    <span class="k">return </span>0
<span class="o">}</span>

calculate_io_bandwidth_average<span class="o">(){</span>
    <span class="nb">declare</span> <span class="nt">-A</span> unit_map
    <span class="nv">unit_map</span><span class="o">=(</span>
    <span class="o">[</span><span class="s2">"GB/s"</span><span class="o">]=</span><span class="k">$((</span><span class="m">1024</span> <span class="o">*</span> <span class="m">1024</span> <span class="o">*</span> <span class="m">1024</span><span class="k">))</span>
    <span class="o">[</span><span class="s2">"MB/s"</span><span class="o">]=</span><span class="k">$((</span><span class="m">1024</span> <span class="o">*</span> <span class="m">1024</span><span class="k">))</span>
    <span class="o">[</span><span class="s2">"kB/s"</span><span class="o">]=</span><span class="k">$((</span><span class="m">1024</span><span class="k">))</span>
    <span class="o">)</span>
    <span class="nv">report</span><span class="o">=(</span><span class="sb">``</span><span class="nb">cat</span> ./log/log<span class="k">*</span> | <span class="nb">grep </span>copied | <span class="nb">awk</span> <span class="s1">'{ print $8":"$9}'</span><span class="sb">``</span><span class="o">)</span>
    <span class="nv">length</span><span class="o">=</span><span class="k">${#</span><span class="nv">report</span><span class="p">[@]</span><span class="k">}</span>
    <span class="nv">sum_bandwith</span><span class="o">=</span>0
    <span class="k">for </span>line <span class="k">in</span> <span class="k">${</span><span class="nv">report</span><span class="p">[@]</span><span class="k">}</span>
    <span class="k">do
    </span><span class="nv">value</span><span class="o">=</span><span class="sb">``</span><span class="nb">echo</span> <span class="nv">$line</span> | <span class="nb">awk</span> <span class="nt">-F</span><span class="s2">":"</span> <span class="s1">'{print $1}'</span><span class="sb">``</span>
    <span class="nv">unit</span><span class="o">=</span><span class="sb">``</span><span class="nb">echo</span> <span class="nv">$line</span> | <span class="nb">awk</span>  <span class="nt">-F</span><span class="s2">":"</span> <span class="s1">'{print $2}'</span><span class="sb">``</span>
    
    <span class="nv">bandwithd</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$value</span> <span class="k">${</span><span class="nv">unit_map</span><span class="p">[</span><span class="nv">$unit</span><span class="p">]</span><span class="k">}</span> | <span class="nb">awk</span> <span class="s1">'{printf "%4.3f\n",$1*$2}'</span><span class="si">)</span>
    <span class="nv">sum_bandwith</span><span class="o">=</span><span class="s2">"</span><span class="si">$(</span> bc <span class="o">&lt;&lt;&lt;</span><span class="s2">"</span><span class="nv">$sum_bandwith</span><span class="s2"> + </span><span class="nv">$bandwithd</span><span class="s2">"</span> <span class="si">)</span><span class="s2">"</span>
    <span class="k">done

    </span><span class="nv">avg_bandwidth</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$sum_bandwith</span> <span class="nv">$length</span> | <span class="nb">awk</span> <span class="s1">'{printf "%4.3f\n",$1/$2}'</span><span class="si">)</span>
    <span class="nv">sum_mb_bandwidth</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$sum_bandwith</span> <span class="k">${</span><span class="nv">unit_map</span><span class="p">[</span><span class="s2">"MB/s"</span><span class="p">]</span><span class="k">}</span> | <span class="nb">awk</span> <span class="s1">'{printf "%4.3f\n",$1/$2}'</span><span class="si">)</span>
    <span class="nv">avg_mb_bandwidth</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$avg_bandwidth</span> <span class="k">${</span><span class="nv">unit_map</span><span class="p">[</span><span class="s2">"MB/s"</span><span class="p">]</span><span class="k">}</span> | <span class="nb">awk</span> <span class="s1">'{printf "%4.3f\n",$1/$2}'</span><span class="si">)</span>

    <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$avg_bandwidth</span><span class="s2"> </span><span class="nv">$avg_mb_bandwidth</span><span class="s2"> </span><span class="nv">$sum_mb_bandwidth</span><span class="s2">"</span>
<span class="o">}</span>

echo_result<span class="o">(){</span>
    <span class="nb">local </span><span class="nv">vol</span><span class="o">=</span><span class="nv">$1</span>
    <span class="nb">local </span><span class="nv">bs</span><span class="o">=</span><span class="nv">$2</span>
    <span class="nb">local </span><span class="nv">separately_count</span><span class="o">=</span><span class="nv">$3</span>
    <span class="nb">local </span><span class="nv">avg_bandwidth</span><span class="o">=</span><span class="nv">$4</span>
    <span class="nb">local </span><span class="nv">avg_mb_bandwidth</span><span class="o">=</span><span class="nv">$5</span>
    <span class="nb">local </span><span class="nv">sum_mb_bandwidth</span><span class="o">=</span><span class="nv">$6</span>
    <span class="nb">echo</span> <span class="s2">"vol=</span><span class="nv">$vol</span><span class="s2">, bs=</span><span class="nv">$bs</span><span class="s2">, separately_count=</span><span class="nv">$separately_count</span><span class="s2">, </span><span class="nv">$avg_bandwidth</span><span class="s2"> Bytes/s, </span><span class="nv">$avg_mb_bandwidth</span><span class="s2"> MB/s, </span><span class="nv">$sum_mb_bandwidth</span><span class="s2"> MB/s"</span>
<span class="o">}</span>

test_single_bs<span class="o">(){</span>
    <span class="nb">local </span><span class="nv">vol</span><span class="o">=</span><span class="nv">$1</span>
    <span class="nb">local </span><span class="nv">bs</span><span class="o">=</span><span class="nv">$2</span>
    <span class="nb">local </span><span class="nv">separately_count</span><span class="o">=</span><span class="nv">$3</span>

    test_io <span class="nv">$vol</span> <span class="nv">$bs</span> <span class="nv">$separately_count</span>
    <span class="nb">local </span><span class="nv">bw_list</span><span class="o">=</span><span class="sb">``</span>calculate_io_bandwidth_average<span class="sb">``</span>

    <span class="nb">local </span><span class="nv">avg_bandwidth</span><span class="o">=</span><span class="sb">``</span><span class="nb">echo</span> <span class="nv">$bw_list</span> | <span class="nb">awk</span> <span class="nt">-F</span><span class="s2">" "</span> <span class="s1">'{print $1}'</span><span class="sb">``</span>
    <span class="nb">local </span><span class="nv">avg_mb_bandwidth</span><span class="o">=</span><span class="sb">``</span><span class="nb">echo</span> <span class="nv">$bw_list</span> | <span class="nb">awk</span>  <span class="nt">-F</span><span class="s2">" "</span> <span class="s1">'{print $2}'</span><span class="sb">``</span>
    <span class="nb">local </span><span class="nv">sum_mb_bandwidth</span><span class="o">=</span><span class="sb">``</span><span class="nb">echo</span> <span class="nv">$bw_list</span> | <span class="nb">awk</span>  <span class="nt">-F</span><span class="s2">" "</span> <span class="s1">'{print $3}'</span><span class="sb">``</span>

    echo_result <span class="nv">$vol</span> <span class="nv">$bs</span> <span class="nv">$separately_count</span> <span class="nv">$avg_bandwidth</span> <span class="nv">$avg_mb_bandwidth</span> <span class="nv">$sum_mb_bandwidth</span>
<span class="o">}</span>

test_multiple_bs<span class="o">(){</span>
    <span class="nb">local </span><span class="nv">vol</span><span class="o">=</span><span class="nv">$1</span>
    <span class="nb">local </span><span class="nv">separately_count</span><span class="o">=</span><span class="nv">$2</span>
    <span class="nb">local </span><span class="nv">i</span><span class="o">=</span>1
    <span class="c"># test_single_bs $vol 100M $separately_count</span>
     <span class="nv">i</span><span class="o">=</span>1<span class="p">;</span> <span class="k">while</span> <span class="o">[</span> <span class="nv">$i</span> <span class="nt">-le</span> 512 <span class="o">]</span>
        <span class="k">do 
            </span>test_single_bs <span class="nv">$vol</span> NULLk <span class="nv">$separately_count</span>
            <span class="nv">i</span><span class="o">=</span><span class="k">$((</span><span class="nv">$i</span><span class="o">*</span><span class="m">2</span><span class="k">))</span> 
        <span class="k">done 
     </span><span class="nv">i</span><span class="o">=</span>1<span class="p">;</span> <span class="k">while</span> <span class="o">[</span> <span class="nv">$i</span> <span class="nt">-le</span> 512 <span class="o">]</span>
         <span class="k">do 
             </span>test_single_bs <span class="nv">$vol</span> NULLM <span class="nv">$separately_count</span>
             <span class="nv">i</span><span class="o">=</span><span class="k">$((</span>i<span class="o">*</span><span class="m">2</span><span class="k">))</span>
         <span class="k">done</span> 
<span class="o">}</span>

<span class="nv">vol</span><span class="o">=</span><span class="nv">$1</span>
<span class="nv">separately_count</span><span class="o">=</span><span class="nv">$2</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> ./log
test_multiple_bs <span class="nv">$vol</span> <span class="nv">$separately_count</span>
</code></pre></div></div>

<h3 id="runsh">run.sh</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>

<span class="nb">echo </span>running multiple file <span class="nb">test</span>

./multiple.sh /client/gluster/dt8 8 <span class="o">&gt;&gt;</span> dt8-8.log 
./multiple.sh /client/gluster/dt2dp4rd1 8 <span class="o">&gt;&gt;</span> dt2dp4rd1-8.log 
./multiple.sh /client/gluster/dp8rd2 8 <span class="o">&gt;&gt;</span> dp8rd2-8.log 
./multiple.sh /client/gluster/dt4rp2 8 <span class="o">&gt;&gt;</span> dt4rp2-8.log 
./multiple.sh /nfs/gluster-test 8 <span class="o">&gt;&gt;</span> home1-8.log 

<span class="nb">echo </span>running single file <span class="nb">test</span>

./multiple.sh /client/gluster/dt8 1 <span class="o">&gt;&gt;</span> dt8-1.log 
./multiple.sh /client/gluster/dt2dp4rd1 1 <span class="o">&gt;&gt;</span> dt2dp4rd1-1.log 
./multiple.sh /client/gluster/dp8rd2 1 <span class="o">&gt;&gt;</span> dp8rd2-1.log 
./multiple.sh /nfs/dt4rp2 1 <span class="o">&gt;&gt;</span> dt4rp2-1.log
</code></pre></div></div>

<h3 id="reportsh">report.sh</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="nv">log_file_list</span><span class="o">=</span><span class="sb">``</span><span class="nb">ls</span> | <span class="nb">grep</span> <span class="s2">".log"</span><span class="sb">``</span>
<span class="nv">length</span><span class="o">=</span><span class="sb">``</span><span class="nb">echo</span> <span class="nv">$log_file_list</span> | <span class="nb">wc</span> <span class="nt">-w</span><span class="sb">``</span>
<span class="nb">echo</span> <span class="s1">'logfile, volume_type, bs, bandwidth[Bytes/s]'</span>
<span class="k">for </span>filename <span class="k">in</span> <span class="nv">$log_file_list</span>
<span class="k">do
    </span><span class="nb">cat</span> <span class="nv">$filename</span> | <span class="nb">awk</span> <span class="nt">-v</span> <span class="nv">filename</span><span class="o">=</span><span class="s2">"</span><span class="nv">$filename</span><span class="s2">"</span> <span class="s1">'{gsub("bs=","",$0); gsub(",","",$0); print  filename ", " $2 ", " $8}'</span>
<span class="k">done</span>
</code></pre></div></div>

<h1 id="실험-결과">실험 결과</h1>

<h3 id="단일-파일-io-속도-측정-결과">단일 파일 I/O 속도 측정 결과</h3>

<p>데이터 크기를 1kB부터 512MB까지 2배씩 증가하면서 I/O속도를 측정했습니다. glusterfs는 동일한 스팩의 서버에서 환경을 구성하고 실험 했지만, nfs는 현재 사용중인 서버(16TB * 12, RAID6, 총 146TB)환경에서 실험했기 때문에 정확한 비교에 한계가 있음을 밝힙니다.</p>

<p><img alt="image" src="/images/dc917864-cceb-4cb9-ae8d-dd5e857e74ed" /></p>

<p>단일 파일에 대해서는 파일의 크기가 증가하면서, I/O 속도가 증가하다가 300MBps로 수렴하는 모습을 보입니다. 파일 자체를 분할하거나, 복제하지 않는 distribute 8 클러스터의 속도가 가장 빠르며 다른 클러스터는 유사한 성능을 갖습니다.</p>

<h3 id="다중-파일8개-동시-수행-io-속도-측정-결과">다중 파일(8개 동시 수행) I/O 속도 측정 결과</h3>

<p>현재 구축하는 스토리지는 동시에 여러명의 사용자가 접근하기 때문에 여러개의 파일을 동시에 병렬적으로 처리할 때, I/O 성능을 평가하는 것이 적합합니다. linux Named Pipe (FIFO)를 사용하여 파일을 읽고쓰는 작업을 동시에 실행하고 총 대역폭을 계산했습니다. (모든 I/O 작업을 완벽히 동시에 실행할 수는 없습니다. I/O 작업을 실행하는 간격은 0.05ms입니다. 이후에 다시 다루겠습니다.)</p>

<p><img alt="image" src="/images/0acf31c5-fdec-448c-a3f0-a885f44cba63" /></p>

<p>동시에 파일을 읽고쓰는 작업은 예상대로 distribute 8 에서 가장 높은 성능을 보입니다. 파일의 크기가 작을 경우, 파일 I/O 시간이 매우 짧기 때문에 (distribute 8에서 1MB를 쓰는데 걸리는 시간 1 ms) 서브 프로세스를 실행하는 시간이 실험에 영향을 줄 수 있습니다. 따라서 데이터 크기가 2MB 이상인 구간에서 성능을 평가하는 것이 적합합니다. 2MB 이상 구간에서 파일 I/O 성능과 스토리지 용량을 정리하면 다음과 같습니다.</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>nfs</th>
      <th>distribute 8</th>
      <th>dispersed 8, redundancy 2</th>
      <th>distributed 2, dispersed 4,   redundancy 1</th>
      <th>distributed 4, replicated 2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>brick 수</td>
      <td>-</td>
      <td>8 (204 TB)</td>
      <td>8 (204 TB)</td>
      <td>8 (204 TB)</td>
      <td>8 (204 TB)</td>
    </tr>
    <tr>
      <td>스토리지 용량</td>
      <td>146 TB</td>
      <td>204 TB</td>
      <td>154 TB</td>
      <td>153 TB</td>
      <td>102TB</td>
    </tr>
    <tr>
      <td>단일 파일</td>
      <td>40 ~ 300 MBps</td>
      <td>310 ~ 320 MB/s</td>
      <td>290 MB/s</td>
      <td>300 MB/s</td>
      <td>290 MB/s</td>
    </tr>
    <tr>
      <td>다중 파일(8개 동시)</td>
      <td>300 ~ 600 MBps</td>
      <td>2.1 ~ 2.3 GB/s</td>
      <td>1.2 ~ 1.6 GB/s</td>
      <td>1.5 ~ 1.8 GB/s</td>
      <td>1.1 ~ 1.7 GB/s</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>
    <p><strong>nfs</strong></p>

    <p>I/O 컨트롤러의 병목 현상으로 인해서 다중파일을 I/O 할 때, 분산 파일 시스템 대비 대역폭이 크게 감소하는 보습을 보입니다.</p>
  </li>
  <li>
    <p><strong>distributed 8</strong></p>

    <p>단일 및 다중 파일 모두 가장 높은 성능을 보입니다. 다중파일을 동시에 입출력할 때, I/O 컨트롤러 8개를 동시에 사용하기 때문에 대역폭이 8배 증가합니다.  (8 * 300 MBps = 2.4GBps )</p>
  </li>
  <li>
    <p><strong>dispersed 8, redundancy 2</strong></p>

    <p>다중 파일에서 nfs 대비 300% 가까이 성능이 향상되지만, 파일을 분할하고 erasure code를 생성하는 데 필요한 overhead로 인해서 distributed 8 보다는 낮은 성능을 보입니다.</p>
  </li>
  <li>
    <p><strong>distributed 2, dispersed 4, redundancy 1</strong></p>

    <p>dispersed 8 redundancy 2에 비해서 파일 분할하는 연산량이 적기 때문에, overhead 또한 감소합니다. 또한 파일들을 2개의 dispersed set에 저장함으로 dispersed 8에 비해 다중 파일 성능이 더 높게 측정됩니다.</p>
  </li>
  <li>
    <p><strong>distributed 4, replicated 2</strong></p>

    <p>파일을 복제하는 overhead로 인해서  distributed 8 보다는 낮은 성능을 보이며, 특히 파일의 크기가 증가할 수록 성능이 감소합니다.</p>
  </li>
</ul>

<h2 id="결론">결론</h2>

<p>성능 측면에서는 단일 및 다중 파일 모두 distributed 8이 가장 우수합니다. 하지만 distributed 8은 하나의 볼륨이라도 고장난다면, 전체 볼륨을 복구할 수 없다는 치명적인 단점을 가지고 있습니다. 이러한 문제로 distributed 8을 사용하지 않기로 결정했습니다. 나머지 3개의 후보 중 가장 성능이 우수 하면서, 최대 2개의 볼륨이 고장 나더라도 모든 데이터를 복원할 수 있으며,  전체 하드디스크 용량의 75 %를 사용할 수 있는 distributed 2, dispersed 4, redundancy 1 조합 gluster 볼륨을 사용하기로 결정했습니다.</p>

<h2 id="시행착오">시행착오</h2>
<p>실험을 설계할 때, 동시 파일 I/O 작업을 위해서 linux background process (&amp;) 실행을 사용했습니다. 하지만, subprocess를 생성하는 overhead가 한 파일을 쓰는 속도와 유사하여 대역폭이 매우 크게 측정되는 문제가 있었습니다. linux의 Named Pipe (FIFO)를 이용해서 문제를 해결할 수 있었습니다. 우선 8개의 프로세스를 모두 생성하고 pipe에 값이 들어오면 동시에 I/O 작업을 시행하도록 코드를 수정 했더니, 각 작업간 간격이 0.81 ms에서 0.05ms로 94% 감소했습니다. 각 subprocess마다 값을 전달하기 위해 완벽히 동시에 작업을 수행할 수는 없지만, 유의미한 실험결과를 얻을 수 있다고 판단하여 아래 방법을 통해서 실험을 진행했습니다.</p>

<h3 id="-background-실행-overhead">&amp; background 실행 overhead</h3>

<ul>
  <li>실행 간격: 0.81ms</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>

<span class="nv">NUM_PROCESSES</span><span class="o">=</span>100
<span class="k">for </span>i <span class="k">in</span> <span class="si">$(</span><span class="nb">seq </span>1 <span class="nv">$NUM_PROCESSES</span><span class="si">)</span><span class="p">;</span> <span class="k">do
        </span><span class="nv">now_time</span><span class="o">=</span><span class="si">$(</span><span class="nb">date</span> +%N<span class="si">)</span>
        <span class="nb">echo</span> <span class="nv">$now_time</span>
<span class="k">done</span>

<span class="c"># 차이: 81m 337u 966n / 100 = 0.81ms</span>
</code></pre></div></div>

<h3 id="named-pipe-fifo-를-사용한-subprocess-동기화"><strong>Named Pipe (FIFO) 를 사용한 subprocess 동기화</strong></h3>

<ul>
  <li>실행 간격: 0.055ms</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>

<span class="nv">NUM_PROCESSES</span><span class="o">=</span>100
<span class="nv">PIPE</span><span class="o">=</span>my_sync_pipe
<span class="nb">mkfifo</span> <span class="nv">$PIPE</span>
<span class="k">for </span>i <span class="k">in</span> <span class="si">$(</span><span class="nb">seq </span>1 <span class="nv">$NUM_PROCESSES</span><span class="si">)</span><span class="p">;</span> <span class="k">do</span>
    <span class="o">(</span>
        <span class="c"># Named Pipe에서 데이터를 읽기 위해 대기</span>
        <span class="nb">read</span> <span class="nt">-r</span> &lt; <span class="nv">$PIPE</span>
        <span class="c"># 실제 명령어 실행</span>
        <span class="nv">start_time</span><span class="o">=</span><span class="si">$(</span><span class="nb">date</span> +%s%N<span class="si">)</span>
        <span class="nb">echo</span> <span class="nv">$start_time</span>

    <span class="o">)</span> &amp;
<span class="k">done</span>

<span class="c"># 모든 프로세스가 Named Pipe에서 대기 상태일 때 데이터를 보냄</span>
<span class="nb">sleep </span>2  <span class="c"># 대기 상태를 보장하기 위한 임시 슬립</span>
<span class="k">for </span>i <span class="k">in</span> <span class="si">$(</span><span class="nb">seq </span>1 <span class="nv">$NUM_PROCESSES</span><span class="si">)</span><span class="p">;</span> <span class="k">do
    </span><span class="nb">echo</span> <span class="s2">"Go"</span> <span class="o">&gt;</span> <span class="nv">$PIPE</span>
<span class="k">done

</span><span class="nb">wait</span>  <span class="c"># 모든 백그라운드 프로세스가 완료될 때까지 대기</span>
<span class="nb">rm</span> <span class="nv">$PIPE</span>

<span class="c"># 차이 5m 598u 532ns / 100 = 0.05ms</span>
</code></pre></div></div>

<h2 id="reference">Reference</h2>

<ul>
  <li>https://docs.gluster.org/en/latest/</li>
  <li>https://access.redhat.com/documentation/en-us/red_hat_gluster_storage/3.1/html/administration_guide/chap-recommended-configuration_dispersed</li>
  <li>https://access.redhat.com/documentation/en-us/red_hat_gluster_storage/3.3/html/administration_guide/chap-red_hat_storage_volumes-creating_dispersed_volumes_1</li>
  <li>https://portal.nutanix.com/page/documents/kbs/details?targetId=kA07V0000004U9TSAU</li>
  <li>https://en.wikipedia.org/wiki/Named_pipe</li>
  <li>https://linuxhint.com/send-process-background-linux/</li>
  <li>https://man7.org/linux/man-pages/man1/dd.1.html</li>
</ul>]]></content><author><name></name></author><category term="기타" /><summary type="html"><![CDATA[기존의 파일시스템은 모든 Client 노드가 하나의 물리적 볼륨을 공유하는 NFS 를 사용하고 있었습니다. NFS에 연결된 노드 수와 사용량이 증가하면서 NFS I/O 속도가 감소하고, 메타 데이터가 충돌하는 등 여러 문제가 발생했습니다. 아무리 하드웨어 레벨에서 RAID 6로 묶여있더라도, 100대의 노드에서 발생하는 모든 파일 입출력을 감당하는 것은 성능과 안정성에 문제가 있다고 판단했습니다. 여러 분산 파일 시스템을 조사한 후 glusterfs를 도입하기로 결정했습니다.]]></summary></entry></feed>