<!DOCTYPE html>
<html lang="en"><head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="bdg-blog" /></head>
<style>@import url(/public/css/syntax/monokai.css);</style>
  <title>bdg-blog</title>
  <!-- <link href="/public/css/bootstrap.min.css" rel="stylesheet"> -->

  <link href="/public/css/style.css" rel="stylesheet">
  <body>
  	<div class="container"> 
		<div class="sidebar">
			<div class="sidebar-item sidebar-header">
	<div class='sidebar-brand'>
		<a href="/">bdg-blog</a>
	</div>
	<p class="lead"></p></div>

<div class="sidebar-item sidebar-nav">
	<ul class="nav">
      <li class="nav-title">Pages</li>
	  <li>
	  	<a class="nav-item" href="/">Articles</a>
	  </li>
	  
	  
	    
	  
	    
	      
	    
	  
	    
	  
	    
	  
	</ul>
</div>

<div class="sidebar-item sidebar-nav">
  	<ul class="nav">
			<li class="nav-title">Categories</li>
	    
	    <li>
	    	<a class="nav-item" href="/category/#쿠버네티스">
				<span class="name">쿠버네티스</span>
				<span class="badge">10</span>
	    	</a>
 		</li>
	    
	    <li>
	    	<a class="nav-item" href="/category/#기타">
				<span class="name">기타</span>
				<span class="badge">8</span>
	    	</a>
 		</li>
	    
	    <li>
	    	<a class="nav-item" href="/category/#운영체제/컴퓨터구조">
				<span class="name">운영체제/컴퓨터구조</span>
				<span class="badge">7</span>
	    	</a>
 		</li>
	    
	    <li>
	    	<a class="nav-item" href="/category/#백앤드">
				<span class="name">백앤드</span>
				<span class="badge">5</span>
	    	</a>
 		</li>
	    
	    <li>
	    	<a class="nav-item" href="/category/#컨테이너">
				<span class="name">컨테이너</span>
				<span class="badge">2</span>
	    	</a>
 		</li>
	    
	    <li>
	    	<a class="nav-item" href="/category/#Go">
				<span class="name">Go</span>
				<span class="badge">6</span>
	    	</a>
 		</li>
	    
	    <li>
	    	<a class="nav-item" href="/category/#클린 아키텍쳐">
				<span class="name">클린 아키텍쳐</span>
				<span class="badge">2</span>
	    	</a>
 		</li>
	    
	    <li>
	    	<a class="nav-item" href="/category/#보안">
				<span class="name">보안</span>
				<span class="badge">2</span>
	    	</a>
 		</li>
	    
	    <li>
	    	<a class="nav-item" href="/category/#리눅스">
				<span class="name">리눅스</span>
				<span class="badge">1</span>
	    	</a>
 		</li>
	    
	    <li>
	    	<a class="nav-item" href="/category/#네트워크">
				<span class="name">네트워크</span>
				<span class="badge">4</span>
	    	</a>
 		</li>
	    
	    <li>
	    	<a class="nav-item" href="/category/#자바스크립트">
				<span class="name">자바스크립트</span>
				<span class="badge">1</span>
	    	</a>
 		</li>
	    
	    <li>
	    	<a class="nav-item" href="/category/#클린 코드">
				<span class="name">클린 코드</span>
				<span class="badge">1</span>
	    	</a>
 		</li>
	    
	  </nav>
	</ul>
</div>

<div class="sidebar-item sidebar-footer">
</div>
		</div>
		<div class="content">
			<article class="post">
	<header class="post-header">
		<div class="post-title"> 
			[kubernetes] k3s에서 Nvidia GPU사용하기
		</div>
		<time class="post-date dt-published" datetime="2023-07-26T20:21:54+09:00" itemprop="datePublished">2023/07/26
		</time>		
	</header>

	<div class="post-content">
		<p>운영중인 k3s 클러스터에는 상당히 오래된 gtx 1050 라는 nvidia gpu가 달려있다. VRAM이 무려 4GB 로 아주 작고 귀엽지만, 가벼운 딥러닝 모델을 추론용으로 사용할 수 있기 때문에 이번 기회에 이 gpu를 k3s 클러스터에 연결하고자 한다.</p>

<p><img alt="image" src="/images/9a468452-2fe2-4d76-bbe3-5bd95053ff88" />
[Image From: <a href="https://developer.nvidia.com/blog/announcing-containerd-support-for-the-nvidia-gpu-operator/">https://developer.nvidia.com/blog/announcing-containerd-support-for-the-nvidia-gpu-operator/</a>]</p>

<p>### 1. nvidia gpu 확인</p>

<p>내장 그래픽 카드로 UHD Graphics 620과  Nvidia GPU인 GTX 1050 Mobile 을  가지고 있다. 우선 lshw를 통해서 운영체제가 GPU를 인식하고 있는지 확인한다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>lshw <span class="nt">-C</span> display
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">*</span><span class="nt">-display</span>                 
       description: VGA compatible controller
       product: UHD Graphics 620
       vendor: Intel Corporation
       physical <span class="nb">id</span>: 2
       bus info: pci@0000:00:02.0
       logical name: /dev/fb0
       version: 07
       width: 64 bits
       clock: 33MHz
       capabilities: pcxxxxxxxxx
       configuration: <span class="nv">depth</span><span class="o">=</span>xx <span class="nv">driver</span><span class="o">=</span>xx <span class="nv">latency</span><span class="o">=</span>0 <span class="nv">resolution</span><span class="o">=</span>1920,1080
       resources: ixxxxxxxxx
  <span class="k">*</span><span class="nt">-display</span>
       description: 3D controller
       product: GP107M <span class="o">[</span><span class="k">**</span>GeForce GTX 1050 Mobile<span class="k">**</span><span class="o">]</span>
       vendor: <span class="k">**</span>NVIDIA<span class="k">**</span> Corporation
       physical <span class="nb">id</span>: 0
       bus info: pci@0000:03:00.0
       version: a1
       width: 64 bits
       clock: 33MHz
       capabilities: pxxxxxx
       configuration: <span class="nv">driver</span><span class="o">=</span>nvidia <span class="nv">latency</span><span class="o">=</span>0
       resources: irq:1xxxxxxxxxxxx
</code></pre></div></div>

<h3 id="2-nvidia-driver-설치">2. nvidia-driver 설치</h3>

<p>이제 nvidia-driver를 설치한다. 현재 시점에서 사용할 수 있는 nvidia-driver는 다음 명령어를 통해 확인할 수 있다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>apt search nvidia-driver
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># graphics display 이외의 기능을 담은 드라이버 패키지(커널 드라이버, cuda 드라이버, 유틸)</span>
nvidia-headless-510/jammy-updates,jammy-security 510.85.02-0ubuntu0.22.04.1 amd64
  NVIDIA headless metapackage
<span class="c"># graphics display 이외의 기능을 담은 드라이버 패키지(커널 드라이버, cuda 드라이버, 유틸)</span>
nvidia-headless-510-server/jammy-updates,jammy-security 510.85.02-0ubuntu0.22.04.1 amd64
  NVIDIA headless metapackage

<span class="c"># 모든 드라이버 패키지(커널 드라이버, 2d/3d xorg 드라이버, cuda 드라이버, 유틸)</span>
nvidia-driver-510/jammy-updates,jammy-security,now 510.85.02-0ubuntu0.22.04.1 amd64 <span class="o">[</span>installed]
  NVIDIA driver metapackage
<span class="c"># 모든 드라이버 패키지(커널 드라이버, 2d/3d xorg 드라이버, cuda 드라이버, 유틸)</span>
nvidia-driver-510-server/jammy-updates,jammy-security 510.85.02-0ubuntu0.22.04.1 amd64
  NVIDIA Server Driver metapackage

<span class="c"># server가 붙은 드라이버와 그렇지 않은 지원기간 이외에 큰 차이가 없다.</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>apt update
<span class="nv">$ </span><span class="nb">sudo </span>apt upgrade
<span class="nv">$ </span><span class="nb">sudo </span>apt <span class="nb">install </span>nvidia-driver-510 nvidia-dkms-510

<span class="nv">$ </span><span class="nb">sudo </span>reboot <span class="c"># 드라이버가 gpu를 인식하기 위해서는 재부팅이 필요하다.</span>
</code></pre></div></div>

<p>재부팅 후 nvidia-smi 커맨드를 실행하면, GPU에 대한 간략한 정보를 확인할 수 있는데, 이 정보가 나타난다는 것은 성공적으로 nvidia driver가 설치되었다는 뜻이다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>nvidia-smi

Sun Sep  4 02:33:11 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 510.85.02    Driver Version: 510.85.02    CUDA Version: 11.6     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|<span class="o">===============================</span>+<span class="o">======================</span>+<span class="o">======================</span>|
|   0  NVIDIA GeForce ...  Off  | 00000000:03:00.0 Off |                  N/A |
| N/A   42C    P8    N/A /  N/A |      4MiB /  4096MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|<span class="o">=============================================================================</span>|
|    0   N/A  N/A      1001      G   /usr/lib/xorg/Xorg                  4MiB |
+-----------------------------------------------------------------------------+
</code></pre></div></div>

<p>우리가 사용하는 k3s는 Container Runtime으로 containerd를 사용한다.</p>

<p>(도커를 contianer runtime으로 쓸 수도 있지만, 여러가지 이유로 인해 k3s의 기본설정인 containerd를 사용하고 있다. 두 runtime의 차이와 containrd를 사용하는 이유에 대해서는 다른 포스트에서 다룰 예정이다.)</p>

<p>아무튼, k3s가 nvidia gpu를 사용하기 위해서는</p>

<ol>
  <li>nvidia-container-toolkit이 설치</li>
  <li>containerd의 low-level runtimes에 nvidia-container-runtime 추가</li>
  <li>k3s가 선택적으로 이 nvidia-contianer-runtime을 사용가능</li>
</ol>

<p>이 수행되어야 한다.</p>

<p>하나씩 진행해 보자.</p>

<h3 id="4-nvidia-container-toolkit-설치">4. nvidia-container-toolkit 설치</h3>

<p>toolkit을 설치하는 과정은 경우에 따라 변경될 수 있다. nvidia 공식문서를 참고하여 설치하는 것을 추천한다.</p>

<ul>
  <li><a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#containerd">https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#containerd</a></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ distribution</span><span class="o">=</span><span class="si">$(</span><span class="nb">.</span> /etc/os-release<span class="p">;</span><span class="nb">echo</span> <span class="nv">$ID$VERSION_ID</span><span class="si">)</span> <span class="se">\</span>
    <span class="o">&amp;&amp;</span> curl <span class="nt">-s</span> <span class="nt">-L</span> https://nvidia.github.io/libnvidia-container/gpgkey | <span class="nb">sudo </span>apt-key add - <span class="se">\</span>
    <span class="o">&amp;&amp;</span> curl <span class="nt">-s</span> <span class="nt">-L</span> https://nvidia.github.io/libnvidia-container/<span class="nv">$distribution</span>/libnvidia-container.list | <span class="nb">sudo tee</span> /etc/apt/sources.list.d/nvidia-container-toolkit.list

<span class="nv">$ </span><span class="nb">sudo </span>apt-get update <span class="se">\</span>
    <span class="o">&amp;&amp;</span> <span class="nb">sudo </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> nvidia-container-toolkit
</code></pre></div></div>

<h3 id="3-containerd-설정파일-수정">3. containerd 설정파일 수정</h3>

<p>이제  containerd가 NVIDIA Container Runtime를 사용할 수 있도록 <code class="highlighter-rouge">/etc/containerd/config.toml</code> 파일을 수정한다.</p>

<pre><code class="language-dhall">&lt;--/etc/containerd/config.toml--&gt;
...
privileged_without_host_devices = false
        base_runtime_spec = ""
        [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
-            SystemdCgroup = false
+            SystemdCgroup = true
+       [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.nvidia]
+          privileged_without_host_devices = false
+          runtime_engine = ""
+          runtime_root = ""
+          runtime_type = "io.containerd.runc.v1"
+          [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.nvidia.options]
+            BinaryName = "/usr/bin/nvidia-container-runtime"
+            SystemdCgroup = true
    [plugins."io.containerd.grpc.v1.cri".cni]
    bin_dir = "/opt/cni/bin"
    conf_dir = "/etc/cni/net.d"
...
</code></pre>

<p>containerd를 재시작한다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>systemctl restart containerd
</code></pre></div></div>

<h3 id="5-containerd-에서-gpu-사용-확인">5. containerd 에서 gpu 사용 확인</h3>

<p>containerd에서 gpu가 정상적으로 인식되는지 확인한다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>ctr image pull docker.io/nvidia/cuda:11.0.3-base-ubuntu20.04
<span class="nv">$ </span><span class="nb">sudo </span>ctr run <span class="nt">--rm</span> <span class="nt">-t</span> <span class="se">\</span>
    <span class="nt">--runc-binary</span><span class="o">=</span>/usr/bin/nvidia-container-runtime <span class="se">\</span>
    <span class="nt">--env</span> <span class="nv">NVIDIA_VISIBLE_DEVICES</span><span class="o">=</span>all <span class="se">\</span>
    docker.io/nvidia/cuda:11.0.3-base-ubuntu20.04 <span class="se">\</span>
    cuda-11.0.3-base-ubuntu20.04 nvidia-smi
<span class="o">&gt;&gt;&gt;</span>
Sat Sep  3 17:40:08 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 510.85.02    Driver Version: 510.85.02    CUDA Version: 11.6     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|<span class="o">===============================</span>+<span class="o">======================</span>+<span class="o">======================</span>|
|   0  NVIDIA GeForce ...  Off  | 00000000:03:00.0 Off |                  N/A |
| N/A   42C    P8    N/A /  N/A |      4MiB /  4096MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|<span class="o">=============================================================================</span>|
+-----------------------------------------------------------------------------+
</code></pre></div></div>

<p>이제 containerd가 nvidia-container-runtime을 사용하여 container를 생성하고 관리할 수 있다. 하지만, 아직 k3s는 nvidia-contianer-runtime을 사용하지 못한다.</p>

<h3 id="5-k3s의-contianer-runtimes에-nvidia-container-runtime을-추가">5. k3s의 contianer runtimes에 nvidia-container-runtime을 추가</h3>

<p>다음 단계는 k3s의 container runtime을 nvidia-container-runtime를 사용하는 containerd로 바꾸는 것이다.</p>

<p><code class="highlighter-rouge">/var/lib/rancher/k3s/agent/etc/containerd/config.toml</code> 파일에  <code class="highlighter-rouge">[plugins.cri.containerd.runtimes."nvidia"]</code> 설정과 <code class="highlighter-rouge">[plugins.cri.containerd.runtimes."nvidia".options]</code> 설정을 추가한다.</p>

<pre><code class="language-dhall">&lt;--/var/lib/rancher/k3s/agent/etc/containerd/config.toml--&gt;

[plugins.opt]
  path = "/var/lib/rancher/k3s/agent/containerd"

[plugins.cri]
  stream_server_address = "127.0.0.1"
  stream_server_port = "10010"
  enable_selinux = false
  enable_unprivileged_ports = true
  enable_unprivileged_icmp = true
  sandbox_image = "rancher/mirrored-pause:3.6"

[plugins.cri.containerd]
  snapshotter = "overlayfs"
  disable_snapshot_annotations = true

[plugins.cri.cni]
  bin_dir = "/var/lib/rancher/k3s/data/577968fa3d58539cc4265245941b7be688833e6bf5ad7869fa2afe02f15f1cd2/bin"
  conf_dir = "/var/lib/rancher/k3s/agent/etc/cni/net.d"

[plugins.cri.containerd.runtimes.runc]
  runtime_type = "io.containerd.runc.v2"

[plugins.cri.containerd.runtimes.runc.options]
  SystemdCgroup = true

+[plugins.cri.containerd.runtimes."nvidia"]
+  runtime_type = "io.containerd.runc.v2"
+[plugins.cri.containerd.runtimes."nvidia".options]
+  BinaryName = "/usr/bin/nvidia-container-runtime"
</code></pre>

<p>파일을 수정한 후 k3s를 재시작하면 k3s는 <code class="highlighter-rouge">nvidia-container-runtime</code> 을 사용하는 containerd를 선택적으로 사용할 수 있다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>systemctl restart k3s
</code></pre></div></div>

<h3 id="6--kubernetes-nvidia-plugin-배포">6.  kubernetes nvidia plugin 배포</h3>

<p>k8s nvidia plugin은 다음과 같은 역할을 수행한다.</p>

<ul>
  <li>클러스터의 각 노드들에 달려있는 gpu수를 파악</li>
  <li>gpu의 상태를 지속적으로 트래킹</li>
  <li>k8s클러스터 내 contianer가 gpu를 사용할수 있도록 함</li>
</ul>

<p><a href="https://github.com/NVIDIA/k8s-device-plugin">https://github.com/NVIDIA/k8s-device-plugin</a> 을 참고하면 간단히 daemonset을 배포하여 설치할 수도 있고, helm을 통해서 다양한 커스텀이 가능한 것으로 보인다.</p>

<p>필자는 현재 특별한 커스텀이 필요한 상황이 아님으로 git에 올라온 daemonset을 조금 수정하여 plugin을 설치하였다.</p>

<p>우선 gpu가 달려있는 노드에 gpu=nvidia라는 레이블을 달아준다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># node에 label 추가</span>
<span class="nv">$ </span>kubectl label nodes <span class="o">[</span>gpu가 장착된 노드명 1] <span class="nv">gpu</span><span class="o">=</span>nvidia
</code></pre></div></div>

<p>이제 git에 올라온 경로대로  DaemonSet을 생성하는 yaml을 파일을 다운받고,</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>curl <span class="nt">-O</span> https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.12.3/nvidia-device-plugin.yml
</code></pre></div></div>

<p>gpu가 달려있는 노드에 plugin이 배포될 수 있도록 nodeSelector를 추가한다.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">nodeSelector</span><span class="pi">:</span>
  <span class="na">gpu</span><span class="pi">:</span> <span class="s">nvidia</span>
</code></pre></div></div>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># nvidia-device-plugin.yml</span>

<span class="c1"># Copyright (c) 2019, NVIDIA CORPORATION.  All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the "License");</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an "AS IS" BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>

<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">DaemonSet</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">nvidia-device-plugin-daemonset</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">kube-system</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">name</span><span class="pi">:</span> <span class="s">nvidia-device-plugin-ds</span>
  <span class="na">updateStrategy</span><span class="pi">:</span>
    <span class="na">type</span><span class="pi">:</span> <span class="s">RollingUpdate</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">nvidia-device-plugin-ds</span>
    <span class="na">spec</span><span class="pi">:</span>
<span class="na">+      nodeSelector</span><span class="pi">:</span>
<span class="na">+          gpu</span><span class="pi">:</span> <span class="s">nvidia</span>
      <span class="s">tolerations</span><span class="err">:</span>
      <span class="pi">-</span> <span class="na">key</span><span class="pi">:</span> <span class="s">nvidia.com/gpu</span>
        <span class="na">operator</span><span class="pi">:</span> <span class="s">Exists</span>
        <span class="na">effect</span><span class="pi">:</span> <span class="s">NoSchedule</span>
      <span class="c1"># Mark this pod as a critical add-on; when enabled, the critical add-on</span>
      <span class="c1"># scheduler reserves resources for critical add-on pods so that they can</span>
      <span class="c1"># be rescheduled after a failure.</span>
      <span class="c1"># See https://kubernetes.io/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/</span>
      <span class="na">priorityClassName</span><span class="pi">:</span> <span class="s2">"</span><span class="s">system-node-critical"</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">image</span><span class="pi">:</span> <span class="s">nvcr.io/nvidia/k8s-device-plugin:v0.12.3</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">nvidia-device-plugin-ctr</span>
        <span class="na">env</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">FAIL_ON_INIT_ERROR</span>
            <span class="na">value</span><span class="pi">:</span> <span class="s2">"</span><span class="s">false"</span>
        <span class="na">securityContext</span><span class="pi">:</span>
          <span class="na">allowPrivilegeEscalation</span><span class="pi">:</span> <span class="no">false</span>
          <span class="na">capabilities</span><span class="pi">:</span>
            <span class="na">drop</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">ALL"</span><span class="pi">]</span>
        <span class="na">volumeMounts</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">device-plugin</span>
            <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/var/lib/kubelet/device-plugins</span>
      <span class="na">volumes</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">device-plugin</span>
          <span class="na">hostPath</span><span class="pi">:</span>
            <span class="na">path</span><span class="pi">:</span> <span class="s">/var/lib/kubelet/device-plugins</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl apply <span class="nt">-f</span> nvidia-device-plugin.yml
</code></pre></div></div>

<p>마지막으로 RuntimeClass를 생성하여 pod이 nvidia runtime을 선택할 수 있도록 설정한다.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># nvidia-runtime-class.yml</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">node.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">RuntimeClass</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="c1"># The name the RuntimeClass will be referenced by.</span>
  <span class="c1"># RuntimeClass is a non-namespaced resource.</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">nvidia"</span>
<span class="c1"># The name of the corresponding CRI configuration</span>
<span class="na">handler</span><span class="pi">:</span> <span class="s2">"</span><span class="s">nvidia"</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl apply <span class="nt">-f</span> nvidia-runtime-class.yml
</code></pre></div></div>

<p>이제 모든 준비를 마쳤다.</p>

<h3 id="6--테스트-용-gpu-pod-생성">6.  테스트 용 GPU pod 생성</h3>

<p>gpu를 사용하는 pod을 생성해보자.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># test-gpu-pod.yml</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">gpu</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">restartPolicy</span><span class="pi">:</span> <span class="s">Never</span>
  <span class="na">runtimeClassName</span><span class="pi">:</span> <span class="s2">"</span><span class="s">nvidia"</span> <span class="c1"># nvidia runtime 사용</span>
  <span class="na">nodeSelector</span><span class="pi">:</span> 
    <span class="na">gpu</span><span class="pi">:</span> <span class="s">nvidia</span> <span class="c1"># gpu가 장착된 node에만 배포</span>
  <span class="na">containers</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">gpu</span>
      <span class="na">image</span><span class="pi">:</span> <span class="s2">"</span><span class="s">nvidia/cuda:11.4.1-base-ubuntu20.04"</span>
      <span class="na">command</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">/bin/bash"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">-c"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">--"</span> <span class="pi">]</span>
      <span class="na">args</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">while</span><span class="nv"> </span><span class="s">true;</span><span class="nv"> </span><span class="s">do</span><span class="nv"> </span><span class="s">sleep</span><span class="nv"> </span><span class="s">30;</span><span class="nv"> </span><span class="s">done;"</span> <span class="pi">]</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> kubectl apply <span class="nt">-f</span> test-gpu-pod.yml
<span class="o">&gt;</span> kubectl <span class="nb">exec</span> <span class="nt">-it</span> gpu <span class="nt">--</span> nvidia-smi
Wed Sep 28 03:03:22 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 510.85.02    Driver Version: 510.85.02    CUDA Version: 11.6     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|<span class="o">===============================</span>+<span class="o">======================</span>+<span class="o">======================</span>|
|   0  NVIDIA GeForce ...  Off  | 00000000:03:00.0 Off |                  N/A |
| N/A   39C    P8    N/A /  N/A |      4MiB /  4096MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|<span class="o">=============================================================================</span>|
+-----------------------------------------------------------------------------+
</code></pre></div></div>

<p>성공적으로 pod이 올라갔다!</p>

<p>k3s에 gpu를 연결하는데 생각보다 시간이 오래걸렸다.</p>

<p>대부분의 내용을 <a href="https://itnext.io/enabling-nvidia-gpus-on-k3s-for-cuda-workloads-a11b96f967b0">https://itnext.io/enabling-nvidia-gpus-on-k3s-for-cuda-workloads-a11b96f967b0</a> 이 블로그에서 참고하였는데, k3d에서 배포한 config.toml 파일이 필자가 사용하는 버전에는 사용할 수 없었다. k3s git에 올라온 이슈를 확인하던 중  (<a href="https://github.com/k3s-io/k3s/issues/4070">https://github.com/k3s-io/k3s/issues/4070</a>) 최근 버전이 올라와 있어, 이를 참고하여 배포하였다.</p>

<p>사실 아직 nvidia container runtime, k8s nvidia plugin, cuda(특히, image는 cuda:11.4.1를 사용하는데 실제 nvidia-smi에서 잡히는 cuda version은 로컬에 설치된 11.6으로 나오는 이유?), 등에 대해 명확하게 이해하지 못했다. 기회가 된다면 각 요소들이 어떤 역할을 수행하며, 왜 필요한지에 대해 공부해 볼 예정이다.</p>

<p>또한 괜찮은 아이디어가 떠오른다면 이 gpu를 활용한 인공지능 토이 프로젝트를 진행해 볼 예정이다.</p>

<h2 id="reference">Reference</h2>

<ul>
  <li><a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#containerd">https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#containerd</a></li>
  <li><a href="https://askubuntu.com/questions/1262401/what-is-the-nvidia-server-driver">https://askubuntu.com/questions/1262401/what-is-the-nvidia-server-driver</a></li>
  <li><a href="https://itnext.io/enabling-nvidia-gpus-on-k3s-for-cuda-workloads-a11b96f967b0">https://itnext.io/enabling-nvidia-gpus-on-k3s-for-cuda-workloads-a11b96f967b0</a></li>
  <li><a href="https://github.com/k3s-io/k3s/issues/4070">https://github.com/k3s-io/k3s/issues/4070</a></li>
  <li><a href="https://www.samsungsds.com/kr/insights/docker.html">https://www.samsungsds.com/kr/insights/docker.html</a></li>
  <li><a href="https://developer.nvidia.com/blog/announcing-containerd-support-for-the-nvidia-gpu-operator/">https://developer.nvidia.com/blog/announcing-containerd-support-for-the-nvidia-gpu-operator/</a></li>
</ul>

	</div>
	<br/>
	<br/>
	<script src="https://utteranc.es/client.js"
        repo="deagwon97/deagwon97.github.io"
        issue-term="url"
        theme="github-light"
        crossorigin="anonymous"
        async>
	</script>
</article>
		</div>
	</div>
  </body>
</html>